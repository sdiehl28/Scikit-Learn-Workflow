{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1<br/>*Establish a Baseline model*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Iteration 1](https://sdiehl28.netlify.com/2018/03/iteration-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "1. Quickly create initial model and show that it is better than the null model.\n",
    "2. Demonstrate details of Scikit Learn methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Make a prediction for Survived / Not-Survived using the titanic dataset from Kaggle.  This is a supervised classification problem.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving:\n",
    "* the model's accuracy\n",
    "* the workflow used to create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Tentative Assumptions For 1st Iteration](#assumptions)\n",
    "4. [Model Building & Evaluation](#model)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Versions\n",
    "If your versions are earlier than shown here, you may need to upgrade your software to produce the same results.  On Linux, using the Anaconda distribution, this is done by:\n",
    "```\n",
    "source activate <env>\n",
    "conda update conda\n",
    "conda update --all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 18:21:58) \n",
      "[GCC 7.2.0]\n",
      "numpy:       1.14.2\n",
      "pandas:      0.22.0\n",
      "matplotlib:  2.2.2\n",
      "seaborn:     0.8.1\n",
      "sklearn:     0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "Note that this example is for supervised learning, so we will only deal with labeled data.  The labeled dataset is named \"train.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Create two variables from the data we read in preparation for creating a predictive model.  \n",
    "\n",
    "X: A Pandas DataFrame that represents the features (aka attributes)  \n",
    "y: A Pandas Series that represents the target (aka response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n",
      "X Type:  <class 'pandas.core.frame.DataFrame'>\n",
      "y Type:  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# X: drop target variable\n",
    "# y: keep only the target\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)\n",
    "print('X Type: ', type(X))\n",
    "print('y Type: ', type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  2\n",
      "y dimensions:  1\n"
     ]
    }
   ],
   "source": [
    "# ndim, as in numpy, reports the number of dimensions (e.g. 1D, 2D)\n",
    "print('X dimensions: ',X.ndim)\n",
    "print('y dimensions: ',y.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assumptions\"></a>\n",
    "### First Iteration Assumptions\n",
    "[Back to Outline](#outline)  \n",
    "\n",
    "In order to quickly get something up and running, let's arbitrarily decide upon the following:\n",
    "* use LogisticRegression\n",
    "* drop ID field\n",
    "* drop all non-numeric features\n",
    "* drop any column having a null value\n",
    "* model evaluation metric: accuracy\n",
    "\n",
    "Note that LogisticRegression requires all fields to be numeric and non-null.  Therefore we must either drop fields that don't meet these requirements or convert them to numeric fields.  Here we will drop them.  Later we will convert them to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non-numeric fields and PassengerId\n",
    "drop_cols = ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "X = X.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    0.000000\n",
       "Age       0.198653\n",
       "SibSp     0.000000\n",
       "Parch     0.000000\n",
       "Fare      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of missing values per column\n",
    "nrows, ncols = X.shape\n",
    "X.isnull().sum() / nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Age as it has null values (for the 1st iteration only)\n",
    "drop_cols = ['Age']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "Examining the codebook (aka data dictionary) at: https://www.kaggle.com/c/titanic/data\n",
    "shows that Pclass is an ordered categorical variable that happens to be encoded as an integer.  Let's take a quick look at how survival is related to passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group By passenger class\n",
    "# Survived = 1, Not Survived = 0\n",
    "# mean() of Survived is the fraction that survived\n",
    "all_data.groupby(['Pclass'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that 1st class passengers had a higher survival rate than 2nd class passengers who had a higher survival rate the 3rd class passengers.\n",
    "\n",
    "Passenger class is not a continuous variable.  The distance between 1st class and 2nd class is not the same as the distance between 2nd class and 3rd class; in fact, the distance is not defined.  Nevertheless for predictive modeling purposes, given that the ordinal encoding matches its association with the target variable, leaving it encoded as an integer is a good approach.\n",
    "\n",
    "Keep passenger class encoded as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building & Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "A train/test split will be used to demonstrate how to build and evaluate a model.\n",
    "\n",
    "The random_state will be set so that these results are repeatable.\n",
    "\n",
    "Later, cross validation will be used to get a better estimate of the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "# stratify=y means that the train and test sets will have about the same percentage \n",
    "# of survived observations as exists in our targer vector y\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data  Survived Fraction: 0.38\n",
      "Train Set Survived Fraction: 0.38\n",
      "Test  Set Survived Fraction: 0.38\n"
     ]
    }
   ],
   "source": [
    "# let's verify that stratify=y worked as expected\n",
    "print('All Data  Survived Fraction: {:.2f}'.format(all_data['Survived'].mean()))\n",
    "print('Train Set Survived Fraction: {:.2f}'.format(y_train.mean()))\n",
    "print('Test  Set Survived Fraction: {:.2f}'.format(y_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model on Train Data Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model fitted on train data set to make predictions on test data set\n",
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305970149253731"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuarcy using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305970149253731\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy manually to be sure we understand accuracy_score()\n",
    "print((predictions == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is sometimes referred to as:\n",
    "TP + TN / (TP + FP + TN + FN)\n",
    "\n",
    "Where \"Positive\" in this example is \"Survived\"\n",
    "<pre>\n",
    "TP = True  Positive  \n",
    "FP = False Positive \n",
    "TN = True Negative  \n",
    "FN = False Negative\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 39 \n",
      " 60 126\n"
     ]
    }
   ],
   "source": [
    "# For instructional purposes, let's derive the confusion matrix ourselves\n",
    "TP = ((predictions == 1) & (y_test == 1)).sum()\n",
    "FP = ((predictions == 1) & (y_test == 0)).sum()\n",
    "FN = ((predictions == 0) & (y_test == 1)).sum()\n",
    "TN = ((predictions == 0) & (y_test == 0)).sum()\n",
    "print(TP, FP,\"\\n\",FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 39 \n",
      " 60 126\n"
     ]
    }
   ],
   "source": [
    "# Have sklearn compute the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = confusion.flatten() # see confusion matrix documentation\n",
    "print(tp, fp, \"\\n\", fn, tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our single train/test split, we got an accuracy estimate of 63.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Each time we randomly chose a different train and test subset of our data, we will get a different estimate of the model's accuracy.  If we do this only once, we risk having an unrepresentative train/test split.\n",
    "\n",
    "A better approach is to take several train/test splits and compute the accuracy of each.  This is what Cross Validation does.\n",
    "\n",
    "Good overview of cross validation and overfiting in Python: [Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "Good overview of cross validation and overfitting in general:\n",
    "* chapter 5.1 of [ISL](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "* The first 3 videos for Chapter 5 [ISL Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "print(np.round(scores, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine What Scikit Learn Did Behind the Scenes\n",
    "The [cross_val_score()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) helper function does a lot.  Let's do exactly the same thing by hand to verify we understand it.\n",
    "\n",
    "A [crossvalidation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) object is returned from the call to KFold.  [crossvalidation.split(X)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold.split) is an iterator which returns 2 numpy arrays, one for the train subset and one for the test subset.\n",
    "\n",
    "Compute the accuracy score using the iterator and compare with cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n",
      "Scores match:  True\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "my_scores = np.zeros(n_splits)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1\n",
    "print(np.round(my_scores, 3))\n",
    "# compare with scores computed by cross_val_score above\n",
    "print('Scores match: ',(scores == my_scores).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.685\n"
     ]
    }
   ],
   "source": [
    "# let's use the average of the CV score as the metric of base model performance\n",
    "print('average: {:5.3f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Simplest Model\n",
    "For a classifier, predicting the predominant class is the simplest possible model.  This is sometimes referred to as the \"null model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62  0.652 0.579 0.601 0.629] 0.616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "null_model = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "scores = cross_val_score(null_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "print(np.round(scores, 3), np.round(scores.mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68.5% is better than the null model accuracy 61.6%.  This is likely to be statistically significant.  A hypothesis test could be performed to see if it is, but that will not be done here.\n",
    "\n",
    "Here we will simply say that our simple Logistic Regression Model appears to be off to a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "In this first iteration we:\n",
    "* discussed how Scikit Learn computes accuracy, the confusion matrix, and cross validation scores\n",
    "* created a simple model to use as our baseline\n",
    "* established a baseline accuracy of 68.5%\n",
    "* showed that this accuracy is better than the null model accuracy of 61.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
