{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Model Dev 1<br/>*Establish a Baseline model*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Iterative Dev 1](https://sdiehl28.netlify.com/2018/02/iterative-model-dev-1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Example\n",
    "Make a prediction for Survived / Not-Survived using the titanic dataset from Kaggle.  This is a supervised classification problem.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving:\n",
    "* the model's accuracy\n",
    "* the workflow used to create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Tentative Assumptions For 1st Iteration](#assumptions)\n",
    "4. [Model Building & Evaluation](#model)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Versions\n",
    "If your results are different from these notebooks, it may be that you need to upgrade the version of the software you are using.  On Linux, using the Anaconda distribution, this is done by:\n",
    "```\n",
    "source activate <env>\n",
    "conda update conda\n",
    "conda update --all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 18:10:19) \n",
      "[GCC 7.2.0]\n",
      "numpy:       1.14.1\n",
      "pandas:      0.22.0\n",
      "matplotlib:  2.2.0\n",
      "seaborn:     0.8.1\n",
      "sklearn:     0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Create two variables from the data we read in preparation for creating a predictive model.  \n",
    "\n",
    "X: A Pandas DataFrame that represents the features (aka attributes)  \n",
    "y: A Pandas Series that represents the target (aka response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n"
     ]
    }
   ],
   "source": [
    "# X: drop target variable\n",
    "# y: keep only the target\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  2\n",
      "y dimensions:  1\n"
     ]
    }
   ],
   "source": [
    "# ndim, as in numpy, reports the number of dimensions (e.g. 1D, 2D)\n",
    "print('X dimensions: ',X.ndim)\n",
    "print('y dimensions: ',y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_2D type:  <class 'numpy.ndarray'>\n",
      "y_2D shape:  (891, 1)\n",
      "y_2D dimensions:  2\n",
      "contents match:  True\n"
     ]
    }
   ],
   "source": [
    "# aside for later\n",
    "# y is a 1D object\n",
    "# sometimes we need its 2D equivalent: a 2D object having 1 column\n",
    "# using .values picks out the values as a numpy array\n",
    "# using reshape(-1,1) converts it to a 2D object having 1 column\n",
    "y_2D = y.values.reshape(-1,1)\n",
    "print('y_2D type: ', type(y_2D))\n",
    "print('y_2D shape: ', y_2D.shape)\n",
    "print('y_2D dimensions: ', y_2D.ndim)\n",
    "print('contents match: ',(y.values == y_2D.flatten()).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assumptions\"></a>\n",
    "### First Iteration Assumptions\n",
    "[Back to Outline](#outline)  \n",
    "\n",
    "In order to quickly get something up and running, let's arbitrarily decide upon the following:\n",
    "* use LogisticRegression (as is common for classification problems)\n",
    "* drop ID field\n",
    "* drop all non-numeric features\n",
    "* drop any column having a null value\n",
    "* model evaluation metric: accuracy (auc is another good choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non-numeric fields and PassengerId\n",
    "drop_cols = ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "X = X.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    0.000000\n",
       "Age       0.198653\n",
       "SibSp     0.000000\n",
       "Parch     0.000000\n",
       "Fare      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of missing values per column\n",
    "nrows, ncols = X.shape\n",
    "X.isnull().sum() / nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Age as it has null values (for the 1st iteration only)\n",
    "drop_cols = ['Age']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "Examining the codebook (aka data dictionary) at: https://www.kaggle.com/c/titanic/data\n",
    "shows that Pclass is an ordered categorical variable that happens to be encoded as an integer.  Let's take a quick look at how survival is related to passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f539ddfe198>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAFmlJREFUeJzt3X+YV3Wd9/HnMCO6CAUGFoG3aNDbzL1Fy9+VP7dLzRVx1cWuSJAVM7m1e8kycjPFH7XGdtNq3rmrAl6Z4a+V24t7rcwy77T8kWuavTdSEgQBdVQUo4C5//gezo44DAMzZ74zzPNxXXPNOZ/zOZ/vm7l0XnPO+ZxzGlpaWpAkCaBfvQuQJPUchoIkqWQoSJJKhoIkqWQoSJJKTfUuoDNWrVrt1ClJ2krDhg1q2Nw2jxQkSSVDQZJUMhQkSSVDQZJUMhQkSSVDQZJUMhQkSSVDQZJUMhQkSaVefUezJPVEy5cvY9Kk0xkzJnj99dc54YQTOeWUCW/rt3Dh/2Hp0iVMnfrZOlTZNkNBlXt4+nn1LmGrHTDrW/UuQb3cnnuO5uqrr+P1119nwoTxHHHEMQwdOrTeZW2RoSBJFRo4cCDvfe8Iliz5A1//+kzefPNNGhoa+PKXL3lLv+985xqeeurXvPHGGxx88KGcddY5NDe/zFe+8iVaWlrYsGEDn//8hTQ2NnHllZeyww47sGHDBi6//CoGDx7cZfUaCpJUoRdfXMWyZc8zd+71jBt3MkceeQwAGzZseEu/iRMnM2DAAFpaWpg6dRLHH//XLFr0O/bYY0/+/u+/WO5z663f42MfO5JPfnIiAF39SmVDQZIq8Mwzi5g2bSoA06d/keuvv46DDjqk3N6v31vn+SxYcAc/+9lPaWho4IUXlrNy5QoOPfQjPPvs75k58x8YNOidnHnmWXziE+O46aYbmTnzH9h11/cwefJZ9O/fv8vqNhQkqQIbrylsdN999/Lww7/g8MOPAt56pPDaa69x5523cfPNtwMwdeokWlpaWL9+PZMm/R0Ac+b8K3fffRcnn3wa55zzPwC48spLeeCB+znqqGO6rG5DQZK6wbnnns8//uMV3HrrLfTr148ZM75abhs0aBB77fUBPvOZyYwc+d8YOHAgAL/61aPMm3cDjY2NtLS0MGPGxfzoR//OwoV3069fP/r378+HPvThLq2zoavPR3UnX7LTOzj7SOpZfMmOJKlDDAVJUqmyawoRsRNwP7Bj8Tm3ZebFETEHOBx4teg6KTMfj4gGYDZwPLCmaH+sqvokSW9X5YXmtcBRmfl6ROwAPBAR/7fYdkFm3rZJ/+OAMcXXQcC1xXdJUjep7PRRZrZk5uvF6g7FV3sXhscB84r9HgIGR8TwquqTJL1dpVNSI6IReBQYDVyTmb+IiHOAyyPiK8C9wIWZuRYYASxptfvSom355sYfMmQATU2NldWvvmvYsEH1LkGqi0pDITPXA2MjYjBwZ0TsA3wJeAHoD1wHfBG4FGhrilS7U06bm9d0bcFSYdWq1fUuQb3M+Vct6NLxZl9w4hb7XHHFJfz85w8wZMgQbrppfofHbu+Pnm6ZfZSZrwA/AY7NzOXFKaK1wI3AgUW3pcBurXYbCSzrjvokqTc6/vi/Ztasf+7SMSsLhYgYVhwhEBF/ARwD/HbjdYJittFJwJPFLguAT0dEQ0QcDLyamZs9dSRJfd3Ysfvzjne8o0vHrPL00XBgbnFdoR8wPzPvjogfR8QwaqeLHgc+U/RfSG066iJqU1InV1ibJKkNlYVCZj4B7NdG+1Gb6d8CnFtVPZKkLfOOZklSyVCQJJV8dLYkdYGOTCHtahdfPIPHH3+UV155hfHjj2fKlKmccMJJnRrTUJCkXuqSS67o8jE9fSRJKhkKkqSSoSBJKhkKkqSSoSBJKhkKkqSSU1IlqQtccPdFXTreVSdc1u72FSte4LLLLubll1+ioaEfJ544ntNOO73Tn2soSFIv1NjYxLRp/5OIvViz5g3OPHMiBxxwEHvssWenxvX0kST1QkOHDiViLwAGDNiZUaNG8eKLKzs9rqEgSb3c8uXL+M//TPbee59Oj2UoSFIvtmbNGr785S9w/vnT2XnngZ0ez1CQpF5q3bp1XHTRF/j4x4/l8MPbfFXNVjMUJKkXamlp4corL2X33fdgwoRPddm4zj6SpC6wpSmkXe2JJ/6De+5ZyPveN5pJkz4JwNlnf5ZDDvlIp8Y1FCSpF9p337E88MAjXT5uZaEQETsB9wM7Fp9zW2ZeHBF7ALcAuwCPARMz808RsSMwD/gQ8BLwt5m5uKr6JElvV+U1hbXAUZm5LzAWODYiDga+DnwzM8cAzcCUov8UoDkzRwPfLPpJkrpRZaGQmS2Z+XqxukPx1QIcBdxWtM8FNr47blyxTrH96IhoqKo+SdLbVXpNISIagUeB0cA1wO+BVzJzXdFlKTCiWB4BLAHIzHUR8SrwLuDFzY0/ZMgAmpoaK6pefdmwYYPqXYJUF5WGQmauB8ZGxGDgTuADbXRrKb63dVTQ0kZbqbl5TecKlDZj1arV9S5Bqkx7f/R0y30KmfkK8BPgYGBwRGwMo5HAsmJ5KbAbQLH9ncDL3VGfJKmmytlHw4A/Z+YrEfEXwDHULh7fB5xCbQbSGcBdxS4LivUHi+0/zsx2jxQkqad4ePp5XTreAbO+1e72tWvXMm3aWfzpT39m/fr1HHnk0UyZcnanP7fK00fDgbnFdYV+wPzMvDsifgPcEhGXAb8Cri/6Xw/cFBGLqB0hTKiwNknq1fr378/s2f+bAQMGsG7dOs45ZwoHHXQo++zzl50at7JQyMwngP3aaH8GOLCN9j8Cp1ZVjyRtTxoaGhgwYABQewbS+vXraGjo/IRN72iWpF5q/fr1TJkykeefX8L48afywQ/66GxJ6rMaGxuZM+dm7rhjIU8//RTPPLOo02MaCpLUyw0aNIj99vsQDz30YKfHMhQkqRdqbm5m9era/TRr1/6RRx75JbvvPqrT43pNQZK6wJamkHa1l156kcsvv5gNGzawYcMGjjrqrzjssI92elxDQZJ6odGjx3DjjTd3+biePpIklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVKpsgfiRcRuwDzgPcAG4LrMnB0RXwXOAlYVXWdk5sJiny8BU4D1wHmZeU9V9UmS3q7Kp6SuA6Zn5mMRMQh4NCJ+WGz7ZmZ+o3XniNgbmAB8EHgv8KOIeH9mrq+wRklSK5WdPsrM5Zn5WLG8GngaGNHOLuOAWzJzbWY+CywCDqyqPknS23XLNYWIGAXsB/yiaJoWEU9ExA0RMaRoGwEsabXbUtoPEUlSF6v8JTsRMRC4HfhcZr4WEdcCM4GW4vss4EygoY3dW9obe8iQATQ1NXZxxRIMGzao3iVIdVFpKETEDtQC4buZeQdAZq5otf1fgLuL1aXAbq12Hwksa2/85uY1XVqvtNGqVavrXYJUmfb+6Kns9FFENADXA09n5j+1ah/eqtt44MlieQEwISJ2jIg9gDHAL6uqT5L0dlUeKRwGTAR+HRGPF20zgNMjYiy1U0OLgbMBMvOpiJgP/IbazKVznXkkSd2rslDIzAdo+zrBwnb2uRy4vKqaJEnt845mSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklToUCsXTS7fYJknq3Tp6pDC6jba9urIQSVL9tfvo7Ig4C5gKvD8iWr/w5p1AVlmYJKn7bel9Cj8AfgdcDVzQqv014ImqipIk1Ue7oZCZfwD+AOzTPeVIkuqpQ29ei4gALgLe13qfzDyworokSXXQ0ddx3gLcCtwI+N5kSdpOdTQU+mXmFVszcETsBswD3gNsAK7LzNkRsQvwfWAUsBg4LTObI6IBmA0cD6wBJmXmY1vzmZKkzunolNQHI+K/b+XY64DpmfkB4GDg3IjYG7gQuDczxwD3FusAxwFjiq+pwLVb+XmSpE7q6JHCQcDkiEjgjxsb27umkJnLgeXF8uqIeBoYAYwDjii6zQV+AnyxaJ+XmS3AQxExOCKGF+NIkrpBR0Phc535kIgYBewH/AJ498Zf9Jm5PCJ2LbqNAJa02m1p0bbZUBgyZABNTY2dKU1q07Bhg+pdglQXHQqFzPzptn5ARAwEbgc+l5mv1SYytamhjbaW9sZubl6zrWVJ7Vq1anW9S5Aq094fPR2dkvowbfyC3tKU1IjYgVogfDcz7yiaV2w8LRQRw4GVRftSYLdWu48ElnWkPklS1+jo6aPPt1reCTidLfzCLmYTXQ88nZn/1GrTAuAM4GvF97tatU+LiFuoXcN41esJktS9tun0UUT8gNojMNpzGDAR+HVEPF60zaAWBvMjYgrwHHBqsW0htemoi6hNSZ3ckdokSV2no0cKm3oHsGd7HTLzAdq+TgBwdBv9W4Bzt7EeSVIX2JZrCv2oBcKsqoqSJNXHtlxTWAc8m5leBJak7UyH7mgurin8P+BFoJn/mjEkSdqOdPR1nB8Gfg/cSW220O8iYv8qC5Mkdb+OPvtoNjA5M99fPLPoTOCfqytLklQPHQ2FnTPzxxtXMvM+YOdqSpIk1UtHQ2FNRBy5cSUiDqd2L4EkaTvS0dlH5wG3R8RaalNTdwT+prKqJEl10dFQGAwcAOxK7Ya0FfjeZkna7nQ0FK4C9s/MlQAR0Q/4BuAMJEnajnT0mkJD8RgKADJzA+CLDCRpO9PRUFgdEQdtXCmW36imJElSvXT09NEXgH+LiKeK9b2Bk6spSZJULx19dPaDEbE3cAi1C80/z8zmSiuTJHW7Dj86uwiBhRXWIkmqs45eU5Ak9QGGgiSpZChIkkqGgiSptK3vaN6iiLgBOAFYmZn7FG1fBc4CVhXdZmTmwmLbl4ApwHrgvMy8p6raJEltqywUgDnA1cC8Tdq/mZnfaN1QTHedAHwQeC/wo4h4f2aur7A+SdImKjt9lJn3Ay93sPs44JbMXJuZzwKLgAOrqk2S1LYqjxQ2Z1pEfBp4BJhe3P8wAnioVZ+lRVu7hgwZQFOTj2BS1xs2bFC9S5DqortD4VpgJrV3MswEZlF7tWdDG31b2mh7i+Zm3/OjaqxatbreJUiVae+Pnm4NhcxcsXE5Iv4FuLtYXQrs1qrrSGBZN5YmSaKbp6RGxPBWq+OBJ4vlBcCEiNgxIvYAxgC/7M7aJEnVTkn9HnAEMDQilgIXA0dExFhqp4YWA2cDZOZTETEf+A2wDjjXmUeS1P0qC4XMPL2N5uvb6X85cHlV9UiStsw7miVJJUNBklSqx30Kkjrg/KsW1LuErTb7ghPrXYI6ySMFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJUJAklQwFSVLJO5ol9WkPTz+v3iVslQNmfavS8T1SkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUqmyKakRcQNwArAyM/cp2nYBvg+MAhYDp2Vmc0Q0ALOB44E1wKTMfKyq2iRJbavySGEOcOwmbRcC92bmGODeYh3gOGBM8TUVuLbCuiRJm1FZKGTm/cDLmzSPA+YWy3OBk1q1z8vMlsx8CBgcEcOrqk2S1LbuvqP53Zm5HCAzl0fErkX7CGBJq35Li7bl7Q02ZMgAmpoaKylUfduwYYPqXUKv5M+telX/jHvKYy4a2mhr2dJOzc1rKihFglWrVte7hF7Jn1v1uuJn3F6wdHcorIiI4cVRwnBgZdG+FNitVb+RwLJurq3XuODui+pdwlY5rd4FSOqw7p6SugA4o1g+A7irVfunI6IhIg4GXt14mkmS1H2qnJL6PeAIYGhELAUuBr4GzI+IKcBzwKlF94XUpqMuojYldXJVdUmSNq+yUMjM0zez6eg2+rYA51ZViySpY7yjWZJU6imzjyRtB3rbJAhwIsSmPFKQJJUMBUlSyVCQJJX6/DWF869aUO8Stlr/D9S7AknbK48UJEklQ0GSVDIUJEklQ0GSVDIUJEklQ0GSVDIUJEklQ0GSVDIUJEklQ0GSVDIUJEklQ0GSVDIUJEmlujwlNSIWA6uB9cC6zPxwROwCfB8YBSwGTsvM5nrUJ0l9VT2PFI7MzLGZ+eFi/ULg3swcA9xbrEuSulFPOn00DphbLM8FTqpjLZLUJ9XrJTstwA8iogX4TmZeB7w7M5cDZObyiNh1S4MMGTKApqbGiktVXzRs2KB6lyC1qer/NusVCodl5rLiF/8PI+K32zJIc/OaLi5Lqlm1anW9S5Da1BX/bbYXLHU5fZSZy4rvK4E7gQOBFRExHKD4vrIetUlSX9btoRARO0fEoI3LwMeBJ4EFwBlFtzOAu7q7Nknq6+px+ujdwJ0RsfHzb87Mf4+Ih4H5ETEFeA44tQ61SVKf1u2hkJnPAPu20f4ScHR31yNJ+i89aUqqJKnODAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVDAVJUslQkCSVuv0dzVsSEccCs4FG4F8z82t1LkmS+owedaQQEY3ANcBxwN7A6RGxd32rkqS+o0eFAnAgsCgzn8nMPwG3AOPqXJMk9RkNLS0t9a6hFBGnAMdm5t8V6xOBgzJzWn0rk6S+oacdKTS00dZzUkuStnM9LRSWAru1Wh8JLKtTLZLU5/S02UcPA2MiYg/geWAC8Mn6liRJfUePOlLIzHXANOAe4GlgfmY+Vd+qJKnv6FEXmiVJ9dWjjhQkSfVlKEiSSj3tQrPqwEeLqKeKiBuAE4CVmblPvevpCzxS6ON8tIh6uDnAsfUuoi8xFOSjRdRjZeb9wMv1rqMvMRQ0AljSan1p0SapDzIU5KNFJJUMBfloEUklZx/JR4tIKnmk0Mf5aBH1ZBHxPeDB2mIsjYgp9a5pe+djLiRJJY8UJEklQ0GSVDIUJEklQ0GSVDIUJEkl71NQnxYRpwIzqN3ZvRPwWGZ22X0aEfE4cEhmvtlF430VGJiZn++K8aRNGQrqsyJiOPBtYP/MXBIRDcC+WzlGU3GvR5syc2wny5S6laGgvuw9wJ+BlwAyswV4PCJGAY9k5lCA1usbl4GrgWOAmyPiUmCvzHyx6D8LeC0zL4mIFmAQMB44OTPHF32agOeAQzNzcUR8ATiF2v+TzwNnZeYLEfFO4HpqjzV/DlgFrKj2x6K+zGsK6sv+A/gl8FxE3BYRn4uId3Vgv3cBT2fmRzLz28BdFI8GKX7Znw7M3WSf24GPRsTQYv044LdFIHwKGA0cnJn7AwuBWUW/r1ALmL2BTwGHb+s/VuoIQ0F9VmZuyMyTgCOA+4BPAE8Au2xh1z8C81utzwEmFcvHUQuMxZt81hpahUfR/8Zi+URqRx2PFdcgzgVGFduOpHakQHEkckeH/nHSNvL0kfq8zHwSeBK4JiJ+A+zDW/9g2mmTXd4oTjVt3P9nETEoIv6S2i/7OZv5qDnA/4qI71L7i39i0d4AXJaZN7SxT1uPNpcq45GC+qyIGBERh7RaHwkMo/ZgwB0iYnSxqSOzkeYB04GPUTtV9DaZ+TPgHcCVwL8VRw8AC4DPRsSQoo4dI2LjBe97gclF+7uoXZuQKuORgvqyJuCSiNgdeJPaH0kXZebDEXE+8MOI+AO1U0tbMhd4Frix1S/7zfWbCXx0Y0Nm3lRca/hpRFDU8W1q1zxmAjcURzCLgR9s3T9R2jo+JVWSVPL0kSSpZChIkkqGgiSpZChIkkqGgiSpZChIkkqGgiSp9P8BT6EjTkeGnd8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Survived', hue='Pclass', data=all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 means did not survive and 1 means survived.\n",
    "\n",
    "The above shows that 1st class passengers had a higher survival rate than 2nd class passengers who had a higher survival rate the 3rd class passengers.\n",
    "\n",
    "Passenger class is not a continuous variable.  The distance between 1st class and 2nd class is not the same as the distance between 2nd class and 3rd class; in fact, the distance is not defined.  Nevertheless for predictive modeling purposes, given that the ordinal encoding matches its association with the target variable, leaving it encoded as an integer is a good approach.\n",
    "\n",
    "For now, let's keep passenger class encoded as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building & Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "A train/test split will be used to demonstrate how to build and evaluate a model.\n",
    "\n",
    "The random_state will be set so that these results are repeatable.\n",
    "\n",
    "Cross validation will be used to get a better estimate of the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "# for a single train/test split, with uneven target class distributions, statify=y is good\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model on Train Data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model fitted on train data to make predictions on test data\n",
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305970149253731"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuarcy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305970149253731\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy manually to be sure we understand accuracy_score()\n",
    "# The following computes the mean number of True values, which is the precentage of True values\n",
    "print((predictions == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is sometimes referred to as:\n",
    "TP + TN / (TP + FP + TN + FN)\n",
    "\n",
    "Where \"Positive\" in this example is \"Survived\"\n",
    "<pre>\n",
    "TP = True  Positive  \n",
    "FP = False Positive \n",
    "TN = True Negative  \n",
    "FN = False Negative\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 39 \n",
      " 60 126\n"
     ]
    }
   ],
   "source": [
    "# For instructional purposes, let's derive the confusion matrix ourselves\n",
    "# Recall that y_test is the actual data from the test set\n",
    "TP = ((predictions == 1) & (y_test == 1)).sum()\n",
    "FP = ((predictions == 1) & (y_test == 0)).sum()\n",
    "FN = ((predictions == 0) & (y_test == 1)).sum()\n",
    "TN = ((predictions == 0) & (y_test == 0)).sum()\n",
    "print(TP, FP,\"\\n\",FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 39 \n",
      " 60 126\n"
     ]
    }
   ],
   "source": [
    "# Have sklearn compute the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = confusion.flatten() # see confusion matrix documentation\n",
    "print(tp, fp, \"\\n\", fn, tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our single train/test split, we got an accuracy estimate of 63.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Each time we randomly chose a different train and test subset of our data, we will get a different estimate of the model's accuracy.  If we do this only once, we risk having an unrepresentative train/test split.\n",
    "\n",
    "A better approach is to take several train/test splits and compute the accuracy of each.  This is what Cross Validation does.\n",
    "\n",
    "Good overview of cross validation and overfiting in Python: [Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "Good overview of cross validation and overfitting in general:\n",
    "* chapter 5.1 of [ISL](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "* The first 3 videos for Chapter 5 [ISL Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, scoring='accuracy',\n",
    " n_jobs=1)\n",
    "print(np.round(scores, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine What Scikit Learn Did Behind the Scenes\n",
    "The [cross_val_score()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) helper function does a lot.  Let's do exactly the same thing by hand to verify we understand what it does.\n",
    "\n",
    "A [crossvalidation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) object is returned from the call to KFold.  [crossvalidation.split(X)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold.split) is an iterator which returns 2 numpy arrays, one for the train subset and one for the test subset.\n",
    "\n",
    "Compute the accuracy score using the iterator and compare with cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n",
      "Scores match:  True\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "my_scores = np.zeros(n_splits)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1\n",
    "print(np.round(my_scores, 3))\n",
    "print('Scores match: ',(scores == my_scores).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.685\n"
     ]
    }
   ],
   "source": [
    "# let's use the average of the CV score as the metric of base model performance\n",
    "print('average: {:5.3f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    112\n",
       "1     66\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with Simplest Possible Model Sometimes called the Null Model\n",
    "# Null Model Predicts predominant class every time\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Model Accuracy: 0.616\n"
     ]
    }
   ],
   "source": [
    "# Null Model Accuracy\n",
    "null_accuracy = 165 / (165 + 103)\n",
    "print('Null Model Accuracy: {:5.3f}'.format(null_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68.5% is better than the null model accuracy 61.6%.  This is likely to be statistically significant.  A hypothesis test could be performed to see if it is, but that will not be done here.\n",
    "\n",
    "Here we will simply say that our simple Logistic Regression Model appears to be off to a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "In this first iteration we:\n",
    "* discussed how Scikit Learn computes accuracy, the confusion matrix, and cross validation scores\n",
    "* created a simple model to use as our baseline\n",
    "* established a baseline accuracy of 68.5%\n",
    "* showed that this accuracy is better than the null model accuracy of 61.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
