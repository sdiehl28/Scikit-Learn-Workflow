{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1: Establish a Baseline Model\n",
    "\n",
    "Jupyter Notebook referenced from my website: <a href=\"https://sdiehl28.netlify.com/projects/titanic/titanic01/\" target=\"_blank\">Software Nirvana: Titantic01</a>\n",
    "\n",
    "The material on my website and notebooks is intended to suppliment a course in machine learning, rather than be a course in machine learning.\n",
    "\n",
    "In this series of notebooks which demonstrates iterative model development, topics such as how to use Pandas will not be discussed.  However links to my Jupyter Notebooks which do discuss such topics will presented.\n",
    "    \n",
    "* [github repo](https://github.com/sdiehl28/tutorial-jupyter-notebooks)  \n",
    "* [Pandas: Series](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Series.ipynb)  \n",
    "* [Pandas: Axis Specification](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/AxisSpecification.ipynb)  \n",
    "* [Pandas: DataFrame](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Dataframe.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Example\n",
    "Make a prediction for Survived / Not-Survived using the titanic dataset from Kaggle.  This is a supervised learning problem.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving the model and measuring the model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Train / Test Split](#traintest)\n",
    "4. [Exploratory Data Analysis](#eda)\n",
    "5. [Preprocessing](#preprocess)\n",
    "6. [Model Building](#model)\n",
    "7. [Model Evaluation](#eval)\n",
    "8. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Software Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 18:10:19) \n",
      "[GCC 7.2.0]\n",
      "numpy:       1.14.1\n",
      "pandas:      0.22.0\n",
      "matplotlib:  2.1.2\n",
      "seaborn:     0.8.1\n",
      "sklearn:     0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n"
     ]
    }
   ],
   "source": [
    "# break up the dataframe into X and y\n",
    "# X is a 2 dimensional \"spreadsheet\" of values used for prediction\n",
    "# y is a 1 dimensional vector of target (aka response) values\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"traintest\"></a>\n",
    "### Train and Test Split\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Do this prior to Exploratory Data Analysis and other Model Building Steps to avoid looking at the test data.\n",
    "\n",
    "Train/Test split will later be refined to use cross validation.\n",
    "\n",
    "Performing the same operation on the train and test datasets will later be refined to use a pipeline.\n",
    "\n",
    "The option: stratify = y  (where y is the Survived/NotSurvived column vector)  \n",
    "is a helpful as it creates the same proportion of Survived/NotSurvived in both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eda\"></a>\n",
    "### Exploratory Data Analysis\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "One of the first things to check for is **null values**.  In this *first iteration* of creating a machine learning model, this will be the only EDA performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.219904\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.770465\n",
       "Embarked       0.003210\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of missing values per column\n",
    "nrows, ncols = X_train.shape\n",
    "X_train.isnull().sum() / nrows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Value Analysis\n",
    "The following is a reasonable judgement call as to how to proceed based on the observed percentages of null values.\n",
    "1. The Age attribute has some missing values => impute missing values\n",
    "2. Most of the Cabin attribute is missing => remove it\n",
    "3. Very few Emarked records are missing => remove records with missing Emarked value\n",
    "\n",
    "Age imputation is likely to be helpful, however in this first iteration the goal is to quickly create a model for baseline purposes.\n",
    "\n",
    "Write a note to ourself and others about what to try next.  In a business environment, this would be maintained in an issue tracking system.  \n",
    "\n",
    "**Next Iteration:**\n",
    "- Try Age Imputation\n",
    "- Removed records with missing Emarked value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard Age column (for now)\n",
    "X_train = X_train.drop('Age', axis=1)\n",
    "X_test = X_test.drop('Age', axis=1)\n",
    "\n",
    "# Discard Cabin column\n",
    "X_train = X_train.drop('Cabin', axis=1)\n",
    "X_test = X_test.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Datatypes\n",
    "Often this involves converting text or integers to categorical variables.\n",
    "\n",
    "Based on a review of the data dictionary at [titanic](https://www.kaggle.com/c/titanic/data), and an examination of the values of each column, the following variables need to be converted to categorical:\n",
    "\n",
    "\n",
    "**Next Iteration: convert the following variables to categorical**\n",
    "- Pclass\n",
    "- Sex\n",
    "- Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 1st Iteration only, ignore all text and categorical variables\n",
    "X_train = X_train.drop('Pclass', axis=1)\n",
    "X_test = X_test.drop('Pclass', axis=1)\n",
    "X_train = X_train.drop('Name', axis=1)\n",
    "X_test = X_test.drop('Name', axis=1)\n",
    "X_train = X_train.drop('Sex', axis=1)\n",
    "X_test = X_test.drop('Sex', axis=1)\n",
    "X_train = X_train.drop('Ticket', axis=1)\n",
    "X_test = X_test.drop('Ticket', axis=1)\n",
    "X_train = X_train.drop('Embarked', axis=1)\n",
    "X_test = X_test.drop('Embarked', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural question to ask is, wouldn't it have been easier to drop these columns prior\n",
    "to creating the train/test split so we wouldn't have to apply the same operation (drop column) to one?  The answer is \"yes\", but the proper way to do this, while ensuring no \"test data leakage\", is by way of pipelines and that will be discussed in a subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the datatypes of each remaining column\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"preprocess\"></a>\n",
    "### Preprocessing\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Preprocessing was done \"inline\" with the Exploratory Data Analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Perhaps the simplest model to try for classification of two classes (Survived, Not-Survived) is Logistic Regression.\n",
    "\n",
    "Special techniques are required if one class is on the order of 10 times more frequent than the other.  Let's check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's close enough.  Logistic Regression should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eval\"></a>\n",
    "### Model Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "The simplest measure of \"model performance\" is the percent of correct predictions.  Assuming that the cost of a false positive is equal to the cost of a false negative, \"accuracy\" is a good measure of model value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6567164179104478"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score will compute the accuarcy\n",
    "base_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy manually just to be sure we understand what score() is doing\n",
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150,  77],\n",
       "       [ 15,  26]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(predictions, y_test)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6567164179104478\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "base_model_accuracy = (150 + 26) / (150+77+15+26)\n",
    "print(base_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as above, so the score is the accuracy.  \n",
    "\n",
    "Accuracy is sometimes referred to as:\n",
    "TP + TN / (TP + FP + TN + FN)\n",
    "\n",
    "Where \"Positive\" is arbitrarily defined to be \"Survived\"\n",
    "<pre>\n",
    "TP = True  Positive = confusion\\[0,0\\]  \n",
    "FP = False Positive = confusion\\[0,1\\]  \n",
    "TN = True Negative  = confusion\\[1,0\\]  \n",
    "FN = False Negative = confusion\\[1,1\\]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    165\n",
       "1    103\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with Simplest Possible Model Sometimes called the Null Model\n",
    "# Null Model Predicts predominant class every time\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6380597014925373\n"
     ]
    }
   ],
   "source": [
    "# Null Model Accuracy\n",
    "null_accuracy = 171 / (171 + 97)\n",
    "print(null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "65.7% is better than the null model accuracy 63.8%.  This may or may not be statistically significant.  A hypothesis test could be performed to see if it is, but that will not be done here.\n",
    "\n",
    "Here we will simply say that the Logistic Regression Model is worthwhile to continue using as we iteratively Kaizen the model building process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Conclusion\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "The simple Logistic Regression model had a prediction accuracy of about 68%.  The null model which just predicts the most common class in all cases was accurate about 64% of the time.\n",
    "\n",
    "In this first iteration:\n",
    "* we quickly created a model\n",
    "* noted a few things to try to improve the model\n",
    "* established a baseline accuracy of 65.7%\n",
    "* showed that this accuracy is better than the null model accuracy of 63.8%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
