{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1: Establish a Baseline Model\n",
    "\n",
    "Jupyter Notebook referenced from my website: <a href=\"https://sdiehl28.netlify.com/projects/titanic/titanic01/\" target=\"_blank\">Software Nirvana: Titantic01</a>\n",
    "\n",
    "The material on my website and notebooks is intended to assist a beginner in Applied Machine Learning with Python, but it is not a course in machine learning.\n",
    "\n",
    "The intent of the series of notebooks is to illustrate general iterative model development techniques that apply to a wide range of datasets.\n",
    "\n",
    "The intent of this series of notebooks is not to optimize model creation specific to the Titanic dataset.  That Titanic dataset was chosen to provide a concrete example.\n",
    "\n",
    "Topics such as how to use Pandas will not be discussed.  However links to my Jupyter Notebooks which demonstrate the use of common Pandas methods will be presented.\n",
    "    \n",
    "* [github repo](https://github.com/sdiehl28/tutorial-jupyter-notebooks)  \n",
    "* [Pandas: Series](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Series.ipynb)  \n",
    "* [Pandas: Axis Specification](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/AxisSpecification.ipynb)  \n",
    "* [Pandas: DataFrame](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Dataframe.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Example\n",
    "Make a prediction for Survived / Not-Survived using the titanic dataset from Kaggle.  This is a supervised learning problem.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving:\n",
    "* the model's accuracy\n",
    "* the workflow used to create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Tentative Assumptions For 1st Iteration](#assumptions)\n",
    "4. [Model Building](#model)\n",
    "5. [Model Evaluation](#eval)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Create two variables from the data we read in.  \n",
    "X: Pandas DataFrame that represents the features (aka attributes)  \n",
    "y: Pandas Series that represents the target (aka response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n"
     ]
    }
   ],
   "source": [
    "# X: drop target variable\n",
    "# y: keep only the target\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  2\n",
      "y dimensions:  1\n"
     ]
    }
   ],
   "source": [
    "# ndim, as in numpy, reports the number of dimensions (e.g. 1D, 2D)\n",
    "print('X dimensions: ',X.ndim)\n",
    "print('y dimensions: ',y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_2D type:  <class 'numpy.ndarray'>\n",
      "y_2D shape:  (891, 1)\n",
      "y_2D dimensions:  2\n"
     ]
    }
   ],
   "source": [
    "# aside for later\n",
    "# y is a 1D object\n",
    "# sometimes we need its 2D equivalent: a 2D object having 1 column\n",
    "# using .values picks out the values as a numpy array\n",
    "# using reshape(-1,1) converts it to a 2D object having 1 column\n",
    "y_2D = y.values.reshape(-1,1)\n",
    "print('y_2D type: ', type(y_2D))\n",
    "print('y_2D shape: ', y_2D.shape)\n",
    "print('y_2D dimensions: ', y_2D.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assumptions\"></a>\n",
    "### 1st Iteration: Establish a Baseline Model\n",
    "[Back to Outline](#outline)  \n",
    "\n",
    "In order to quickly get something up and running, let's arbitrarily decide on the following for this iteration:\n",
    "* use LogisticRegression (as is common for classification problems)\n",
    "* drop ID field\n",
    "* drop all non-numeric features\n",
    "* drop any column having a null value\n",
    "* model evaluation metric: accuracy (auc is another good choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.198653\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.771044\n",
       "Embarked       0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of missing values per column\n",
    "nrows, ncols = X.shape\n",
    "X.isnull().sum() / nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp      int64\n",
       "Parch      int64\n",
       "Fare     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note Pclass is encoded as an integer, but it is actually an ordered categorial variable\n",
    "# Let's remove it as well\n",
    "drop_cols = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'Ticket', 'Cabin', 'Embarked']\n",
    "X.drop(drop_cols, axis=1, inplace = True)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Note: the decision to drop these columns did not depend on the data, therefore it is \"okay\" to do this prior to the train/test split.\n",
    "\n",
    "Had we decided to only keep columns that were correlated with the target, for example, this would require examining the data and would have to be performed after the train/test split.\n",
    "\n",
    "Link to stat prof anecdotal story."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building & Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "A train/test split will be used to demonstrate how to build and evaluate a model.\n",
    "\n",
    "Random_state will be set so that these results are repeatable.\n",
    "\n",
    "Cross validation will be used to get a more accurate estimate of accuracy than a single train/test split can provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6417910447761194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score will compute the accuarcy\n",
    "base_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy manually just to be sure we understand what score() is doing\n",
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143,  74],\n",
       "       [ 22,  29]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(predictions, y_test)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6417910447761194\n",
      "0.6417910447761194\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "base_model_accuracy = (143 + 29) / (143+74+22+29)\n",
    "print(base_model_accuracy)\n",
    "print((predictions == y_test).sum() / len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as above for base_model.score(), so the score is computing the accuracy.  \n",
    "\n",
    "Accuracy is sometimes referred to as:\n",
    "TP + TN / (TP + FP + TN + FN)\n",
    "\n",
    "Where \"Positive\" is arbitrarily defined to be \"Survived\"\n",
    "<pre>\n",
    "TP = True  Positive = confusion[0,0]  \n",
    "FP = False Positive = confusion[0,1]  \n",
    "TN = True Negative  = confusion[1,0]  \n",
    "FN = False Negative = confusion[1,1]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the above approach is that we took just one random train/test split.  To get a more accurate result we can perform multiple train/test splits using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 0.663\n"
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation,\n",
    " n_jobs=1)\n",
    "print('median: {:5.3f}'.format(np.median(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    165\n",
       "1    103\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with Simplest Possible Model Sometimes called the Null Model\n",
    "# Null Model Predicts predominant class every time\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Model Accuracy: 0.616\n"
     ]
    }
   ],
   "source": [
    "# Null Model Accuracy\n",
    "null_accuracy = 165 / (165 + 103)\n",
    "print('Null Model Accuracy: {:5.3f}'.format(null_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "66.3% is better than the null model accuracy 61.6%.  This is likely to be statistically significant.  A hypothesis test could be performed to see if it is, but that will not be done here.\n",
    "\n",
    "Here we will simply say that the Logistic Regression Model is worthwhile to continue using as we iteratively Kaizen the model building process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "The simple Logistic Regression model had a prediction accuracy of about 68%.  The null model which just predicts the most common class in all cases was accurate about 64% of the time.\n",
    "\n",
    "In this first iteration:\n",
    "* we quickly created a model\n",
    "* noted a few things to try to improve the model\n",
    "* established a baseline accuracy of 66.3%\n",
    "* showed that this accuracy is better than the null model accuracy of 61.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
