{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1<br/>*Establish a Baseline model*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Baseline Model (1)](https://sdiehl28.netlify.com/2018/03/baseline-model-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "1. Quickly create initial model and compare to null model.\n",
    "2. Demonstrate details of Scikit Learn methods such as cross_val_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Make a prediction for Survived / Not-Survived using the titanic dataset from Kaggle.  This is a supervised classification problem.\n",
    "\n",
    "The purpose of these notebooks is **not** to teach how to predict on the titanic dataset.  There are many Kaggle kernels available for that.  The purpose is to show iterative development in general along with specifics of how the Scikit Learn API works.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving:\n",
    "* the model's accuracy\n",
    "* the workflow used to create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Tentative Assumptions For 1st Iteration](#assumptions)\n",
    "4. [Model Building & Evaluation](#model)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Versions\n",
    "If your versions are earlier than shown below, you may need to upgrade your software to produce the same results.  On Linux, using the Anaconda distribution, this is done by:\n",
    "```\n",
    "source activate <env>\n",
    "conda update conda\n",
    "conda update --all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 18:21:58) \n",
      "[GCC 7.2.0]\n",
      "numpy:       1.14.2\n",
      "pandas:      0.22.0\n",
      "matplotlib:  2.2.2\n",
      "seaborn:     0.8.1\n",
      "sklearn:     0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "Note that this example is for supervised learning, so we will only deal with labeled data.  The labeled dataset is named \"train.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Create two variables from the data we read in preparation for creating a predictive model.  \n",
    "\n",
    "X: A Pandas DataFrame that represents the features (aka attributes)  \n",
    "y: A Pandas Series that represents the target (aka response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n",
      "X Type:  <class 'pandas.core.frame.DataFrame'>\n",
      "y Type:  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# X: drop target variable\n",
    "# y: keep only the target\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)\n",
    "print('X Type: ', type(X))\n",
    "print('y Type: ', type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  2\n",
      "y dimensions:  1\n"
     ]
    }
   ],
   "source": [
    "# ndim, as in numpy, reports the number of dimensions (e.g. 1D, 2D)\n",
    "print('X dimensions: ',X.ndim)\n",
    "print('y dimensions: ',y.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assumptions\"></a>\n",
    "### First Iteration Assumptions\n",
    "[Back to Outline](#outline)  \n",
    "\n",
    "In order to quickly get something up and running, let's arbitrarily decide upon the following:\n",
    "* use LogisticRegression\n",
    "* drop ID field\n",
    "* drop all non-numeric features\n",
    "* drop any column having a null value\n",
    "* model evaluation metric: accuracy\n",
    "\n",
    "Note that LogisticRegression requires all fields to be numeric and non-null.  Therefore we must either drop fields that don't meet these requirements or convert them to numeric fields.  Here we will drop them.  Later we will convert them to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of column names of type object\n",
    "drop_fields = list(X.dtypes.index[X.dtypes.values == 'object'].values)\n",
    "drop_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'PassengerId']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDs fields should almost never be features\n",
    "drop_fields.append('PassengerId')\n",
    "drop_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "Age       float64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all non-numeric fields and PassengerId\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "Age        True\n",
       "SibSp     False\n",
       "Parch     False\n",
       "Fare      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which fields have null values\n",
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "SibSp     False\n",
       "Parch     False\n",
       "Fare      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for 1st iteration only, remove all columns with null values\n",
    "X.dropna(axis=1, inplace=True)\n",
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "Examining the codebook (aka data dictionary) at: https://www.kaggle.com/c/titanic/data\n",
    "shows that Pclass is an ordered categorical variable that happens to be encoded as an integer.  Let's take a quick look at how survival is related to passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine percentage of survivors by class\n",
    "# Survived = 1, Not Survived = 0\n",
    "# mean() of Survived is the fraction that survived\n",
    "all_data.groupby(['Pclass'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that 63% of 1st class passengers survived, 47% of 2nd class passengers survived and 24% of 3rd class passengers survived.\n",
    "\n",
    "Passenger class is not a continuous variable.  The distance between 1st class and 2nd class is not the same as the distance between 2nd class and 3rd class; in fact, the distance is not defined.  Nevertheless for predictive modeling purposes, given that the ordinal encoding matches its association with the target variable, leaving it encoded as an integer is a good approach.\n",
    "\n",
    "Keep passenger class, which is an ordered categorical variable, encoded as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building & Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "A train/test split will be used to demonstrate how to build and evaluate a model.\n",
    "\n",
    "The random_state will be set so that these results are repeatable.\n",
    "\n",
    "Later, cross validation will be used to get a better estimate of the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "# stratify=y means that the train and test sets will have nearly the same percentage \n",
    "# of survived observations as exists in our targer vector y\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data  Survived Fraction: 0.38\n",
      "Train Set Survived Fraction: 0.38\n",
      "Test  Set Survived Fraction: 0.38\n"
     ]
    }
   ],
   "source": [
    "# let's verify that stratify=y worked as expected\n",
    "print('All Data  Survived Fraction: {:.2f}'.format(all_data['Survived'].mean()))\n",
    "print('Train Set Survived Fraction: {:.2f}'.format(y_train.mean()))\n",
    "print('Test  Set Survived Fraction: {:.2f}'.format(y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the percentage of survived passengers is the same in the entire data set, as it is in the train and test data sets, \"stratify=y\" worked as expected.  That is, it ensured the same frequency of each class value in each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model on Train Data Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model fitted on train data set to make predictions on test data set\n",
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305970149253731"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuarcy using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305970149253731\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy manually to be sure we understand accuracy_score()\n",
    "print((y_test == predictions).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that accuracy_score() gave us the same value as the determining the mean number of times the prediction for the test set was the same as the actual test set label.\n",
    "\n",
    "Although it may seem confusing at first to see mean() used to compute the percentage of True values in a boolean collection, it is a commonly used idiom.\n",
    "\n",
    "Let's look at the above single line computation in more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Python is a Strongly Typed Language\n",
    "Sometimes \"dynamic typing\" is conflated with weakly typed.  These are different concepts.  Python is a strongly typed language, therefore examining the types of objects is very helpful in understanding what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Collection Type:  <class 'numpy.ndarray'>\n",
      "Predictions Value Type:       int64\n",
      "Predictions Values:           [0 1]\n",
      "y_test Collection Type:       <class 'pandas.core.series.Series'>\n",
      "y_test Value Type:            int64\n",
      "y_test Values:                [0 1]\n",
      "Comparison Collection Type:   <class 'pandas.core.series.Series'>\n",
      "Comparison Value Type:        bool\n",
      "Comparison Values:            [ True False]\n",
      "Accuracy:                     0.6306\n"
     ]
    }
   ],
   "source": [
    "print('Predictions Collection Type: ', type(predictions))\n",
    "print('Predictions Value Type:      ', predictions.dtype)\n",
    "print('Predictions Values:          ', np.unique(predictions))\n",
    "print('y_test Collection Type:      ', type(y_test))\n",
    "print('y_test Value Type:           ', y_test.dtype)\n",
    "print('y_test Values:               ', y_test.unique())\n",
    "print('Comparison Collection Type:  ', type(predictions == y_test))\n",
    "print('Comparison Value Type:       ', (predictions == y_test).dtype)\n",
    "print('Comparison Values:           ', (predictions == y_test).unique())\n",
    "print('Accuracy:                     {:.4f}'.format((y_test == predictions).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So LogisticRegression's predict(), with default options, returns a numpy array of integer values with values of 0 or 1.  This numpy array can be compared, element by element, with a Pandas Series of integer values to produce a new Pandas Series of boolean values.  The mean of a boolean Series is defined as the number of True values divided by the number of non-null values, and gives the accuracy of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Accuracy, for a binary classification problem, is sometimes referred to as:\n",
    "(TN + TP) / (TN + FP + FN + TP)\n",
    "\n",
    "Where \"Positive\" in this example is \"Survived\"\n",
    "<pre>\n",
    "TP = True  Positive  \n",
    "FP = False Positive \n",
    "TN = True Negative  \n",
    "FN = False Negative\n",
    "</pre>\n",
    "\n",
    "For a binary classification problem, sklearn represents this [Confusion Matrix](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TN FP\n",
      " FN TP\n"
     ]
    }
   ],
   "source": [
    "# sklearn confusion matrix\n",
    "print(\"\",\"TN\", \"FP\\n\",\"FN TP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  39]\n",
      " [ 60  43]]\n"
     ]
    }
   ],
   "source": [
    "# For instructional purposes, let's derive the confusion matrix ourselves\n",
    "TN = ((y_test == 0) & (predictions == 0)).sum()\n",
    "FP = ((y_test == 0) & (predictions == 1)).sum()\n",
    "FN = ((y_test == 1) & (predictions == 0)).sum()\n",
    "TP = ((y_test == 1) & (predictions == 1)).sum()\n",
    "\n",
    "my_confusion_matrix = np.array([[TN, FP],[FN, TP]])\n",
    "print(my_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  39]\n",
      " [ 60  43]]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to compute the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our hand-coded and sklearn confusion matrix results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6306\n"
     ]
    }
   ],
   "source": [
    "# Alternative accuracy computation\n",
    "print('Accuracy: {:.4f}'.format((TN+TP)/(TN + FP + FN + TP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our single train/test split, we got an accuracy estimate of about 63.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Each time we randomly chose a different train and test subset of our data, we will get a different estimate of the model's accuracy.  If we do this only once, we risk having an unrepresentative train/test split.\n",
    "\n",
    "A better approach is to take several train/test splits and compute the accuracy of each.  This is what Cross Validation does.\n",
    "\n",
    "Good overview of cross validation and overfiting in Python: [Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "Good overview of cross validation and overfitting in general:\n",
    "* chapter 5.1 of [ISL](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "* The first 3 videos for Chapter 5 [ISL Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "k_folds = 5\n",
    "crossvalidation = KFold(n_splits=k_folds, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cross validated scores for each of the K=5 folds\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n",
      "Mean Cross Validated Score: 0.685\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(np.round(scores, 3))\n",
    "print(f'Mean Cross Validated Score: {scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine What cross_val_score() Did Behind the Scenes\n",
    "The [cross_val_score()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) helper function does a lot.  Let's do exactly the same thing by hand to verify we understand it.\n",
    "\n",
    "A [crossvalidation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) object is returned from the call to KFold.  [crossvalidation.split(X)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold.split) is an iterator which returns 2 numpy arrays, one set of indexes to define the train set and one set of indexes to define test set.\n",
    "\n",
    "Compute the accuracy score using the iterator and compare with cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative computation of cross validated scores\n",
    "my_scores = np.zeros(k_folds)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n",
      "Mean Cross Validated Score: 0.685\n",
      "Scores match:  True\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(np.round(my_scores, 3))\n",
    "print(f'Mean Cross Validated Score: {my_scores.mean():.3f}')\n",
    "\n",
    "# compare with scores computed by cross_val_score above\n",
    "print('Scores match: ',(scores == my_scores).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores match.  The computations are the same, however cross_val_score() required only 1 line of code whereas the alternative required more than 10 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Simplest Model\n",
    "For a classifier, predicting the predominant class is the simplest possible model.  This is sometimes referred to as the \"null model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62  0.652 0.579 0.601 0.629] 0.616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "null_model = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "scores = cross_val_score(null_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "print(np.round(scores, 3), np.round(scores.mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple LogisticRegression model has an estimated accuracy of 68.5% which is better than the null model which has an estimated accuracy of 61.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "Model building steps only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV Accuracy: 0.685\n"
     ]
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# create target and feature variables\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "\n",
    "# remove all fields of type object\n",
    "drop_fields = list(X.dtypes.index[X.dtypes.values == 'object'].values)\n",
    "\n",
    "# also remove the ID field\n",
    "drop_fields.append('PassengerId')\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "\n",
    "# remove the remaining column having null values\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "# create model instance\n",
    "base_model = LogisticRegression()\n",
    "\n",
    "# prepare for K=5 fold CV\n",
    "k_folds = 5\n",
    "crossvalidation = KFold(n_splits=k_folds, shuffle=True, random_state=5)\n",
    "\n",
    "# compute the 5 cross validated scores\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# print the mean score\n",
    "print(f'Mean CV Accuracy: {scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "In this first iteration we:\n",
    "* discussed how Scikit Learn computes accuracy, the confusion matrix, and cross validation scores\n",
    "* created a simple model to use as our baseline\n",
    "* established a baseline accuracy of 68.5%\n",
    "* showed that this accuracy is better than the null model accuracy of 61.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
