{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titantic Series of Notebooks\n",
    "A series of notebooks illustrating iterative model development.  See my website: <a href=\"https://sdiehl28.netlify.com/\" target=\"_blank\">Software Nirvana</a>\n",
    "\n",
    "The material on my website and notebooks is intended to assist a beginner in Applied Machine Learning, but it is not a course on Machine Learning.\n",
    "\n",
    "This series illustrates *general* Machine Learning techniques and is *not* intended to optimize model creation specific to the Titanic dataset.  The Titanic dataset was chosen to provide a well known concrete example.\n",
    "\n",
    "Topics such as how to use Pandas will not be discussed.  However links to my Jupyter Notebooks which demonstrate the use of common Pandas methods will be presented.\n",
    "    \n",
    "* [github repo](https://github.com/sdiehl28/tutorial-jupyter-notebooks)  \n",
    "* [Pandas: Series](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Series.ipynb)  \n",
    "* [Pandas: Axis Specification](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/AxisSpecification.ipynb)  \n",
    "* [Pandas: DataFrame](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Dataframe.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1: Establish a Baseline Model\n",
    "\n",
    "The first step is to quickly build a baseline model and establish an estimate of its accuarcy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Example\n",
    "Make a prediction for Survived / Not-Survived using the titanic dataset from Kaggle.  This is a supervised classification problem.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving:\n",
    "* the model's accuracy\n",
    "* the workflow used to create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Tentative Assumptions For 1st Iteration](#assumptions)\n",
    "4. [Model Building & Evaluation](#model)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Create two variables from the data we read in in order to create a predictive model.  \n",
    "\n",
    "X: A Pandas DataFrame that represents the features (aka attributes)  \n",
    "y: A Pandas Series that represents the target (aka response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n"
     ]
    }
   ],
   "source": [
    "# X: drop target variable\n",
    "# y: keep only the target\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  2\n",
      "y dimensions:  1\n"
     ]
    }
   ],
   "source": [
    "# ndim, as in numpy, reports the number of dimensions (e.g. 1D, 2D)\n",
    "print('X dimensions: ',X.ndim)\n",
    "print('y dimensions: ',y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_2D type:  <class 'numpy.ndarray'>\n",
      "y_2D shape:  (891, 1)\n",
      "y_2D dimensions:  2\n",
      "contents match:  True\n"
     ]
    }
   ],
   "source": [
    "# aside for later\n",
    "# y is a 1D object\n",
    "# sometimes we need its 2D equivalent: a 2D object having 1 column\n",
    "# using .values picks out the values as a numpy array\n",
    "# using reshape(-1,1) converts it to a 2D object having 1 column\n",
    "y_2D = y.values.reshape(-1,1)\n",
    "print('y_2D type: ', type(y_2D))\n",
    "print('y_2D shape: ', y_2D.shape)\n",
    "print('y_2D dimensions: ', y_2D.ndim)\n",
    "print('contents match: ',(y.values == y_2D.flatten()).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assumptions\"></a>\n",
    "### 1st Iteration Assumptions\n",
    "[Back to Outline](#outline)  \n",
    "\n",
    "In order to quickly get something up and running, let's arbitrarily decide upon the following:\n",
    "* use LogisticRegression (as is common for classification problems)\n",
    "* drop ID field\n",
    "* drop all non-numeric features\n",
    "* drop any column having a null value\n",
    "* model evaluation metric: accuracy (auc is another good choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-numeric and PassengerId as seen above\n",
    "drop_cols = ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "X = X.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    0.000000\n",
       "Age       0.198653\n",
       "SibSp     0.000000\n",
       "Parch     0.000000\n",
       "Fare      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of missing values per column\n",
    "nrows, ncols = X.shape\n",
    "X.isnull().sum() / nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Age as it has null values (for the 1st iteration only)\n",
    "drop_cols = ['Age']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the codebook (aka data dictionary) at: https://www.kaggle.com/c/titanic/data\n",
    "shows that Pclass is an ordered categorical variable that happens to be encoded as an integer.  Let's take a quick look at how survival is related to passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4a2805a1d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a2801f0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Survived', hue='Pclass', data=all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 means did not survive and 1 means survived.\n",
    "\n",
    "The above shows that 1st class passengers had a higher survival rate than 2nd class passengers who had a higher survival rate the 3rd class passengers.\n",
    "\n",
    "Passenger class is not a continuous variable.  The distance between 1st class and 2nd class is not the same as the distance between 2nd class and 3rd class; in fact, the distance is not defined.  Nevertheless for predictive modeling purposes, given that the ordinal encoding matches its association with the target variable, leaving it encoded as an integer is arguably acceptable.\n",
    "\n",
    "For now, let's keep passenger class encoded as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building & Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "A train/test split will be used to demonstrate how to build and evaluate a model.\n",
    "\n",
    "The random_state will be set so that these results are repeatable.\n",
    "\n",
    "Cross validation will be used to get a better estimate of the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "# for a single train/test split, with uneven target class distributions, statify=y is good\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model on Train Data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model fitted on train data to make predictions on test data\n",
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6305970149253731"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute accuarcy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305970149253731\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy manually to be sure we understand accuracy_score()\n",
    "# The following computes the mean number of True values, which is the precentage of True values\n",
    "print((predictions == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is sometimes referred to as:\n",
    "TP + TN / (TP + FP + TN + FN)\n",
    "\n",
    "Where \"Positive\" in this example is \"Survived\"\n",
    "<pre>\n",
    "TP = True  Positive  \n",
    "FP = False Positive \n",
    "TN = True Negative  \n",
    "FN = False Negative\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 39 \n",
      " 60 126\n"
     ]
    }
   ],
   "source": [
    "# For instructional purposes, let's derive the confusion matrix ourselves\n",
    "# Recall that y_test is the actual data from the test set\n",
    "TP = ((predictions == 1) & (y_test == 1)).sum()\n",
    "FP = ((predictions == 1) & (y_test == 0)).sum()\n",
    "FN = ((predictions == 0) & (y_test == 1)).sum()\n",
    "TN = ((predictions == 0) & (y_test == 0)).sum()\n",
    "print(TP, FP,\"\\n\",FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 39 \n",
      " 60 126\n"
     ]
    }
   ],
   "source": [
    "# Have sklearn compute the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "tn, fp, fn, tp = confusion.flatten() # see confusion matrix documentation\n",
    "print(tp, fp, \"\\n\", fn, tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our single train/test split, we got an accuracy estimate of 63.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "Each time we randomly chose a different train and test subset of our data, we will get a different estimate of the model's accuracy.  If we do this only once, we risk having an unrepresentative train/test split.\n",
    "\n",
    "A better approach is to take several train/test splits and compute the accuracy of each.  This is what Cross Validation does.\n",
    "\n",
    "Good overview of cross validation and overfiting in Python: [Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "Good overview of cross validation and overfitting in general:\n",
    "* chapter 5.1 of [ISL](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "* The first 3 videos for Chapter 5 [ISL Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, scoring='accuracy',\n",
    " n_jobs=1)\n",
    "print(np.round(scores, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine What Scikit Learn Did Behind the Scenes\n",
    "As per the documentation, [crossvalidation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) is an iterator which contains the indexes of the train and test subsets of the original data.\n",
    "\n",
    "Let's compute the accuracy score using the iterator to better understand the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726 0.708 0.635 0.674 0.68 ]\n",
      "Scores match:  True\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "my_scores = np.zeros(n_splits)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1\n",
    "print(np.round(my_scores, 3))\n",
    "print('Scores match: ',(scores == my_scores).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.685\n"
     ]
    }
   ],
   "source": [
    "# let's use the average of the CV score as the metric of base model performance\n",
    "print('average: {:5.3f}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    112\n",
       "1     66\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with Simplest Possible Model Sometimes called the Null Model\n",
    "# Null Model Predicts predominant class every time\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Model Accuracy: 0.616\n"
     ]
    }
   ],
   "source": [
    "# Null Model Accuracy\n",
    "null_accuracy = 165 / (165 + 103)\n",
    "print('Null Model Accuracy: {:5.3f}'.format(null_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "68.5% is better than the null model accuracy 61.6%.  This is likely to be statistically significant.  A hypothesis test could be performed to see if it is, but that will not be done here.\n",
    "\n",
    "Here we will simply say that our simple Logistic Regression Model appears to be off to a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "In this first iteration we:\n",
    "* discussed how Scikit Learn computes accuracy, the confusion matrix, and cross validation scores\n",
    "* created a simple model to use as our baseline\n",
    "* established a baseline accuracy of 68.5%\n",
    "* showed that this accuracy is better than the null model accuracy of 61.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
