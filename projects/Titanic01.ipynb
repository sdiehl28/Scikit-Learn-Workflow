{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1<br/>*Establish a Baseline model*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Baseline Model (1a)](http://localhost:1313/2018/03/baseline-model-1a/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "1. Create initial model\n",
    "2. Demonstrate details of Scikit Learn's cross_val_score(), confusion_matrix() and accuracy_score()\n",
    "4. Compare initial model to null model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Model Development\n",
    "In order to demonstrate iterative model development, the titanic dataset from Kaggle will be used.\n",
    "\n",
    "The purpose of these notebooks is **not** to teach how to predict on the titanic dataset!  There are many Kaggle kernels available for that.  The purpose of this series of notebooks is to illustrate iterative model development in general and to show the specifics of how various Scikit Learn methods work.\n",
    "\n",
    "The model will make a prediction for Survived / Not-Survived.  This is a supervised classification problem.\n",
    "\n",
    "Several notebooks will be created after this one.  Each iteratively improving:\n",
    "* the model's accuracy\n",
    "* the workflow used to create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Acquire and Read Data](#readdata)\n",
    "2. [Identify Target Variable](#target)\n",
    "3. [Tentative Assumptions For 1st Iteration](#assumptions)\n",
    "4. [Exploratory Data Analysis](#eda)\n",
    "5. [Model Building](#model)\n",
    "6. [Model Evaluation: Train/Test Split](#traintest)\n",
    "7. [Model Evaluation: Confusion Matrix](#confusion)\n",
    "8. [Model Evaluation: Cross Validation](#crossvalidation)\n",
    "9. [Model Summary](#modelsummary)\n",
    "0. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Versions\n",
    "If your versions are earlier than shown below, you may need to upgrade your software to produce the same results.  On Linux, using the Anaconda distribution, this is done by:\n",
    "```\n",
    "source activate <env>\n",
    "conda update conda\n",
    "conda update --all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 18:21:58) \n",
      "[GCC 7.2.0]\n",
      "numpy:       1.14.2\n",
      "pandas:      0.22.0\n",
      "matplotlib:  2.2.2\n",
      "seaborn:     0.8.1\n",
      "sklearn:     0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"readdata\"></a>\n",
    "### Acquire the Data\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Download \"train.csv\" from: https://www.kaggle.com/c/titanic/data and place it in a data subdirectory.\n",
    "\n",
    "This link also has the data dictionary (sometimes called the codebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "Note that this example is for supervised learning, so we will only deal with labeled data.  The labeled dataset is named \"train.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "all_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"target\"></a>\n",
    "### Target Variable: Survived\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Create two variables from the data we read in preparation for creating a predictive model.  \n",
    "\n",
    "X: A Pandas DataFrame that represents the features (aka attributes)  \n",
    "y: A Pandas Series that represents the target (aka response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n",
      "X Type:  <class 'pandas.core.frame.DataFrame'>\n",
      "y Type:  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# X: drop target variable\n",
    "# y: keep only the target\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)\n",
    "print('X Type: ', type(X))\n",
    "print('y Type: ', type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dimensions:  2\n",
      "y dimensions:  1\n"
     ]
    }
   ],
   "source": [
    "# ndim, as in numpy, reports the number of dimensions (e.g. 1D, 2D)\n",
    "print('X dimensions: ',X.ndim)\n",
    "print('y dimensions: ',y.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"assumptions\"></a>\n",
    "### First Iteration Assumptions\n",
    "[Back to Outline](#outline)  \n",
    "\n",
    "In order to quickly get something up and running, let's arbitrarily decide upon the following:\n",
    "* use LogisticRegression\n",
    "* drop ID field\n",
    "* drop all non-numeric features\n",
    "* drop any column having a null value\n",
    "* model evaluation metric: accuracy\n",
    "\n",
    "Note that LogisticRegression requires all fields to be numeric and non-null.  Therefore we must either drop fields that don't meet these requirements or convert them to numeric fields.  Here we will drop them.  Later we will convert them to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of column names of type object\n",
    "drop_fields = list(X.dtypes.index[X.dtypes.values == 'object'].values)\n",
    "drop_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'PassengerId']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDs fields should almost never be features\n",
    "drop_fields.append('PassengerId')\n",
    "drop_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "Age       float64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all non-numeric fields and PassengerId (1st iteration only)\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "Age        True\n",
       "SibSp     False\n",
       "Parch     False\n",
       "Fare      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which fields have null values\n",
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass    False\n",
       "SibSp     False\n",
       "Parch     False\n",
       "Fare      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all columns with null values (1st iteration only)\n",
    "X.dropna(axis=1, inplace=True)\n",
    "X.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eda\"></a>\n",
    "### Initial Exploratory Data Analysis\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Examining the codebook (aka data dictionary) at: https://www.kaggle.com/c/titanic/data\n",
    "shows that Pclass is an ordered categorical variable that happens to be encoded as an integer.  Let's take a quick look at how survival is related to passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine percentage of survivors by class\n",
    "# Survived = 1, Not Survived = 0\n",
    "# mean() of Survived is the fraction that survived\n",
    "all_data.groupby(['Pclass'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that 63% of 1st class passengers survived, 47% of 2nd class passengers survived and 24% of 3rd class passengers survived.\n",
    "\n",
    "Passenger class is not a continuous variable.  The distance between 1st class and 2nd class is not the same as the distance between 2nd class and 3rd class; in fact, the distance is not defined.  Nevertheless for predictive modeling purposes, given that the ordinal encoding matches its association with the target variable, leaving it encoded as an integer is a good approach.\n",
    "\n",
    "Keep passenger class, which is an ordered categorical variable, encoded as an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Initially we will evaluate the model based on a single train/test split.  As this is part of the model building process, it is discussed here.\n",
    "\n",
    "random_state is set so that the train/test split is always the same.  This allows anyone who executes this notebook to get the same results.  This is part of reproducible research.\n",
    "\n",
    "stratify=y is used so that our train/test split has the same ratio of survived/not-survived in the train and test data sets, as exists in the y response data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.30, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Data  Survived Fraction: 0.38\n",
      "Train Set Survived Fraction: 0.38\n",
      "Test  Set Survived Fraction: 0.38\n"
     ]
    }
   ],
   "source": [
    "# let's verify that stratify=y worked as expected\n",
    "print('All Data  Survived Fraction: {:.2f}'.format(y.mean()))\n",
    "print('Train Set Survived Fraction: {:.2f}'.format(y_train.mean()))\n",
    "print('Test  Set Survived Fraction: {:.2f}'.format(y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the percentage of survived passengers is about the same in the entire data set, as it is in the train and test data sets, \"stratify=y\" worked as expected.  That is, it ensured the same frequency of each class value in each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model on Train Data Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"traintest\"></a>\n",
    "### Model Evaluation: Train/Test Split\n",
    "[Back to Outline](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6305970149253731\n",
      "0.6305970149253731\n"
     ]
    }
   ],
   "source": [
    "# Use model fitted on train data set to make predictions on test data set\n",
    "predictions = base_model.predict(X_test)\n",
    "\n",
    "# Compute accuarcy using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))\n",
    "\n",
    "# Compute accuracy manually to be sure we understand accuracy_score()\n",
    "print((y_test == predictions).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that accuracy_score() gave us the same value as the determining the mean number of times the prediction for the test set was the same as the actual test set label.\n",
    "\n",
    "Although it may seem confusing at first to see mean() used to compute the percentage of True values in a boolean collection, it is a commonly used idiom.\n",
    "\n",
    "To fully understand what is happening, it is often helpful to look at the data types of the objects.  Let's look at the last line of code above in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions Collection Type:  <class 'numpy.ndarray'>\n",
      "Predictions Value Type:       int64\n",
      "Predictions Values:           [0 1]\n",
      "y_test Collection Type:       <class 'pandas.core.series.Series'>\n",
      "y_test Value Type:            int64\n",
      "y_test Values:                [0 1]\n",
      "Comparison Collection Type:   <class 'pandas.core.series.Series'>\n",
      "Comparison Value Type:        bool\n",
      "Comparison Values:            [ True False]\n",
      "Accuracy:                     0.6306\n"
     ]
    }
   ],
   "source": [
    "print('Predictions Collection Type: ', type(predictions))\n",
    "print('Predictions Value Type:      ', predictions.dtype)\n",
    "print('Predictions Values:          ', np.unique(predictions))\n",
    "print('y_test Collection Type:      ', type(y_test))\n",
    "print('y_test Value Type:           ', y_test.dtype)\n",
    "print('y_test Values:               ', y_test.unique())\n",
    "print('Comparison Collection Type:  ', type(predictions == y_test))\n",
    "print('Comparison Value Type:       ', (predictions == y_test).dtype)\n",
    "print('Comparison Values:           ', (predictions == y_test).unique())\n",
    "print('Accuracy:                     {:.4f}'.format((y_test == predictions).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that:\n",
    "* predictions, returned from predict(), is a numpy array of integers\n",
    "* y, the response (or target) variable, is a Pandas Series\n",
    "* comparisons between numpy arrays and Pandas Series are allowable\n",
    "* this comparison results in a Pandas Series of type bool\n",
    "* taking the mean of a boolean collection gives the percentage of True values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"confusion\"></a>\n",
    "### Model Evalutation: Confusion Matrix\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "For binary classification problems such as this, the following terms are often used:\n",
    "<pre>\n",
    "TP = True  Positive  \n",
    "FP = False Positive \n",
    "TN = True Negative  \n",
    "FN = False Negative\n",
    "</pre>\n",
    "\n",
    "Where \"positive\" in this example means \"Survived\".\n",
    "\n",
    "TP means we predicted survived and that passenger did survive.  \n",
    "FP means we predicted survived and the passenger did not survive.  \n",
    "TN means we predicted not-survived and the passenger did not survive.  \n",
    "FN means we predicted not-survived and the passenger did survive.\n",
    "\n",
    "Accuracy is the number of true prediction divided by the total number of predictions:\n",
    "(TN + TP) / (TN + FP + FN + TP)\n",
    "\n",
    "\n",
    "For a binary classification problem, sklearn represents this as a [Confusion Matrix](http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TN FP\n",
      " FN TP\n"
     ]
    }
   ],
   "source": [
    "# sklearn confusion matrix\n",
    "print(\"\",\"TN\", \"FP\\n\",\"FN TP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  39]\n",
      " [ 60  43]]\n"
     ]
    }
   ],
   "source": [
    "# For instructional purposes, let's derive the confusion matrix ourselves\n",
    "TN = ((y_test == 0) & (predictions == 0)).sum()\n",
    "FP = ((y_test == 0) & (predictions == 1)).sum()\n",
    "FN = ((y_test == 1) & (predictions == 0)).sum()\n",
    "TP = ((y_test == 1) & (predictions == 1)).sum()\n",
    "\n",
    "my_confusion_matrix = np.array([[TN, FP],[FN, TP]])\n",
    "print(my_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  39]\n",
      " [ 60  43]]\n"
     ]
    }
   ],
   "source": [
    "# Use sklearn to compute the confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, predictions)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our hand-coded and sklearn confusion matrix results are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6306\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy from Confusion Matrix\n",
    "print('Accuracy: {:.4f}'.format((TN+TP)/(TN + FP + FN + TP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we got the same accuarcy as before, about 63.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"crossvalidation\"></a>\n",
    "### Model Evaluation: Cross Validation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Each time we randomly chose a different train and test subset of our data, we will get a different estimate of the model's accuracy.  If we do this only once, we risk having an unrepresentative train/test split.\n",
    "\n",
    "A better approach is to take several train/test splits and compute the accuracy of each.  This is what Cross Validation does.\n",
    "\n",
    "Good overview of cross validation and overfiting in Python:\n",
    "* [Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "* [Learning Curves](https://www.dataquest.io/blog/learning-curves-machine-learning/)\n",
    "\n",
    "Good overview of cross validation and overfitting in general:\n",
    "* chapter 5.1 of [ISL](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "* The first 3 videos for Chapter 5 [ISL Videos](http://www.dataschool.io/15-hours-of-expert-machine-learning-videos/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      " [0.689 0.764 0.697 0.73  0.629 0.64  0.652 0.697 0.708 0.652]\n",
      "Cross Validated Accuracy: 0.686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Recommended Values are 5 or 10\n",
    "k_folds = 10\n",
    "\n",
    "# For repeatability\n",
    "random_seed=5\n",
    "\n",
    "# Create the K Cross Validation Train/Test Splits\n",
    "crossvalidation = KFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "# compute cross validated scores for each of the K=5 folds\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# print results\n",
    "print('Scores: \\n', np.round(scores, 3))\n",
    "print(f'Cross Validated Accuracy: {scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score()\n",
    "The [cross_val_score()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) helper function does a lot.  Let's do exactly the same thing by hand to verify we understand it.\n",
    "\n",
    "A [crossvalidation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) object is returned from the call to KFold.\n",
    "\n",
    "[crossvalidation.split(X)](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold.split) is an iterator which returns 2 numpy arrays, one set of indexes to define the train set and one set of indexes to define the test set.\n",
    "\n",
    "Compute the accuracy score using the iterator and compare with cross_val_score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      " [0.689 0.764 0.697 0.73  0.629 0.64  0.652 0.697 0.708 0.652]\n",
      "Cross Validated Accuracy: 0.686\n",
      "Scores match:  True\n"
     ]
    }
   ],
   "source": [
    "# Alternative computation of cross validated scores\n",
    "\n",
    "# From Above\n",
    "k_folds = 10\n",
    "random_seed=5\n",
    "crossvalidation = KFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "# Use crossvalidation iterator explicitly\n",
    "my_scores = np.zeros(k_folds)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    \n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1\n",
    "\n",
    "# print results\n",
    "print('Scores: \\n', np.round(scores, 3))\n",
    "print(f'Cross Validated Accuracy: {scores.mean():.3f}')\n",
    "\n",
    "# compare with scores computed by cross_val_score() above\n",
    "print('Scores match: ',(scores == my_scores).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores match.  The computations are the same, however cross_val_score() required only 1 line of code whereas the alternative required more than 10 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Simplest Model\n",
    "For a classifier, predicting the predominant class is the simplest possible model.  This is sometimes referred to as the \"null model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      " [0.6   0.64  0.629 0.674 0.551 0.607 0.607 0.596 0.64  0.618]\n",
      "Cross Validated Accuracy: 0.616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "k_folds = 10\n",
    "random_seed=5\n",
    "crossvalidation = KFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "null_model = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "\n",
    "null_model_scores = cross_val_score(null_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print('Scores: \\n', np.round(null_model_scores, 3))\n",
    "print(f'Cross Validated Accuracy: {null_model_scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random_state used for KFold() is the same for both our LogisticRegression model and the null model.  This means we computed the scores over the same train/test splits.  This means we can compare the differences in each value to see which did better for a given training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Diff Scores: \n",
      "[0.089 0.124 0.067 0.056 0.079 0.034 0.045 0.101 0.067 0.034]\n",
      "Mean diff: 0.070\n"
     ]
    }
   ],
   "source": [
    "diff_scores = scores - null_model_scores\n",
    "print(f'CV Diff Scores: \\n{np.round(diff_scores,3)}')\n",
    "print(f'Mean diff: {diff_scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f0b3a2f0710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=diff_scores)\n",
    "plt.axhline(0, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that every CV score was better for our simple Logistic Regression model than it was for the null model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"modelsummary\"></a>\n",
    "### Model Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Model building steps only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: \n",
      " [0.689 0.764 0.697 0.73  0.629 0.64  0.652 0.697 0.708 0.652]\n",
      "Cross Validated Accuracy: 0.686\n"
     ]
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# create target and feature variables\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "\n",
    "# remove all fields of type object\n",
    "drop_fields = list(X.dtypes.index[X.dtypes.values == 'object'].values)\n",
    "\n",
    "# also remove the ID field\n",
    "drop_fields.append('PassengerId')\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "\n",
    "# remove the remaining column having null values\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "# create model instance\n",
    "base_model = LogisticRegression()\n",
    "\n",
    "# Recommended Values are 5 or 10\n",
    "k_folds = 10\n",
    "\n",
    "# For repeatability\n",
    "random_seed=5\n",
    "\n",
    "# Create the K Cross Validation Train/Test Splits\n",
    "crossvalidation = KFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "# compute cross validated scores for each of the K=5 folds\n",
    "scores = cross_val_score(base_model, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# print results\n",
    "print('Scores: \\n', np.round(scores, 3))\n",
    "print(f'Cross Validated Accuracy: {scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Summary\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "In this first iteration we:\n",
    "* discussed how Scikit Learn computes accuracy, the confusion matrix, and cross validation scores\n",
    "* created a simple model to use as our baseline\n",
    "* established a baseline accuracy of 68.6%\n",
    "* created the simplest possible \"null model\" for comparison\n",
    "* showed that our baseline model accuracy (68.6%) is better than the null model (61.6%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
