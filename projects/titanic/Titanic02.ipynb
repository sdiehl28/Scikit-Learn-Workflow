{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 <br/>*Cross Validation: Right and Wrong*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Cross Validation](https://sdiehl28.netlify.com/projects/titanic/titanic02/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "1. Add Age to the model (requires imputation of missing values)\n",
    "2. Demonstrate the right and wrong way to perform Cross Validation\n",
    "3. Compare this model with the previous iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where We Are\n",
    "In the first iteration, we created a simple model and showed that the accuracy was better than the null model.  The null model is the model that predicts the predominant class in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next\n",
    "<a href=\"https://en.wikipedia.org/wiki/Imputation_(statistics)\">Imputation on Wikipedia</a>\n",
    "\n",
    "This iteration will use Age as an additional attribute for prediction.  Missing values for Age will be imputed.\n",
    "\n",
    "Special attention will be paid to avoid a common beginner's mistake, which is to use the test data when performing imputation or other preprocessing steps. The easiest way to ensure there is no \"data leakage\", is to use a Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Model Building Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "Age       float64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../../data/train.csv')\n",
    "\n",
    "# break up the dataframe into X and y\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "\n",
    "# As before, remove all non-numeric fields and PassengerId\n",
    "drop_fields = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'PassengerId']\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "[Cross Validation](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/projects/Titanic01.ipynb#crossvalidation) was discussed in the previous iteration.\n",
    "\n",
    "Here the goal is demonstrate cross validation within the context of imputing missing Age values.  The right way to do this, along with a common wrong way, are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Using Cross Validation the Right Way\n",
    "\n",
    "To a beginner, it can appear that using an Imputer and a Pipeline is a lot of extra work.  Why not just impute the Age prior to cross validation and be done with it?\n",
    "\n",
    "If you were to look at the [\"Kernels\"](https://www.kaggle.com/c/titanic/kernels?sortBy=votes&group=everyone&pageSize=20&competitionId=3136) on Kaggle posted for the Titanic dataset, you would see that most people do just that.  But this is bad practice.  It could lead to an estimate of model accuracy that is too high.  Using the test data for any type of data transformation, prior to training your model, is \"data leakage\".\n",
    "\n",
    "Scikit Learn correctly uses the mean of the **train** set as the replacement value for missing values in both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal is to show that CV setup correctly differs from CV setup incorrectly\n",
    "# k_folds should normally be 5 or 10.  It is 2 here to illustrate the goal.\n",
    "random_state = 121212\n",
    "k_folds = 2\n",
    "crossvalidation = StratifiedKFold(n_splits=k_folds, shuffle=True, \n",
    "                                  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores : [0.71524664 0.69213483]\n",
      "Cross Validated Accuracy: 0.704\n"
     ]
    }
   ],
   "source": [
    "# Use an Imputer and a Pipeline\n",
    "# Note: Age is the only column in X with null values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='mean')\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "classifier = make_pipeline(imputer, LogisticRegression())\n",
    "\n",
    "scores = cross_val_score(classifier, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=1)\n",
    "\n",
    "print('Scores :', scores)\n",
    "print(f'Cross Validated Accuracy: {scores.mean() :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Using Cross Validation the Right Way: Detail\n",
    "Using cross_val_score hides the key pedagogical point, so don't use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  True\n"
     ]
    }
   ],
   "source": [
    "random_state = 121212\n",
    "k_folds = 2\n",
    "crossvalidation = StratifiedKFold(n_splits=k_folds, shuffle=True, \n",
    "                                  random_state=random_state)\n",
    "\n",
    "my_scores = np.zeros(k_folds)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X,y):\n",
    "    \n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :].copy()\n",
    "    y_train = y[train_idx].copy()\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :].copy()\n",
    "    y_test = y[test_idx].copy()\n",
    "    \n",
    "    # find the average age on the train set\n",
    "    train_age_mean = X_train['Age'].mean()\n",
    "    \n",
    "    # Replace missing Age values in the train data\n",
    "    X_train.loc[X_train['Age'].isnull(), 'Age'] = train_age_mean\n",
    "    \n",
    "    # Replace missing Age values in the test data\n",
    "    # Key Point: missing value in Test data set replaced with mean of TRAIN data\n",
    "    X_test.loc[X_test['Age'].isnull(), 'Age'] = train_age_mean\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1\n",
    "    \n",
    "# Verify this is exactly the same as using cross_val_score\n",
    "print(\"Scores Match: \", (scores == my_scores).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Using Cross Validation The Wrong Way\n",
    "The wrong, but common way to do this is to impute age over the entire dataset and then estimate model accuracy using either a train/test split or cross validation.\n",
    "\n",
    "The purpose of using a train/test split or cross validation is to train the model on one set of data (the training set) and evaluate it on another set (the test data).  However if you impute age using the entire dataset, you are in effect building the model using the test data. This defeats the purpose of using a train/test split or cross validation and the result is that the estimate of model accuracy could be too high.\n",
    "\n",
    "In the following, I will show that the wrong way produces different results than the right way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  False\n",
      "Scores Diff:   0.0011\n"
     ]
    }
   ],
   "source": [
    "# Prior to Cross Validation:\n",
    "#   Impute the missing values as the mean of *all* data\n",
    "# This is \"data leakage\"!  Don't do this!\n",
    "# Replace all null Age values with the mean of all Age Values\n",
    "X.loc[X['Age'].isnull(), 'Age'] = X['Age'].mean()\n",
    "\n",
    "# Setup: same as above\n",
    "random_state = 121212\n",
    "k_folds = 2\n",
    "crossvalidation = StratifiedKFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_state)\n",
    "\n",
    "wrong_scores = cross_val_score(LogisticRegression(), X, y, \n",
    "                               cv=crossvalidation,\n",
    "                               scoring='accuracy', n_jobs=1)\n",
    "\n",
    "# We do *not* get the same scores as above!\n",
    "print(\"Scores Match: \", (scores == wrong_scores).all())\n",
    "print(\"Scores Diff:  \", np.round(scores.mean() - wrong_scores.mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing all the missing values, over both the train and test sets, prior to performing cross validation produced different results!  That said, the difference is very small and is not significant for **this particular** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation The Wrong Way: Discussion\n",
    "**What was wrong:** Used all data for imputation (did not have hold-out set).\n",
    "\n",
    "**What may happen:** Estimate of model accuracy may be too high.\n",
    "\n",
    "**Importance in Practice:  With *imputation*, this is usually not a problem** unless you have a very small amount of data on which to perform the imputation.  In the above, we saw it made almost no difference.\n",
    "\n",
    "**Importance in Practice:  With *feature selection*, this is usually a very serious problem** which leads to highly inflated values of model accuracy.  Feature selection is the process of determining which variables to include in the model.  If you use the entire dataset, and decide to keep variables based on some statistic of the data, such as correlation to the target variable, then you *must* use a Pipeline or otherwise ensure that you choice of variables to include is determined on a train set and evaluated separately on a test set.\n",
    "\n",
    "**Great Explanation and Story by Robert Tibshirani:**\n",
    "Robert Tibshirani, in the youtube video [Cross Validation: Right and Wrong](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf), explains the right and wrong way to perform cross validation in detail.  He also presents a wonderful story about a Ph.D. oral dissertation presenter filtering away variables *prior* to performing cross validation and the serious effect it had on his medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Score as per Previous Iterations\n",
    "In order to compare model performance between Jupyter notebooks, it is necessary to compute the model performance in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.689 0.7   0.697 0.685 0.742 0.697 0.73  0.652 0.674 0.75 ]\n",
      "Cross Validated Accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Same as for previous iterations to allow for comparison\n",
    "k_folds = 10\n",
    "random_seed=5\n",
    "crossvalidation = StratifiedKFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "scores = cross_val_score(classifier, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# save scores for comparison with another iteration\n",
    "np.save(\"../../data/iter02.data\", scores)\n",
    "\n",
    "print('Scores: ', np.round(scores, 3))\n",
    "print(f'Cross Validated Accuracy: {scores.mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Performance with Previous Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd13133ef0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in scores from 1st iteration\n",
    "first_iter_scores = np.load('../../data/iter01.data.npy')\n",
    "\n",
    "df = pd.DataFrame(data=list(zip(scores, first_iter_scores)),\n",
    "                  columns=['scores','first_iter_scores'])\n",
    "sns.boxplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same random_state was used for each iteration of the model.  This means that each of the 10 folds of the model was build and tested on exactly the same data.  This means that we can directly compare the corresponding scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.045 -0.022  0.     0.     0.022  0.022  0.022  0.034  0.045  0.067]\n"
     ]
    }
   ],
   "source": [
    "diff_scores = scores - first_iter_scores\n",
    "print(np.round(sorted(diff_scores),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fdd13146940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at differences\n",
    "sns.boxplot(y=diff_scores)\n",
    "plt.axhline(0, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Model wins:  6\n",
      "New Model ties:  2\n",
      "New Model loses: 2\n"
     ]
    }
   ],
   "source": [
    "# How many times is the new model better?\n",
    "print(f'New Model wins:  {(diff_scores > 0).sum()}')\n",
    "print(f'New Model ties:  {(diff_scores == 0).sum()}')\n",
    "print(f'New Model loses: {(diff_scores < 0).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above boxplot and paired comparisons of the scores, it appears the new model is slightly better.  The change we made was to impute the missing Age values by their mean value and make use of the Age value in the Logistic Regression Model.  It is reasonable that the model would improve with the addition of the Age variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary\n",
    "Model building steps only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.689 0.7   0.697 0.685 0.742 0.697 0.73  0.652 0.674 0.75 ]\n",
      "Cross Validated Accuracy: 0.702\n"
     ]
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../../data/train.csv')\n",
    "\n",
    "# break up the dataframe into X and y\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "\n",
    "# As before, remove all non-numeric fields and PassengerId\n",
    "drop_fields = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'PassengerId']\n",
    "X = X.drop(drop_fields, axis=1)\n",
    "\n",
    "k_folds = 10\n",
    "random_seed=5\n",
    "crossvalidation = StratifiedKFold(n_splits=k_folds, shuffle=True, \n",
    "                        random_state=random_seed)\n",
    "\n",
    "imputer = Imputer(strategy='mean')\n",
    "classifier = make_pipeline(imputer, LogisticRegression())\n",
    "scores = cross_val_score(classifier, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=1)\n",
    "\n",
    "# Use the mean score as the best estimate of model accuracy\n",
    "print('Scores: ', np.round(scores,3))\n",
    "print(f'Cross Validated Accuracy: {scores.mean() :.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Cross Validated Accuracy: 0.687\n"
     ]
    }
   ],
   "source": [
    "# previous model\n",
    "print(f'Previous Cross Validated Accuracy: {first_iter_scores.mean() :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this iteration we:\n",
    "* Added Age to the model\n",
    "* Imputed the missing Age values\n",
    "* Showed the right and wrong way to setup for cross validation\n",
    "* Used Imputation as part of a Pipeline, along with cross_val_score. This improves the quality of the software as it concisely performs cross validation correctly\n",
    "* slightly improved the model's accuracy from 68.7% to 70.2%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
