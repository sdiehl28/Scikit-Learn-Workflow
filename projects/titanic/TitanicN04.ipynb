{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Cross Validation<br/>*Right and Wrong*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "1. Standardize the variables (to use Logistic Regression's regularization properly)\n",
    "2. Demonstrate the right and wrong way to perform Cross Validation\n",
    "\n",
    "Before continuing with iterative model development, it is important to understand some of the subtleties of using Cross Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding Data Leakage\n",
    "There are two common statements made about model building and the test set.  The second statement includes the first.\n",
    "1. Never use the test set's target variable to build a model.\n",
    "2. Never use any part of the test set to build a model.\n",
    "\n",
    "The first statement is an absolute must.  If this is not done, the estimate of model performance could be very much too high.\n",
    "\n",
    "The second statement represents good practice. Although looking at some part of the test data other than the target variable might not affect the estimate of model performance very much, there is rarely a need to do so.\n",
    "\n",
    "The easiest way to ensure that there is no data leakage is to encapsulate all data transformation operations inside of a Pipe and use that pipe.\n",
    "\n",
    "Every Scikit Learn example I have reviewed on Scikit Learn which performs a data transformation, encapsulates that transformation inside of a pipe.  In other words, the Scikit Learn examples ensure that no part of the test data is being used to build a model.\n",
    "\n",
    "The reason for stressing this point is that *most* of the [kernels](https://www.kaggle.com/c/titanic/kernels) on Kaggle for the Titanic data set violate this rule.  A common example is to see all of the data standardized prior to starting the model building process.  This is poor practice even if it doesn't make much of a difference on the Titanic data set.\n",
    "\n",
    "Below Standardization will be performed the \"right way\" (using the equivalent of a pipe) and the \"wrong way\" (on all data up front) to show the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style\n",
    "\n",
    "import titanic_helper_code as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.7.3 (default, Mar 27 2019, 22:11:17) \n",
      "[GCC 7.3.0]\n",
      "numpy:       1.16.4\n",
      "pandas:      0.24.2\n",
      "matplotlib:  3.1.0\n",
      "seaborn:     0.9.0\n",
      "sklearn:     0.21.1\n",
      "Description:\tUbuntu 18.04.2 LTS\n"
     ]
    }
   ],
   "source": [
    "# Version Information\n",
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)\n",
    "!lsb_release -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Model Building Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from my titanic_helper_code.py\n",
    "def get_Xy_v1(filename='./data/train.csv'):\n",
    "    \"\"\"Data Encoding for Iteration 1\n",
    "\n",
    "    Version 1\n",
    "    * Pclass, Fare, and Sex encoded as 1/0 for female/male\n",
    "    \"\"\"\n",
    "\n",
    "    # read data\n",
    "    all_data = pd.read_csv(filename)\n",
    "    X = all_data.drop('Survived', axis=1)\n",
    "    y = all_data['Survived']\n",
    "    \n",
    "    # encode data\n",
    "    X['Sex'] = X['Sex'].replace({'female':1, 'male':0})\n",
    "    \n",
    "    # drop unused columns\n",
    "    drop_columns = ['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', \n",
    "                    'Ticket', 'Cabin', 'Embarked']\n",
    "    X = X.drop(drop_columns, axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = tt.get_Xy_v1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"crossvalidation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation: The Right Way\n",
    "The goal here is simply to show that there is a difference between computing the accuracy when no test data is looked at vs when some of the test data is looked at (but not the target variable).\n",
    "\n",
    "In order to show a difference in what follows, strong regularization is used, C=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a specific set of CV folds for repeatability\n",
    "cv_select = RepeatedStratifiedKFold(n_splits=2, n_repeats=10, random_state=108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Scores  min:0.757 max:0.813\n",
      "CV Mean Score: 0.784 +/- 0.017\n"
     ]
    }
   ],
   "source": [
    "# perform CV with transformation, without a pipe, to illustrate the concept\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "lr = LogisticRegression(penalty='l2', C=0.001, solver='liblinear')\n",
    "\n",
    "score_per_fold = []\n",
    "for train_idx, test_idx in cv_select.split(X,y):\n",
    "    \n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :]\n",
    "    y_train = y.iloc[train_idx]\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :]\n",
    "    y_test = y.iloc[test_idx]\n",
    "    \n",
    "    # standardize the variables on train\n",
    "    X_train_transformed = ss.fit_transform(X_train)\n",
    "    \n",
    "    # fit model on train\n",
    "    lr.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    # standardize variables on test\n",
    "    X_test_transformed = ss.transform(X_test) # do not call fit_transform!\n",
    "    \n",
    "    # predict using fitted model on test\n",
    "    predictions = lr.predict(X_test_transformed)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    fold_score = accuracy_score(y_test, predictions)\n",
    "    score_per_fold.append(fold_score)\n",
    "    \n",
    "scores = np.array(score_per_fold)\n",
    "tt.print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation: The Wrong Way\n",
    "The wrong, but common way to do this is to standardize the variables over the *entire* dataset and then estimate model accuracy using either a train/test split or cross validation.\n",
    "\n",
    "Below it is shown that there is a difference between performing CV correctly and incorrectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  False\n",
      "Scores Diff:   0.0029\n"
     ]
    }
   ],
   "source": [
    "# Prior to Cross Validation: standardize *all* the data up front\n",
    "# This is \"data leakage\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "wrong_scores = cross_val_score(lr, X_scaled, y, \n",
    "                               cv=cv_select, scoring='accuracy')\n",
    "\n",
    "# We do *not* get the same scores as above!\n",
    "print(\"Scores Match: \", (scores == wrong_scores).all())\n",
    "print(\"Scores Diff:  \", np.round(wrong_scores.mean() - scores.mean(), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Standardizing all the values prior to evaluating the model with cross validation led to an estimate of model performance that was slightly too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation The Wrong Way: Discussion\n",
    "**What was wrong:** Used all data for standardization.  That is, test data was used to compute the mean and standard deviation which was applied in the standarization transform.\n",
    "\n",
    "**What may happen:** Estimate of model accuracy may be too high.\n",
    "\n",
    "**With any transformation that does not look at the target variable, this might not be a problem.**  In the above, we saw that it made almost no difference.\n",
    "\n",
    "**With any transformation which does look at the target variable, as some variable selection procedures do, this may be a very serious problem** leading to highly inflated values of model accuracy.\n",
    "\n",
    "**Great Explanation and Story by Robert Tibshirani:**  \n",
    "Robert Tibshirani, in the youtube video [Cross Validation: Right and Wrong](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf), \n",
    "explains the right and wrong way to perform cross validation in detail.  \n",
    "\n",
    "In the video, he presents a story about a Ph.D. oral dissertation in which the presenter filtered away variables *prior* to cross validation, using correlations to the target variable, and the serious effect this had on his medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "**Best practice is to ensure that the entire model building process is encapsulated inside of cross validation.**  \n",
    "\n",
    "This is most easily accomplished by encapsulating all data transformation operations inside of a pipe, as will be shown in the next notebook.\n",
    "\n",
    "Note that certain mappings, such as encoding \"female\" as 1 and \"male\" as 0, are independent of any test data.  Such encodings need not be encapsulated within a pipe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
