{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow Iteration 2\n",
    "\n",
    "Content for my website: <a href=\"https://sdiehl28.netlify.com/\" target=\"_blank\">Software Nirvana</a>\n",
    "\n",
    "How to use Pandas methods will not be discussed here.  Here are links to notebooks I created to assist in understanding Pandas methods.  The material on my website and notebooks is intended to suppliment a course in machine learning, rather than be a course in machine learning.  \n",
    "* [github repo](https://github.com/sdiehl28/tutorial-jupyter-notebooks)  \n",
    "* [Pandas Series](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Series.ipynb)  \n",
    "* [Pandas Axes Specification](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/AxisSpecification.ipynb)  \n",
    "* [Pandas DataFrame](http://nbviewer.jupyter.org/github/sdiehl28/tutorial-jupyter-notebooks/blob/master/pandas/Dataframe.ipynb)  \n",
    "\n",
    "SD TODO: Ajust link to 1st iteration of workflow on blog  \n",
    "SD TODO: Define and/or provide link to \"test set data leakage\" and perhaps overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where We Are\n",
    "In the first iteration, we created a simple model and showed that the accuracy was better than the null model.  The null model being the model that predicts the predominant class in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next\n",
    "Refine any or all of the model building steps and measure the accuracy of the new model.\n",
    "\n",
    "Start by copying the previous notebook and renaming it.  For each reminder to ourself on what to try next from the previous iteration, try it.  In addition, more Exploratory Data Analysis would likely be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"outline\"></a>\n",
    "### Outline\n",
    "1. [Previous Iteration](#previous)\n",
    "2. [Exploratory Data Analysis](#eda)\n",
    "3. [Preprocessing](#preprocess)\n",
    "4. [Model Building](#model)\n",
    "5. [Model Evaluation](#eval)\n",
    "6. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Software Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:      3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 18:10:19) \n",
      "[GCC 7.2.0]\n",
      "numpy:       1.14.1\n",
      "pandas:      0.22.0\n",
      "matplotlib:  2.1.2\n",
      "seaborn:     0.8.1\n",
      "sklearn:     0.19.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('python:     ', sys.version)\n",
    "print('numpy:      ', np.__version__)\n",
    "print('pandas:     ', pd.__version__)\n",
    "import matplotlib\n",
    "print('matplotlib: ', matplotlib.__version__)\n",
    "print('seaborn:    ', sns.__version__)\n",
    "print('sklearn:    ', sk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (891, 11)\n",
      "y Shape:  (891,)\n"
     ]
    }
   ],
   "source": [
    "# break up the dataframe into X and y\n",
    "# X is a 2 dimensional \"spreadsheet\" of values used for prediction\n",
    "# y is a 1 dimensional vector of target (aka response) values\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "print('X Shape: ', X.shape)\n",
    "print('y Shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "### This Section Deals with a Subtle Train/Test Split Bug\n",
    "The train/test split should create *copies* of a dataframe rather than a view into a dataframe.  However in the version I am using, a view is returned for X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weakref at 0x7f53cb2067c8; to 'DataFrame' at 0x7f540481f8d0>\n",
      "<weakref at 0x7f53cb2067c8; to 'DataFrame' at 0x7f540481f8d0>\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.is_copy)\n",
    "print(X_test.is_copy)\n",
    "print(y_train.is_copy)\n",
    "print(y_test.is_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we see a weakref, this means we have a view.  That will cause problems with chained assignment later.  See: [Setting With Copy Warning](https://www.dataquest.io/blog/settingwithcopywarning/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shouldn't have to do this, but it ensures we have independent copies\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "y_train = y_train.copy()\n",
    "y_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X_train.is_copy)\n",
    "print(X_test.is_copy)\n",
    "print(y_train.is_copy)\n",
    "print(y_test.is_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is correct.  If DataFrame.is_copy is None, then we are not using a view into another DataFrame.\n",
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eda\"></a>\n",
    "### Exploratory Data Analysis\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "One of the first things to check for is **null values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.187801\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.776886\n",
       "Embarked       0.003210\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of missing values per column\n",
    "nrows, ncols = X_train.shape\n",
    "X_train.isnull().sum() / nrows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Value Analysis\n",
    "The following is a reasonable judgement call as to how to proceed based on the observed percentages of null values.\n",
    "1. The Age attribute has some missing values => impute missing values\n",
    "2. Most of the Cabin attribute is missing => remove it\n",
    "3. Very few Emarked records are missing => remove records with missing Emarked value\n",
    "\n",
    "Age imputation is likely to be helpful, however in this first iteration the goal is to quickly create a model for baseline purposes.\n",
    "\n",
    "Write a note to ourself and others about what to try next.\n",
    "\n",
    "**TODO: Try Age Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age Value\n",
    "For instructional purposes, to emphasize not looking at the test data, this this will be performed manually rather than using a Scikit Learn Imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a boolean Series where Age is null\n",
    "train_age_null = X_train['Age'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573   NaN\n",
       "697   NaN\n",
       "601   NaN\n",
       "709   NaN\n",
       "783   NaN\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify we did this correctly\n",
    "X_train.loc[train_age_null, 'Age'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset will be used to train model\n",
    "# Set the null Age values, in train, to the mean Age value, in train\n",
    "X_train.loc[train_age_null, 'Age'] = X_train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.787885375494064"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe the mean value\n",
    "X_train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573    29.787885\n",
       "697    29.787885\n",
       "601    29.787885\n",
       "709    29.787885\n",
       "783    29.787885\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that the values that were null are now the mean\n",
    "X_train.loc[train_age_null, 'Age'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Test Set Null Age Values with Mean from *Train* Set\n",
    "This step is key to understanding how to avoid \"test set data leakage\".  If we look at the data in the test set, in any way, it no longer acts as a test set.\n",
    "\n",
    "We must replace null values in the test set with the mean from the *train* set without looking at any of the values in the *test* set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset will be used to evaluate the model's accuracy\n",
    "# Set the null Age values, in test, to the mean Age value, in train\n",
    "test_age_null = X_test['Age'].isnull()\n",
    "X_test.loc[test_age_null, 'Age'] = X_train['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584    29.787885\n",
       "411    29.787885\n",
       "826    29.787885\n",
       "384    29.787885\n",
       "692    29.787885\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check that the values that were null are now the mean\n",
    "X_test.loc[test_age_null, 'Age'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Imputation\n",
    "It is critical to understand that we replaced null values in the test set with values computed from the train set.  We never looked at the data in test set\n",
    "\n",
    "Although we did not use Scikit Learn's imputer, it does exactly this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Datatypes\n",
    "Often this involves converting text or integers to categorical variables.\n",
    "\n",
    "Based on a review of the data dictionary at [titanic](https://www.kaggle.com/c/titanic/data), and an examination of the values of each column, the following variables need to be converted to categorical:\n",
    "\n",
    "** TODO: convert the following variables to categorical **\n",
    "* Pclass\n",
    "* Sex\n",
    "* Embarked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2nd Iteration only, ignore all text and categorical variables\n",
    "X_train = X_train.drop('Pclass', axis=1)\n",
    "X_test = X_test.drop('Pclass', axis=1)\n",
    "X_train = X_train.drop('Name', axis=1)\n",
    "X_test = X_test.drop('Name', axis=1)\n",
    "X_train = X_train.drop('Sex', axis=1)\n",
    "X_test = X_test.drop('Sex', axis=1)\n",
    "X_train = X_train.drop('Ticket', axis=1)\n",
    "X_test = X_test.drop('Ticket', axis=1)\n",
    "X_train = X_train.drop('Embarked', axis=1)\n",
    "X_test = X_test.drop('Embarked', axis=1)\n",
    "X_train = X_train.drop('Cabin', axis=1)\n",
    "X_test = X_test.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A natural question to ask is, wouldn't it have been easier to drop these columns prior\n",
    "to creating the train/test split so we wouldn't have to apply the same operation (drop column) to one?  The answer is \"yes\", but the proper way to do this, while ensuring no \"test data leakage\", is by way of pipelines and that will be discussed in a subsequent notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the datatypes of each remaining column\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"preprocess\"></a>\n",
    "### Preprocessing\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Preprocessing was done \"inline\" with the Exploratory Data Analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"model\"></a>\n",
    "### Model Building\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "Perhaps the simplest model to try for classification of two classes (Survived, Not-Survived) is Logistic Regression.\n",
    "\n",
    "Special techniques are required if one class is much more rare than another.  Let's check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's close enough to \"even\" for this first iteration.  Logistic Regression may work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "base_model = LogisticRegression()\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"eval\"></a>\n",
    "### Model Evaluation\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "The simplest measure of \"model value\" (to the business or end user) is the percent of correct predictions.  Assuming that the cost of a false positive is equal to the cost of a false negative, \"accuracy\" is a good measure of model value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = base_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155,  69],\n",
       "       [ 16,  28]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6828358208955224\n"
     ]
    }
   ],
   "source": [
    "# Compute Accuracy\n",
    "base_model_accuracy = (155 + 28) / (155+69+16+28)\n",
    "print(base_model_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    171\n",
       "1     97\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with Simplest Possible Model Sometimes called the Null Model\n",
    "# Null Model Predicts predominant class every time\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6380597014925373\n"
     ]
    }
   ],
   "source": [
    "# Null Model Accuracy\n",
    "null_accuracy = 171 / (171 + 97)\n",
    "print(null_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"summary\"></a>\n",
    "### Conclusion\n",
    "[Back to Outline](#outline)\n",
    "\n",
    "The simple Logistic Regression model had a prediction accuracy of about 68%.  The null model which just predicts the most common class in all cases was accurate about 64% of the time.\n",
    "\n",
    "In this first iteration:\n",
    "* we quickly created a model\n",
    "* noted a few things to try to improve the model\n",
    "* established a baseline accuracy of 68%\n",
    "* showed that this accuracy is better than the null model accuracy of 64%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
