{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Model Dev 2 <br/>*Imputation and Cross Validation*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Iterative Dev 2](https://sdiehl28.netlify.com/2018/02/iterative-model-dev-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where We Are\n",
    "In the first iteration, we created a simple model and showed that the accuracy was better than the null model.  The null model is the model that predicts the predominant class in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next\n",
    "<a href=\"https://en.wikipedia.org/wiki/Imputation_(statistics)\">Imputation on Wikipedia</a>\n",
    "\n",
    "This notebook will impute the missing values for Age and use Age as an additional attribute for prediction.  We will also check to see if adding the Age variable improved prediction accuracy.\n",
    "\n",
    "Special attention will be paid to avoid a common beginner's mistake, which is to look at the test data when performing imputation or other preprocessing steps.  The easiest way to ensure there is no \"test set leakage\", is to use a Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "Age       float64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# break up the dataframe into X and y\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "\n",
    "# As before, remove all non-numeric fields and PassengerId\n",
    "drop_cols = ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Cross Validation the Right Way\n",
    "This will be performed manually to emphasize how preprocessing operations work on the folds in a cross validation.  The key is that the held-out data, aka the test data, can never be looked at.\n",
    "\n",
    "This will also be performed with an Imputer and a Pipeline to show a more concise workflow.\n",
    "\n",
    "To a beginner, it can appear that using an Imputer and a Pipeline is a lot of extra work.  Why not just impute the Age before cross validation and be done with it.  If you were to look that at the [\"Kernels\"](https://www.kaggle.com/c/titanic/kernels?sortBy=votes&group=everyone&pageSize=20&competitionId=3136) on Kaggle posted for the Titantic dataset, you would see that at least half the people do just that.  But this is bad practice and can lead to an estimate of model accuracy that is too high.  Looking at the test data prior to training your model is called \"data leakage\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age without using Pipeline\n",
    "A nice introduction to overfitting, train/test split, and cross validation in Python is:[Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "K-Fold Cross Validation *is* train/test split, but performed K times to get a more accurate estimate of model accuracy.\n",
    "\n",
    "We train the model on the train data and we test the accuracy of the model on the test data.\n",
    "\n",
    "With a train/test split, we have missing Age values in both the train and test sets.  \n",
    "\n",
    "For the train set, we replace the missing values with the average Age of the train set.  \n",
    "\n",
    "For the test set, we are not permitted to look at its data as the purpose of the test set is for model evaluation.  If we look at its data, we have made the mistake of \"data leakage\".  The test data has \"leaked\" into our training data as part of our model building process.  This may cause our estimate of model accuracy to be too high.  For the test set, we replace the missing values with the average Age of the *train* set. \n",
    "\n",
    "All of the above holds true for Cross Validation as well, as Cross Validation is just multiple train/test splits.\n",
    "\n",
    "For each of the K folds, we will compute the mean Age value in the train set, and use that value to replace the missing values in both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random_state to get the same folds each time we call KFold()\n",
    "random_state = 121212\n",
    "\n",
    "# use low number of splits for illustration, 5 or 10 is the recommended value\n",
    "n_splits = 2\n",
    "\n",
    "# create K folds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the K folds to impute Age and compute the accuracy score\n",
    "my_scores = np.zeros(n_splits)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :].copy()\n",
    "    y_train = y[train_idx].copy()\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :].copy()\n",
    "    y_test = y[test_idx].copy()\n",
    "    \n",
    "    # find the average age on the train set\n",
    "    train_age_mean = X_train['Age'].mean()\n",
    "    \n",
    "    # use this value for *both* the train and test set\n",
    "    X_train.loc[X_train['Age'].isnull(), 'Age'] = train_age_mean\n",
    "    X_test.loc[X_test['Age'].isnull(), 'Age'] = train_age_mean # Key Concept!\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Pandas copy\n",
    "In the above, we had to use .copy() for our train and test sets.  This is critical to avoiding the Pandas warning: SettingWithCopyWarning.\n",
    "\n",
    "The imputation requires us to modify both the train and test sets for X.  However X.iloc[] returns a *view* into X, not a copy of a subset of X.  If we try to use this view to modify data, we will get: SettingwithCopyWarning.\n",
    "\n",
    "In most cases this warning means your code will not do what you intended.  Therefore you should always write code that does not produce this Pandas warning.\n",
    "\n",
    "It can be difficult to discover why this warning was issued.  One way to track this down is to print out the .is_copy member of your dataframe.  If you find you get this warning when trying to modify data through a view (implemented as a weak reference) then you need to get an independent copy of your data using .copy() and the warning will go away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weakref at 0x7fbcc8c5c4a8; to 'DataFrame' at 0x7fbccb7c0be0>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[train_idx, :].is_copy) # view into dataframe\n",
    "print(X.iloc[train_idx, :].copy().is_copy) # independent copy of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age with Pipeline\n",
    "Scikit Learn correctly uses the mean of the train set as the replacement value for missing values in the test set.  However this is all done behind the scenes.  The following is exactly the same as the above, but requires much less code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: same as above\n",
    "random_state = 121212\n",
    "n_splits = 2\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, \n",
    "                        random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  True\n",
      "[0.70852018 0.69438202] 0.7014511009220538\n"
     ]
    }
   ],
   "source": [
    "# Use an Imputer and a Pipeline\n",
    "# Note: Age is the only column in X with null values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='mean')\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "classifier = make_pipeline(imputer, LogisticRegression())\n",
    "\n",
    "# cross_val_score() will properly compute \n",
    "# imputation and score per fold\n",
    "scores = cross_val_score(classifier, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=1)\n",
    "\n",
    "# Check to see that we got the same scores \n",
    "# as in the above for-loop\n",
    "print(\"Scores Match: \", (scores == my_scores).all())\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Methods Produce the Same Result\n",
    "The for-loop over each K fold train/test splits is the same as using an Imputer and LogisticRegression in a Pipeline in cross_val_score()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Cross Validation The Wrong Way\n",
    "In my review of Kaggle Kernels published for the Titantic dataset about half of the [\"Kernels\"](https://www.kaggle.com/c/titanic/kernels?sortBy=votes&group=everyone&pageSize=20&competitionId=3136) imputed the Age value over the entire data set.  This is a potentially serious mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to Cross Validation:\n",
    "#   impute the missing values as the mean of all the data\n",
    "# Don't do this!  This is \"data leakage\"!\n",
    "# Replace all null Age values with the mean of all Age Values\n",
    "X.loc[X['Age'].isnull(), 'Age'] = X['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: same as above\n",
    "random_state = 121212\n",
    "n_splits = 2\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, \n",
    "                        random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross_val_score()\n",
    "wrong_scores = cross_val_score(LogisticRegression(), X, y, \n",
    "                               cv=crossvalidation,\n",
    "                               scoring='accuracy', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  False\n",
      "[0.70852018 0.69438202] 0.7014511009220538\n"
     ]
    }
   ],
   "source": [
    "# We do *not* get the same scores as above\n",
    "# because we did the cross validation wrong!\n",
    "print(\"Scores Match: \", (scores == wrong_scores).all())\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing all the missing values, over both the train and test sets, prior to performing cross validation produced different results!\n",
    "\n",
    "The use of the Imputer and estimator in the Pipeline, or the hand coded for-loop over the K folds, produced the correct result.\n",
    "\n",
    "For this dataset, the difference is very little and I had to use n_splits=2 and try a few different random_state values to get folds which illustrate this difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation The Wrong Way: Discussion\n",
    "**What was wrong:** Used both train and test data for imputation. \n",
    "\n",
    "**What may happen:** Estimate of model accuracy may be too high.\n",
    "\n",
    "**Importance in Practice:** With imputation, this is often not much of an issue if the amount of data from which to perform the imputation is large. Nevertheless, there is no point in making a potentially serious error when using Pipelines makes it easy to do this correctly.\n",
    "\n",
    "**Common Real Life Situation with Serious Consequences:**\n",
    "If you have a lot of variables, and you decide, prior to performing cross validation, that you will remove some of the variables based on some statistic of the data, such as too little correlation with the target variable, then you will almost certainly overfit your model.  That is, your report of model accuracy will be too high.\n",
    "\n",
    "**Great Explanation and Story by Robert Tibshirani:**\n",
    "Robert Tibshirani, in the youtube video [Cross Validation: Right and Wrong](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf), explains the above in detail and presents a wonderful anecdotal story about a Ph.D. oral dissertation presenter filtering away variables prior to performing cross validation and the serious effect it had on his medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this iteration we:\n",
    "* showed the right and wrong way to perform cross validation\n",
    "* showed that using Pipelines with Cross Validation improves the quality of the software by making it easy to concisely perform cross validation correctly.\n",
    "* added the Age variable to our model and used it's mean to impute missing values\n",
    "* showed that our estimate of model accuracy increased from 68.5% to 70.1%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
