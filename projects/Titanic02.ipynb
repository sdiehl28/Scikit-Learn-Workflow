{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2 <br/>*Imputation and Cross Validation*\n",
    "\n",
    "Jupyter Notebook referenced from my website:\n",
    "[Software Nirvana: Cross Validation (2)](https://sdiehl28.netlify.com/2018/03/cross-validation-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "1. Iteratively improve upon model using Age Imputation\n",
    "2. Demonstrate the right and wrong way to perform Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where We Are\n",
    "In the first iteration, we created a simple model and showed that the accuracy was better than the null model.  The null model is the model that predicts the predominant class in all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Next\n",
    "<a href=\"https://en.wikipedia.org/wiki/Imputation_(statistics)\">Imputation on Wikipedia</a>\n",
    "\n",
    "This notebook will impute the missing values for Age and use Age as an additional attribute for prediction.  We will also check to see if adding the Age variable improved prediction accuracy.\n",
    "\n",
    "Special attention will be paid to avoid a common beginner's mistake, which is to look at the test data when performing imputation or other preprocessing steps.  The easiest way to ensure there is no \"test set leakage\", is to use a Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Imports and Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "%matplotlib inline\n",
    "sns.set() # enable seaborn style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Model Building Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "Age       float64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Fare      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the labeled data\n",
    "all_data = pd.read_csv('../data/train.csv')\n",
    "\n",
    "# break up the dataframe into X and y\n",
    "X = all_data.drop('Survived', axis=1)\n",
    "y = all_data['Survived']\n",
    "\n",
    "# As before, remove all non-numeric fields and PassengerId\n",
    "drop_cols = ['PassengerId', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
    "X = X.drop(drop_cols, axis=1)\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Cross Validation the Right Way\n",
    "This will be performed manually to emphasize how preprocessing operations work on the folds in a cross validation.  The key is that the held-out data, aka the test data, can never be looked at.\n",
    "\n",
    "Later this will also be performed with an Imputer and a Pipeline to show a more concise workflow.\n",
    "\n",
    "To a beginner, it can appear that using an Imputer and a Pipeline is a lot of extra work.  Why not just impute the Age before cross validation and be done with it.  If you were to look that at the [\"Kernels\"](https://www.kaggle.com/c/titanic/kernels?sortBy=votes&group=everyone&pageSize=20&competitionId=3136) on Kaggle posted for the Titantic dataset, you would see that at least half the people do just that.  But this is bad practice and can lead to an estimate of model accuracy that is too high.  Looking at the test data prior to training your model is called \"data leakage\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age without using Pipeline\n",
    "A nice introduction to overfitting, train/test split, and cross validation in Python is:[Train/Test Split and Cross Validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
    "\n",
    "K-Fold Cross Validation *is* train/test split, but performed K times to get a more accurate estimate of model accuracy.\n",
    "\n",
    "We train the model on the train data and we test the accuracy of the model on the test data.\n",
    "\n",
    "With a train/test split, we have missing Age values in both the train and test sets.  \n",
    "\n",
    "For the train set, we replace the missing values with the average Age of the train set.  \n",
    "\n",
    "For the test set, we are not permitted to look at its data as the purpose of the test set is for model evaluation.  If we look at its data, we have made the mistake of \"data leakage\".  The test data has \"leaked\" into our training data as part of our model building process.  This may cause our estimate of model accuracy to be too high.  For the test set, we replace the missing values with the average Age of the *train* set. \n",
    "\n",
    "All of the above holds true for Cross Validation as well, as Cross Validation is just multiple train/test splits.\n",
    "\n",
    "For each of the K folds, we will compute the mean Age value in the train set, and use that value to replace the missing values in both the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random_state to get the same folds each time we call KFold()\n",
    "random_state = 121212\n",
    "\n",
    "# use low number of splits for illustration, 5 or 10 is the recommended value\n",
    "n_splits = 2\n",
    "\n",
    "# create K folds\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the K folds to impute Age and compute the accuracy score\n",
    "my_scores = np.zeros(n_splits)\n",
    "i = 0\n",
    "lr_model = LogisticRegression()\n",
    "for train_idx, test_idx in crossvalidation.split(X):\n",
    "    # train subset\n",
    "    X_train = X.iloc[train_idx, :].copy()\n",
    "    y_train = y[train_idx].copy()\n",
    "    \n",
    "    # test subset\n",
    "    X_test = X.iloc[test_idx, :].copy()\n",
    "    y_test = y[test_idx].copy()\n",
    "    \n",
    "    # find the average age on the train set\n",
    "    train_age_mean = X_train['Age'].mean()\n",
    "    \n",
    "    # use this value for *both* the train and test set\n",
    "    X_train.loc[X_train['Age'].isnull(), 'Age'] = train_age_mean\n",
    "    X_test.loc[X_test['Age'].isnull(), 'Age'] = train_age_mean # Key Concept!\n",
    "    \n",
    "    # fit model on train\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict using model on test\n",
    "    predictions = lr_model.predict(X_test)\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    my_scores[i] = accuracy_score(y_test, predictions)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Pandas copy\n",
    "In the above, we had to use .copy() for our train and test sets.  This is critical to avoiding the Pandas warning: SettingWithCopyWarning.\n",
    "\n",
    "The imputation requires us to modify both the train and test sets for X.  However X.iloc[] returns a *view* into X, not a copy of a subset of X.  If we try to use this view to modify data, we will get: SettingwithCopyWarning.\n",
    "\n",
    "In most cases this warning means your code will not do what you intended.  Therefore you should always write code that does not produce this Pandas warning.\n",
    "\n",
    "It can be difficult to discover why this warning was issued.  One way to track this down is to print out the .is_copy member of your dataframe.  If you find you get this warning when trying to modify data through a view (implemented as a weak reference) then you need to get an independent copy of your data using .copy() and the warning will go away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<weakref at 0x7fe50083fef8; to 'DataFrame' at 0x7fe50342e0b8>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[train_idx, :].is_copy) # view into dataframe\n",
    "print(X.iloc[train_idx, :].copy().is_copy) # independent copy of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age with Pipeline\n",
    "Scikit Learn correctly uses the mean of the train set as the replacement value for missing values in the test set.  However this is all done behind the scenes.  The following is exactly the same as the above, but requires much less code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: same as above\n",
    "random_state = 121212\n",
    "n_splits = 2 # for illustration only, 5 or 10 is the recommended value\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, \n",
    "                        random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  True\n",
      "[0.70852018 0.69438202] 0.7014511009220538\n"
     ]
    }
   ],
   "source": [
    "# Use an Imputer and a Pipeline\n",
    "# Note: Age is the only column in X with null values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='mean')\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "classifier = make_pipeline(imputer, LogisticRegression())\n",
    "\n",
    "# cross_val_score() will properly compute \n",
    "# imputation and score per fold\n",
    "scores = cross_val_score(classifier, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=1)\n",
    "\n",
    "# Check to see that we got the same scores \n",
    "# as in the above for-loop\n",
    "print(\"Scores Match: \", (scores == my_scores).all())\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Methods Produce the Same Result\n",
    "The for-loop over each K fold train/test split is the same as using an Imputer and LogisticRegression in a Pipeline in cross_val_score()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Age: Cross Validation The Wrong Way\n",
    "In my review of Kaggle Kernels published for the Titantic dataset about half of the [\"Kernels\"](https://www.kaggle.com/c/titanic/kernels?sortBy=votes&group=everyone&pageSize=20&competitionId=3136) imputed the Age value over the entire data set, that is, they had \"data leakage\".\n",
    "\n",
    "It turns out that with imputation, \"data leakage\" usually doesn't matter even though it is incorrect and may produce a different estimate of the model accuracy.  If you decide to impute missing values using your entire dataset, you should at least make a note that you are \"cheating\", but that you expect it to make little difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior to Cross Validation:\n",
    "#   impute the missing values as the mean of all the data\n",
    "# This is \"data leakage\"!\n",
    "# Replace all null Age values with the mean of all Age Values\n",
    "X.loc[X['Age'].isnull(), 'Age'] = X['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: same as above\n",
    "random_state = 121212\n",
    "n_splits = 2 # for illustration only, 5 or 10 is the recommended value\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, \n",
    "                        random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross_val_score()\n",
    "wrong_scores = cross_val_score(LogisticRegression(), X, y, \n",
    "                               cv=crossvalidation,\n",
    "                               scoring='accuracy', n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Match:  False\n",
      "[0.70627803 0.69662921] 0.7014536201944879\n",
      "[0.70852018 0.69438202] 0.7014511009220538\n"
     ]
    }
   ],
   "source": [
    "# We do *not* get the same scores as above\n",
    "# because we set up the cross validation wrong!\n",
    "print(\"Scores Match: \", (scores == wrong_scores).all())\n",
    "print(wrong_scores, wrong_scores.mean())\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing all the missing values, over both the train and test sets, prior to performing cross validation produced different results!  That said, the difference was not statistically significant.  In fact, I had to use n_splits=2 just to demonstrate that a difference was possible on this dataset.\n",
    "\n",
    "The use of the Imputer and estimator in the Pipeline, or the hand coded for-loop over the K folds, produced the correct result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation The Wrong Way: Discussion\n",
    "**What was wrong:** Used all data for imputation (did not have hold-out set).\n",
    "\n",
    "**What may happen:** Estimate of model accuracy may be too high.\n",
    "\n",
    "**Importance in Practice:  With *imputation*, this is usually not a problem** unless you have a very small amount of data on which to perform the imputation.  In the above, we saw it made almost no difference whatsoever.\n",
    "\n",
    "**Importance in Practice:  With *feature selection*, this is usually a very serious problem** that leads to highly inflated values of model accuracy.  Feature selection is the process of determining which variables to include in the model.  If you use the entire dataset, and decide to keep variables based on some statistic of the data, such as correlation to the target variable, then you *must* use a Pipeline or otherwise ensure that you choice of variables is determined on a train set and evaluated on a test set.\n",
    "\n",
    "**Great Explanation and Story by Robert Tibshirani:**\n",
    "Robert Tibshirani, in the youtube video [Cross Validation: Right and Wrong](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf), explains the right and wrong way to perform cross validation in detail.  He also presents a wonderful story about a Ph.D. oral dissertation presenter filtering away variables *prior* to performing cross validation and the serious effect it had on his medical research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Score with K=5 for a (possibly) better estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7150838  0.69662921 0.70224719 0.74719101 0.64606742] 0.7014437260686712\n"
     ]
    }
   ],
   "source": [
    "random_state = 100\n",
    "n_splits = 5 # 5 or 10 is the recommended value\n",
    "crossvalidation = KFold(n_splits=n_splits, shuffle=True, \n",
    "                        random_state=random_state)\n",
    "\n",
    "imputer = Imputer(strategy='mean')\n",
    "classifier = make_pipeline(imputer, LogisticRegression())\n",
    "scores = cross_val_score(classifier, X, y, cv=crossvalidation, \n",
    "                         scoring='accuracy', n_jobs=1)\n",
    "\n",
    "# Use the mean score as the best estimate of model accuracy\n",
    "print(scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K=2 and K=5 gave use almost exactly the same estimate of model accuracy in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this iteration we:\n",
    "* showed the right and wrong way to perform cross validation\n",
    "* showed that using Pipelines with Cross Validation improves the quality of the software by making it easy to concisely perform cross validation correctly.\n",
    "* added the Age variable to our model and used it's mean to impute missing values\n",
    "* showed that our estimate of model accuracy increased from 68.5% to 70.1%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "356px",
    "left": "51px",
    "right": "20px",
    "top": "142px",
    "width": "714px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
