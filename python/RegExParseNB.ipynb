{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing a Jupyter Lab Notebook with Regular Expressions\n",
    "\n",
    "This is a fairly involved example that requires knowledge similar to that for my notebooks:\n",
    "1. Core Python\n",
    "2. Core Python 2\n",
    "3. Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Overview\n",
    "\n",
    "Find all imported modules in all notebooks found in the \\\\$\\{HOME\\} directory and below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Detail\n",
    "\n",
    "* Skip notebooks under the \\\\$\\{HOME\\}/anaconda3\n",
    "* Only check notebook cells of type 'code'\n",
    "* Ignore cells that begin with %% (cell magics)\n",
    "* Ignore content of comments, triple quoted strings, etc.\n",
    "* Determine which root level modules found in all notebooks are missing from the conda environment this notebook is running in\n",
    "* Create a mapping between each module and the notebooks which use them\n",
    "* Find the most commonly imported modules\n",
    "\n",
    "Jupyter Notebook Format: https://nbformat.readthedocs.io/en/latest/format_description.html  \n",
    "API to read Jupyter Notebooks: https://nbformat.readthedocs.io/en/latest/api.html\n",
    "\n",
    "For complete parsing of Python syntax use: https://greentreesnakes.readthedocs.io/en/latest/\n",
    "\n",
    "This example uses Regular Expression to parse all common use cases of Python's import syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the Test Notebook Cell using Regular Expressions\n",
    "\n",
    "Primary import syntax use cases:\n",
    "1. import module\n",
    "2. import module.submodule\n",
    "3. from \\_\\_future\\_\\_ import module\n",
    "4. from module import something\n",
    "5. from module.submodule import something\n",
    "\n",
    "To determine which modules are referenced, its representation will be normalized.\n",
    "\n",
    "It is not possible to know from the syntax whether 'something' is or is not a module.  However an attempt can be made to load it as a module, and if it loads, then it must be a module.\n",
    "\n",
    "RegEx note: a module name can be captured with: ```([\\w|\\.]+)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Modules on a Line\n",
    "\n",
    "Express the import statement found by the regex in the following normalized form:\n",
    "\n",
    "```\n",
    "from module.submodule import something ->\n",
    "[module, module.submodule, module.submodule.something]\n",
    "\n",
    "import module.submodule.subsubmodule ->\n",
    "[module, module.submodule, module.submodule.subsubmodule]\n",
    "```\n",
    "\n",
    "Later each of these modules will attempt to be imported.\n",
    "\n",
    "No attempt is made to parse an import statement that continues across lines.  This is not recommended practice and is very rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_modules(line):\n",
    "    \"\"\"Finds potential modules on a given line\"\"\"\n",
    "    m = re.search(r'(from\\s+([\\w|\\.]+)\\s+)?import\\s+([\\w|\\.]+)', line)\n",
    "    if m:\n",
    "        mod_list = []\n",
    "        if m.group(2) is not None and m.group(2) != '__future__':\n",
    "            module = m.group(2) + '.' + m.group(3)\n",
    "        else:\n",
    "            module = m.group(3)\n",
    "         \n",
    "        modules = module.split('.')\n",
    "        mod_list = []\n",
    "        for i in range(1, len(modules)+1):\n",
    "            mod_list.append(\".\".join(modules[:i]))\n",
    "            \n",
    "        return mod_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Test of parse_modules()\n",
    "\n",
    "This is effectively a unit test.  pytest or similar should be used for unit testing, not a Jupyter Notebook.  However the principals of unit testing can still be followed within a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['module']\n",
      "['module', 'module.submodule']\n",
      "['module', 'module.submodule', 'module.submodule.submodule']\n",
      "['module']\n",
      "['module', 'module.submodule']\n",
      "['module', 'module.submodule']\n",
      "['module', 'module.submodule', 'module.submodule.subsubmodule']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# test parsing of import statements on a line\n",
    "print(parse_modules('import module'))\n",
    "print(parse_modules('import module.submodule'))\n",
    "print(parse_modules('import module.submodule.submodule'))\n",
    "print(parse_modules('from __future__ import module'))\n",
    "print(parse_modules('from __future__ import module.submodule'))\n",
    "print(parse_modules('from module import submodule'))\n",
    "print(parse_modules('from module.submodule import subsubmodule'))\n",
    "print(parse_modules('result_set = %sql select from actor where first_name = \"Bob\"'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Cell Test of parse_modules()\n",
    "\n",
    "This is a slightly higher level \"unit test\", as it makes use of the above and additional code to parse an entire notebook cell.  The cell is created specifically for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Test Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "import not_real_module\n"
     ]
    }
   ],
   "source": [
    "# create a test notebook cell with imports\n",
    "from __future__ import annotations\n",
    "import sys\n",
    "import numpy as np\n",
    "import sys\n",
    "from numpy import random\n",
    "import sklearn.model_selection\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# when parsed, these should be the modules found to be referenced\n",
    "parsed_modules = {'annotations',\n",
    " 'nbformat',\n",
    " 'numpy',\n",
    " 'numpy.random',\n",
    " 'sklearn',\n",
    " 'sklearn.feature_extraction',\n",
    " 'sklearn.feature_extraction.DictVectorizer',\n",
    " 'sklearn.model_selection',\n",
    " 'sys'}\n",
    "\n",
    "# from __future__ import not_real_module\n",
    "print(\"hello world\") # import not_real_module\n",
    "print(\"import not_real_module\")\n",
    "s = \"\"\"\n",
    "import not_real_module\n",
    "\"\"\"\n",
    "import nbformat\n",
    "t = \"\"\"import not_real_module\n",
    "\"\"\"\n",
    "a = 'import not_real_module'\n",
    "b = 'from not_real_module import not_real_class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "##### Find the above notebook cell and display it\n",
    "Note that if you change the previous cell and do not save the notebook, then the following code will read the old version of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Index: 10\n",
      "\n",
      "# create a test notebook cell with imports\n",
      "from __future__ import annotations\n",
      "import sys\n",
      "import numpy as np\n",
      "import sys\n",
      "from numpy import random\n",
      "import sklearn.model_selection\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "# when parsed, these should be the modules found to be referenced\n",
      "parsed_modules = {'annotations',\n",
      " 'nbformat',\n",
      " 'numpy',\n",
      " 'numpy.random',\n",
      " 'sklearn',\n",
      " 'sklearn.feature_extraction',\n",
      " 'sklearn.feature_extraction.DictVectorizer',\n",
      " 'sklearn.model_selection',\n",
      " 'sys'}\n",
      "\n",
      "# from __future__ import not_real_module\n",
      "print(\"hello world\") # import not_real_module\n",
      "print(\"import not_real_module\")\n",
      "s = \"\"\"\n",
      "import not_real_module\n",
      "\"\"\"\n",
      "import nbformat\n",
      "t = \"\"\"import not_real_module\n",
      "\"\"\"\n",
      "a = 'import not_real_module'\n",
      "b = 'from not_real_module import not_real_class'\n"
     ]
    }
   ],
   "source": [
    "nb = nbformat.read('RegExParseNB.ipynb', as_version=4)\n",
    "for cell_num, cell in enumerate(nb.cells):\n",
    "    if '# create a test notebook cell with imports' in cell.source:\n",
    "        break\n",
    "\n",
    "print(f'Cell Index: {cell_num}')\n",
    "print()\n",
    "print(nb.cells[cell_num].source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Cell Test of parse_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "modules = set()\n",
    "cell = nb.cells[cell_num]\n",
    "\n",
    "# remove contents of triple quoted strings\n",
    "source = re.sub(r'\\\"{3}(.*?)\\\"{3}', '', cell.source, flags = re.DOTALL | re.MULTILINE)\n",
    "\n",
    "# process each line\n",
    "lines = source.splitlines()\n",
    "for line in lines:\n",
    "    \n",
    "    # only consider text before # or first single or double quote\n",
    "    line = re.split('[#\\'\"]',line)[0]  \n",
    "    \n",
    "    mods = parse_modules(line)\n",
    "    if mods:\n",
    "        modules.update(mods)\n",
    "        \n",
    "# correct set of modules        \n",
    "modules == parsed_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Software Engineering Note\n",
    "The above shows a piece of code that works on a good test example.  The next step is refactor this code into a function or method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial version of method, cut and paste from above tested code as much as possible\n",
    "def find_modules_from_cell(cell, modules):\n",
    "    \n",
    "    # remove contents of triple quoted strings\n",
    "    source = re.sub(r'\\\"{3}(.*?)\\\"{3}', '', cell.source, flags = re.DOTALL | re.MULTILINE)\n",
    "\n",
    "    # process each line\n",
    "    lines = source.splitlines()\n",
    "    for line in lines:\n",
    "\n",
    "        # only consider text before # or first single or double quote\n",
    "        line = re.split('[#\\'\"]',line)[0]  \n",
    "\n",
    "        mods = parse_modules(line)\n",
    "        if mods:\n",
    "            modules.update(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"unit test\" refactored code\n",
    "modules = set()\n",
    "cell = nb.cells[cell_num]\n",
    "\n",
    "find_modules_from_cell(cell, modules)\n",
    "modules == parsed_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find \\\\${HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = %env\n",
    "home = env['HOME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Notebooks to Parse\n",
    "\n",
    "Find all files that:\n",
    "1. end in '.ipynb'\n",
    "2. do not end in '-checkpoint.ipynb'\n",
    "3. do not begin with \\\\$\\{HOME\\}/anaconda3\n",
    "\n",
    "Note that regular expressions are not used here as str.startswith() and str.endswith() are easier to read than regular expressions and execute faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "notebooks = []\n",
    "for dirpath, dirnames, filenames in os.walk(home):\n",
    "    for filename in filenames:\n",
    "        fullname = os.path.join(dirpath, filename)\n",
    "        if fullname.endswith('.ipynb') \\\n",
    "            and not fullname.endswith('-checkpoint.ipynb') \\\n",
    "            and not fullname.startswith(home+'/anaconda3'):\n",
    "            notebooks.append(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all potential modules referenced in all notebooks found above\n",
    "modules = set()\n",
    "for notebook in notebooks:\n",
    "    nb = nbformat.read(notebook, as_version=4)\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and not cell.source.startswith('%%'):\n",
    "            find_modules_from_cell(cell, modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Software Engineering Note\n",
    "\n",
    "find_modules_from_cell is a \"helper\" function.  In other words, it is a function which is used locally to solve a specific problem and is not intended to be used by other software developers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Loading Each Module\n",
    "\n",
    "Modules could fail to load because:\n",
    "1. old notebook reference module that has moved\n",
    "2. module is not available in the virtual environment from which this notebook is being run\n",
    "3. 'from module import something' was normalized to module.something, which may not be a module\n",
    "4. an error in parsing could incorrectly identify something that is not a module\n",
    "\n",
    "Get a list of all the modules that will not load.\n",
    "\n",
    "If the root module will not load, then this is either a parsing error or a module not in the current virtual environment.\n",
    "\n",
    "If module.something will not load, but module will load, then module.something is not a module.\n",
    "\n",
    "Note: use of exec() could result in potentially hackable code and shouldn't be used in production code.  exec() is fine to use for testing in a safe environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agni/anaconda3/envs/ml/lib/python3.7/site-packages/nbformat/current.py:19: UserWarning: nbformat.current is deprecated.\n",
      "\n",
      "- use nbformat for read/write/validate public API\n",
      "- use nbformat.vX directly to composing notebooks of a particular version\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "missing_root_modules = set()\n",
    "loadable_modules = set()\n",
    "for module in modules:\n",
    "    try:\n",
    "        # attempt to import each module\n",
    "        exec(f'import {module}')\n",
    "        loadable_modules.add(module)\n",
    "    except ModuleNotFoundError as err:\n",
    "        # skip modules which include a possible submodule\n",
    "        if '.' not in module:\n",
    "            missing_root_modules.add(module)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221 38 645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PyPDF2',\n",
       " 'PyQt4',\n",
       " 'annotations',\n",
       " 'cufflinks',\n",
       " 'cv',\n",
       " 'dask_ml',\n",
       " 'dask_xgboost',\n",
       " 'descartes',\n",
       " 'dill',\n",
       " 'division',\n",
       " 'file1',\n",
       " 'foo',\n",
       " 'graphviz',\n",
       " 'helpers_05_08',\n",
       " 'historical_prices_and_dividends',\n",
       " 'keras',\n",
       " 'mglearn',\n",
       " 'mod',\n",
       " 'mpi4py',\n",
       " 'mprun_demo',\n",
       " 'nbpackage',\n",
       " 'netCDF4',\n",
       " 'pandas_datareader',\n",
       " 'plotly',\n",
       " 'print_function',\n",
       " 'pydot',\n",
       " 'pygame',\n",
       " 'pyspark',\n",
       " 'rasterio',\n",
       " 'rmtkernel',\n",
       " 'selenium',\n",
       " 'shapely',\n",
       " 'spacy',\n",
       " 'splipy',\n",
       " 'tensorflow',\n",
       " 'testdill',\n",
       " 'vincent',\n",
       " 'xgboost'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(loadable_modules), len(missing_root_modules), len(modules))\n",
    "missing_root_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Software Engineering Note\n",
    "For a given module, it is helpful to know the set of notebook filenames which import this module.\n",
    "\n",
    "In computer science, this is called an inverted index.  It is inverted because instead of mapping notebooks to modules (we began with os.walk(home) to find notebooks) we are mapping modules to notebooks.\n",
    "\n",
    "It is easy to modify the above code to create a mapping of module name to set of notebook filenames, using defaultdict(set).\n",
    "\n",
    "The only changes to the already tested method are:\n",
    "1. add notebook to the argument list\n",
    "2. last line: for each key, add a notebook to its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to map module to set of notebooks\n",
    "def find_modules_from_cell(cell, notebook, dd):\n",
    "    \n",
    "    # remove contents of triple quoted strings\n",
    "    source = re.sub(r'\\\"{3}(.*?)\\\"{3}', '', cell.source, flags = re.DOTALL | re.MULTILINE)\n",
    "\n",
    "    # process each line\n",
    "    lines = source.splitlines()\n",
    "    for line in lines:\n",
    "\n",
    "        # only consider text before # or first single or double quote\n",
    "        line = re.split('[#\\'\"]',line)[0]  \n",
    "\n",
    "        mods = parse_modules(line)\n",
    "        if mods:\n",
    "            for mod in mods:\n",
    "                dd[mod].add(notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reparse the Notebook Cells, this time keeping a mapping from module to set of notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# uses new version of find_modules_from_cell\n",
    "dd = defaultdict(set)\n",
    "for notebook in notebooks:\n",
    "    nb = nbformat.read(notebook, as_version=4)\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and not cell.source.startswith('%%'):  \n",
    "            find_modules_from_cell(cell, notebook, dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Software Engineering Note\n",
    "It is a good idea to check every step of the way.\n",
    "\n",
    "The list of keys in the above dictionary should match the set of modules found above.  Verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# although the keys are unique, set equality requires both objects being compared to be sets\n",
    "modules == set(dd.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Above\n",
    "The code developed above, all in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nbformat\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also use pathlib2\n",
    "env = %env\n",
    "home = env['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of notebooks\n",
    "notebooks = []\n",
    "for dirpath, dirnames, filenames in os.walk(home):\n",
    "    for filename in filenames:\n",
    "        fullname = os.path.join(dirpath, filename)\n",
    "        if fullname.endswith('.ipynb') \\\n",
    "            and not fullname.endswith('-checkpoint.ipynb') \\\n",
    "            and not fullname.startswith(home+'/anaconda3'):\n",
    "            notebooks.append(fullname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_modules(line):\n",
    "    \"\"\"Finds potential modules on a given line\"\"\"\n",
    "    m = re.search(r'(from\\s+([\\w|\\.]+)\\s+)?import\\s+([\\w|\\.]+)', line)\n",
    "    if m:\n",
    "        mod_list = []\n",
    "        if m.group(2) is not None and m.group(2) != '__future__':\n",
    "            module = m.group(2) + '.' + m.group(3)\n",
    "        else:\n",
    "            module = m.group(3)\n",
    "         \n",
    "        modules = module.split('.')\n",
    "        mod_list = []\n",
    "        for i in range(1, len(modules)+1):\n",
    "            mod_list.append(\".\".join(modules[:i]))\n",
    "            \n",
    "        return mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to map module to set of notebooks\n",
    "def find_modules_from_cell(cell, notebook, dd):\n",
    "    \n",
    "    # remove contents of triple quoted strings\n",
    "    source = re.sub(r'\\\"{3}(.*?)\\\"{3}', '', cell.source, flags = re.DOTALL | re.MULTILINE)\n",
    "\n",
    "    # process each line\n",
    "    lines = source.splitlines()\n",
    "    for line in lines:\n",
    "\n",
    "        # only consider text before # or first single or double quote\n",
    "        line = re.split('[#\\'\"]',line)[0]  \n",
    "\n",
    "        mods = parse_modules(line)\n",
    "        if mods:\n",
    "            for mod in mods:\n",
    "                dd[mod].add(notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = defaultdict(set)\n",
    "for notebook in notebooks:\n",
    "    nb = nbformat.read(notebook, as_version=4)\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == 'code' and not cell.source.startswith('%%'):  \n",
    "            find_modules_from_cell(cell, notebook, dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the 5 Modules Referenced Most Often "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know how often each module was referenced:\n",
    "# create a new dictionary that maps key to number of notebooks in value set\n",
    "\n",
    "# dictionary comprehension\n",
    "counts = {key:len(value) for (key,value) in dd.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy              referenced in 292 notebooks\n",
      "matplotlib         referenced in 231 notebooks\n",
      "matplotlib.pyplot  referenced in 228 notebooks\n",
      "pandas             referenced in 226 notebooks\n",
      "seaborn            referenced in 144 notebooks\n"
     ]
    }
   ],
   "source": [
    "# create a sorted list of (key,value) tuples from the counts dictionary\n",
    "sorted_by_value = sorted(counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# top 5 most used\n",
    "for key, value in sorted_by_value[:5]:\n",
    "    print(f'{key:<18} referenced in {value:>3} notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the \"inverted index\" (dd) to display the location of one of the notebooks which reference the most common module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module: numpy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Python/Complete-Python-3-Bootcamp-master/16-Bonus Material - Introduction to GUIs/06-Custom Widget.ipynb'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common module\n",
    "module = sorted_by_value[0][0]\n",
    "print(f'Module: {module}')\n",
    "\n",
    "# one of its file locations\n",
    "notebook = sorted(dd[module])[0]\n",
    "\n",
    "# path relative to home directory\n",
    "notebook.split(home)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 passes, but very easy to understand and sorted_by_value is short\n",
    "root_modules  = [(key,value) for key,value in sorted_by_value if key.count('.') == 0]\n",
    "submodules    = [(key,value) for key,value in sorted_by_value if key.count('.') == 1]\n",
    "subsubmodules = [(key,value) for key,value in sorted_by_value if key.count('.') == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy              referenced in 292 notebooks\n",
      "matplotlib         referenced in 231 notebooks\n",
      "pandas             referenced in 226 notebooks\n",
      "seaborn            referenced in 144 notebooks\n",
      "sklearn            referenced in 141 notebooks\n"
     ]
    }
   ],
   "source": [
    "# top 5 most used root modules\n",
    "for key, value in root_modules[:5]:\n",
    "    print(f'{key:<18} referenced in {value:>3} notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib.pyplot        referenced in 228 notebooks\n",
      "sklearn.model_selection  referenced in  92 notebooks\n",
      "sklearn.metrics          referenced in  86 notebooks\n",
      "IPython.display          referenced in  70 notebooks\n",
      "sklearn.linear_model     referenced in  54 notebooks\n"
     ]
    }
   ],
   "source": [
    "# top 5 most used sub-modules\n",
    "for key, value in submodules[:5]:\n",
    "    print(f'{key:<24} referenced in {value:>3} notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.model_selection.cross_val_score  referenced in  44 notebooks\n",
      "IPython.display.display                  referenced in  44 notebooks\n",
      "sklearn.preprocessing.StandardScaler     referenced in  42 notebooks\n",
      "sklearn.model_selection.train_test_split referenced in  41 notebooks\n",
      "sklearn.linear_model.LogisticRegression  referenced in  40 notebooks\n"
     ]
    }
   ],
   "source": [
    "# top 5 most used sub-sub-modules\n",
    "for key, value in subsubmodules[:5]:\n",
    "    print(f'{key:<40} referenced in {value:>3} notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization vs Readability\n",
    "As seen below, the 1 pass code is about twice as fast as the 3 pass code, but it is only about 160 $\\mu$s faster.  \n",
    "\n",
    "Unless this operation is to be performed tens of thousands of times, readability is more important than optimization.  Readability reduces the cost of maintaining the code over the lifetime of the project and is particularly important if there are many developers working on the same code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 µs ± 5.85 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "root_modules  = [(key,value) for key,value in sorted_by_value if key.count('.') == 0]\n",
    "submodules    = [(key,value) for key,value in sorted_by_value if key.count('.') == 1]\n",
    "subsubmodules = [(key,value) for key,value in sorted_by_value if key.count('.') == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 µs ± 1.39 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "root_modules = []\n",
    "submodules = []\n",
    "subsubmodules = []\n",
    "for key,value in sorted_by_value:\n",
    "    count = key.count('.')\n",
    "    if count == 0:\n",
    "        root_modules.append((key,value))\n",
    "    elif count == 1:\n",
    "        submodules.append((key,value))\n",
    "    elif count == 2:\n",
    "        subsubmodules.append((key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the timeit cell magic creates variables that are local to that cell only\n",
    "# rerun to ensure the two methods produce the same output\n",
    "root_modules3  = [(key,value) for key,value in sorted_by_value if key.count('.') == 0]\n",
    "submodules3    = [(key,value) for key,value in sorted_by_value if key.count('.') == 1]\n",
    "subsubmodules3 = [(key,value) for key,value in sorted_by_value if key.count('.') == 2]\n",
    "\n",
    "root_modules1 = []\n",
    "submodules1 = []\n",
    "subsubmodules1 = []\n",
    "for key,value in sorted_by_value:\n",
    "    count = key.count('.')\n",
    "    if count == 0:\n",
    "        root_modules1.append((key,value))\n",
    "    elif count == 1:\n",
    "        submodules1.append((key,value))\n",
    "    elif count == 2:\n",
    "        subsubmodules1.append((key, value))\n",
    "        \n",
    "assert root_modules1 == root_modules3\n",
    "assert submodules1 == submodules3\n",
    "assert subsubmodules1 == subsubmodules3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
