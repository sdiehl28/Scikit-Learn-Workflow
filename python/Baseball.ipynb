{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseBall Data Analysis with Pandas\n",
    "\n",
    "This is the first in a series of notebooks.\n",
    "\n",
    "This notebook is designed to be used with Jupyter Lab and the Table of Contents extension: https://github.com/jupyterlab/jupyterlab-toc\n",
    "\n",
    "This notebook briefly describes:\n",
    "* the baseball data\n",
    "* how the data will be persisted after being wrangled (in later notebooks)\n",
    "\n",
    "This notebook will:\n",
    "* create directories to hold the downloaded data\n",
    "* download the data\n",
    "* unzip the downloaded files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source Baseball Data\n",
    "**Lahman**  \n",
    "* Stats per Player per Season including:\n",
    "  * Batting.csv\n",
    "  * Pitching.csv\n",
    "  * Fielding.csv\n",
    "* \"Lookup\" tables such as:\n",
    "  * People.csv: player_id -> player info\n",
    "  * Parks.csv: park_id -> park info\n",
    "  * Teams.csv: team_id -> team info\n",
    "* and more ...\n",
    "\n",
    "**Retrosheet**  \n",
    "* Play by Play data for every MLB game since 1921\n",
    "  * as parsed by cwdaily -> Batting and Pitching stats per Player per Game\n",
    "  * as parsed by cwgame -> Game Stats (e.g. home and away team hits) per Game  \n",
    "  \n",
    "**Using Both**  \n",
    "* People.csv has the Lahman player_id as well as the Retrosheet player_id\n",
    "* This allows for joins (about player data) between the two data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting Intermediate Results\n",
    "\n",
    "**Primary Concern: Column Data Types**\n",
    "* dates should be read back in as dates to allow for date specific operations\n",
    "* small integer values should be read back as small integers to save memory\n",
    "* categories should be read back as categories to save memory  \n",
    "  \n",
    "In all cases: it is helpful to both data analysts and other software libraries which may make use of the data, to know the most specific data type for a variable.\n",
    "\n",
    "**Persisted Data Representations**  \n",
    "For demonstration purposes, the data will be persisted in two forms (only one form is necessary for data analysis):\n",
    "1. CSV files\n",
    "2. Postgres Tables\n",
    "\n",
    "**CSV Files**  \n",
    "To avoid loss of Pandas column data types:\n",
    "* When writing:\n",
    "  * The DataFrame's data types will be written to a csv file.\n",
    "  * The DataFrame will be written to a csv file.\n",
    "* When reading:\n",
    "  * The data types will be read.\n",
    "  * The data types will be used to properly read in the DataFrame.\n",
    "\n",
    "**Postgres**  \n",
    "1. pd.to_sql()\n",
    "  * automatically chooses the right database data type for pd.datetime\n",
    "  * chooses too large a database data type for numeric values, so\n",
    "    * specify SQL Alchemy types such as SmallInteger and Integer, appropriately\n",
    "2. df.read_sql()\n",
    "  * automatically chooses the right Pandas data type for database datetime columns\n",
    "  * chooses too large a Pandas data type for numeric values, so\n",
    "    * use pd.to_numeric with downcast\n",
    "  * chooses object when category may be more appropriate, so\n",
    "    * convert object to category if number of unique values is less than 5% (for example) of the number of records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Download and Unpack Lahman Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lahman Directories\n",
    "* raw data -- zipped and unzipped files\n",
    "* wrangled data -- to be populated in later notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path objects\n",
    "home = Path.home()\n",
    "lahman = home.joinpath('data/lahman')\n",
    "p_raw = lahman.joinpath('raw')\n",
    "p_wrangled = lahman.joinpath('wrangled')\n",
    "\n",
    "# create directories from these path objects\n",
    "p_raw.mkdir(parents=True, exist_ok=True)\n",
    "p_wrangled.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Unzip\n",
    "There are two sources for the Lahman data.\n",
    "\n",
    "**Sean Lahman**  \n",
    "http://www.seanlahman.com/baseball-archive/statistics  \n",
    "There appears to be a snapshot of data taken the day prior to last season's opening day.\n",
    "\n",
    "**Baseball Databank**  \n",
    "https://github.com/chadwickbureau/baseballdatabank  \n",
    "This is the latest data.  As of the time of this writing, it includes the 2018 season whereas the previous link does not.\n",
    "\n",
    "In order to use 2018 data, the baseball databank will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zip file from github (if not already downloaded)\n",
    "os.chdir(p_raw)\n",
    "baseball_zip = p_raw.joinpath('baseballdatabank-master.zip')\n",
    "\n",
    "if not baseball_zip.is_file():\n",
    "    url = 'https://github.com/chadwickbureau/baseballdatabank/archive/master.zip'\n",
    "    wget.download(url)\n",
    "\n",
    "    # unzip it\n",
    "    with zipfile.ZipFile('baseballdatabank-master.zip', \"r\") as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "os.chdir(p_raw)\n",
    "people_csv = p_raw.joinpath('People.csv')\n",
    "\n",
    "if not people_csv.is_file():\n",
    "    unzip_dir = p_raw.joinpath('baseballdatabank-master/core')\n",
    "\n",
    "    # move the unzipped csv files to the current working directory\n",
    "    os.chdir(p_raw)\n",
    "    for root, dirs, files in os.walk(unzip_dir):\n",
    "        for file in files:\n",
    "            shutil.move(root+'/'+file, '.')\n",
    "\n",
    "    # rm the extract directory\n",
    "    shutil.rmtree('baseballdatabank-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AllstarFull.csv',\n",
       " 'Appearances.csv',\n",
       " 'AwardsManagers.csv',\n",
       " 'AwardsPlayers.csv',\n",
       " 'AwardsShareManagers.csv',\n",
       " 'AwardsSharePlayers.csv',\n",
       " 'Batting.csv',\n",
       " 'BattingPost.csv',\n",
       " 'CollegePlaying.csv',\n",
       " 'Fielding.csv',\n",
       " 'FieldingOF.csv',\n",
       " 'FieldingOFsplit.csv',\n",
       " 'FieldingPost.csv',\n",
       " 'HallOfFame.csv',\n",
       " 'HomeGames.csv',\n",
       " 'Managers.csv',\n",
       " 'ManagersHalf.csv',\n",
       " 'Parks.csv',\n",
       " 'People.csv',\n",
       " 'Pitching.csv',\n",
       " 'PitchingPost.csv',\n",
       " 'Salaries.csv',\n",
       " 'Schools.csv',\n",
       " 'SeriesPost.csv',\n",
       " 'Teams.csv',\n",
       " 'TeamsFranchises.csv',\n",
       " 'TeamsHalf.csv',\n",
       " 'baseballdatabank-master.zip',\n",
       " 'readme2014.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the current directory (p_raw) has the csv files\n",
    "os.chdir(p_raw)\n",
    "sorted(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Download and Unpack Retrosheet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retrosheet Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Retrosheet directories for:\n",
    "* raw data -- zipped and unzipped files\n",
    "* wrangled data -- to be populated in later notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path objects\n",
    "home = Path.home()\n",
    "retrosheet = home.joinpath('data/retrosheet')\n",
    "p_raw = retrosheet.joinpath('raw')\n",
    "p_wrangled = retrosheet.joinpath('wrangled')\n",
    "\n",
    "# create directories (if they don't already exist) from these path objects\n",
    "p_raw.mkdir(parents=True, exist_ok=True)\n",
    "p_wrangled.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrosheet Event (aka Play by Play) Data\n",
    "Data is available from 1921 to present.\n",
    "\n",
    "Here, data from 1955 through 2018 will be downloaded and unzipped.  The start year of 1955 was chosen in part because there are fewer missing values for baseball attributes from 1955 on.\n",
    "\n",
    "Using 1955 to present will result in (at least one temporary) 2+ Gig Pandas DataFrame in later notebooks, so chose more or less years as appropriate for your computer's resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to raw file directory\n",
    "os.chdir(p_raw)\n",
    "\n",
    "for year in range(1955,2019):   \n",
    "    # download each event file, if it doesn't exist locally\n",
    "    filename = f'{year}eve.zip'\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        url = f'http://www.retrosheet.org/events/{year}eve.zip'\n",
    "        wget.download(url)\n",
    "    \n",
    "    # unzip each zip file, if its contents don't exist locally\n",
    "    # {year}BOS.EVA is in all zip files\n",
    "    filename = f'{year}BOS.EVA'\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        filename = f'{year}eve.zip'\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzipped Data File Types\n",
    "The unzipped data consists of 3 types of files:\n",
    "1. *.EVA and *.EVN -- these are American League and National League event files per team per year\n",
    "2. *.ROS -- these are the rosters per team per year\n",
    "3. TEAM* -- these are the MBL teams in existence per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018HOU.EVA\n",
      "2018CHN.EVN\n",
      "2018MIL.EVN\n",
      "2018CLE.EVA\n",
      "2018TEX.EVA\n",
      "2018ATL.EVN\n",
      "2018ANA.EVA\n",
      "2018PHI.EVN\n",
      "2018TOR.EVA\n",
      "2018PIT.EVN\n",
      "2018SEA.EVA\n",
      "2018DET.EVA\n",
      "2018SLN.EVN\n",
      "2018BOS.EVA\n",
      "2018OAK.EVA\n",
      "2018TBA.EVA\n",
      "2018MIN.EVA\n",
      "2018WAS.EVN\n",
      "2018MIA.EVN\n",
      "2018ARI.EVN\n",
      "2018SDN.EVN\n",
      "2018LAN.EVN\n",
      "2018COL.EVN\n",
      "2018KCA.EVA\n",
      "2018CHA.EVA\n",
      "2018CIN.EVN\n",
      "2018SFN.EVN\n",
      "2018NYN.EVN\n",
      "2018BAL.EVA\n",
      "2018NYA.EVA\n"
     ]
    }
   ],
   "source": [
    "# List 2018 Play by Play Files\n",
    "files = os.listdir(p_raw)\n",
    "for file in files:\n",
    "    if '2018' in file and (file.endswith('.EVA') or file.endswith('.EVN')):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OAK2018.ROS\n",
      "DET2018.ROS\n",
      "MIA2018.ROS\n",
      "TEX2018.ROS\n",
      "LAN2018.ROS\n",
      "SEA2018.ROS\n",
      "CIN2018.ROS\n",
      "CHA2018.ROS\n",
      "CHN2018.ROS\n",
      "PHI2018.ROS\n",
      "BOS2018.ROS\n",
      "ATL2018.ROS\n",
      "MIN2018.ROS\n",
      "NYA2018.ROS\n",
      "ANA2018.ROS\n",
      "HOU2018.ROS\n",
      "TOR2018.ROS\n",
      "NYN2018.ROS\n",
      "COL2018.ROS\n",
      "KCA2018.ROS\n",
      "TBA2018.ROS\n",
      "CLE2018.ROS\n",
      "BAL2018.ROS\n",
      "SFN2018.ROS\n",
      "SDN2018.ROS\n",
      "SLN2018.ROS\n",
      "PIT2018.ROS\n",
      "ARI2018.ROS\n",
      "WAS2018.ROS\n",
      "MIL2018.ROS\n"
     ]
    }
   ],
   "source": [
    "# List 2018 Roster Files\n",
    "files = os.listdir(p_raw)\n",
    "for file in files:\n",
    "    if '2018' in file and file.endswith('.ROS'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAM2018\n"
     ]
    }
   ],
   "source": [
    "# List 2018 Team Files\n",
    "files = os.listdir(p_raw)\n",
    "for file in files:\n",
    "    if '2018' in file and file.startswith('TEAM'):\n",
    "        print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
