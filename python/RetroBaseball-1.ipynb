{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Retrosheet Baseball Data -- Parse Play by Play Data\n",
    "\n",
    "**Baseball Notebooks**  \n",
    "1. Downloaded and unzipped baseball data.\n",
    "2. Helper functions and their motivation for use.\n",
    "3. Lahman data was wrangled and persisted.\n",
    "4. This notebook.\n",
    "\n",
    "Parse the Retrosheet Play by Play data.\n",
    "\n",
    "The parses used will be the open source parsers by Dr. T. L. Turocy.  \n",
    "Parser Description: http://chadwick.sourceforge.net/doc/index.html  \n",
    "Parser Source: https://sourceforge.net/projects/chadwick/\n",
    "\n",
    "As of March 2019, the cwdaily parser, published in July 2018, is not described on the above web site.  It is similar to the other parsers described there.\n",
    "\n",
    "This notebook is designed to be used with Jupyter Lab and the Table of Contents extension: https://github.com/jupyterlab/jupyterlab-toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Repeatable Research\n",
    "All data processing should be documented so that others can repeat the results.  This includes every step from downloading the data through analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Directories for Data Processing\n",
    "\n",
    "* ~/data/retrosheet/raw -- event files downloaded and unzipped\n",
    "* ~/data/retrosheet/parsed -- results of running 2 parsers on the event files\n",
    "* ~/data/retrosheet/collected -- collect the parsed files into dataframes\n",
    "* ~/data/retrosheet/wrangled -- wrangle the data for analsyis\n",
    "* ~/data/retrosheet/src -- optional directory to hold parser source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Baseball Notebook #2\n",
    "import helper_functions as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path objects\n",
    "home = Path.home()\n",
    "retrosheet = home.joinpath('data/retrosheet')\n",
    "p_raw = retrosheet.joinpath('raw')\n",
    "p_wrangled = retrosheet.joinpath('wrangled')\n",
    "\n",
    "p_parsed = retrosheet.joinpath('parsed')\n",
    "p_collected = retrosheet.joinpath('collected')\n",
    "p_src = retrosheet.joinpath('src')\n",
    "\n",
    "# create directories (if they don't already exist) from these path objects\n",
    "p_raw.mkdir(parents=True, exist_ok=True)\n",
    "p_wrangled.mkdir(parents=True, exist_ok=True)\n",
    "p_parsed.mkdir(parents=True, exist_ok=True)\n",
    "p_collected.mkdir(parents=True, exist_ok=True)\n",
    "p_src.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Parse Event Data for Stats per Player per Game\n",
    "\n",
    "The event data is in a format that is very difficult to work with.  There is an open-source project which has parsers for the Retrosheet event data.  This project has 6 parsers.  Each of these parsers is fed event data and produces csv or XML or text output.\n",
    "\n",
    "The two parsers that are of interest for this study are:\n",
    "1. cwdaily -- player per game stats\n",
    "2. cwgame -- game stats\n",
    "\n",
    "The cwbox parser produces a box score in the form MLB fans are accustomed to seeing (or it can produce XML with appropriate tags).  This appears to have the same information as is produced by cwdaily, however cwdaily formats the data as one line per player per game, which is much easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Computer Resource Usage\n",
    "\n",
    "This analysis was run on a 2015 workstation with:\n",
    "* Ubuntu 18.04 LTS\n",
    "* 4 core Xeon CPU with hyperthreading running at 3.7 GHz\n",
    "* 96 GB of RAM\n",
    "* 1 TB PCIe SSD\n",
    "\n",
    "8 or 16 GB of RAM is probably sufficient, but if you run out of RAM, try the following (in order of preference):\n",
    "1. use 1975 (or later) to present instead of 1955 to present\n",
    "2. cwdaily: use '-f 0-51' instead of '-f 0-116' -- the rest of the fields are not as useful\n",
    "3. cwgame: use '-f 0-45' instead of '-f 0-45,82,83 -x 0-59' -- the rest of the fields are not as useful\n",
    "\n",
    "All the following notebooks will work as-is with less years, so the preferred approach to reducing RAM usage would be to process fewer years of Retrosheet data.  \n",
    "\n",
    "cwdaily creates about 25 times more records as cwgame, so reducing the number of fields for cwdaily will make far more of a difference than doing so for cwgame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Chadwick Parsers on Linux (or use prebuilt Windows binaries)\n",
    "This section describes how to download the source, compile and install it.\n",
    "\n",
    "The compile and install procedure here is the standard procedure for compiling and installing open-source code on Linux.\n",
    "\n",
    "Go To:  \n",
    "https://sourceforge.net/projects/chadwick/  \n",
    "Download the source code for version 0.7.1 or later.\n",
    "\n",
    "If you do not already have a build environment:\n",
    "1. sudo apt install gcc\n",
    "2. sudo apt install build-essential\n",
    "\n",
    "cd to the source directory:\n",
    "1. ./configure\n",
    "2. make\n",
    "3. make install  # or: sudo make install  \n",
    "\n",
    "Result\n",
    "1. The cw command line tools will be installed in /usr/local/bin.  \n",
    "2. The cw library will be installed in /usr/local/lib.  \n",
    "\n",
    "To allow the command line tools to find the shared libraries, add the following to your .bashrc and then: source .bashrc  \n",
    "```export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/lib```\n",
    "\n",
    "Optionally copy cwdaily.c and cwgame.c to the src directory.  These C source code files will be parsed to get data dictionary infromation.  These files, and the parsing of these C source code files, is only useful to understanding the data and is not required for the later baseball analysis notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Prebuilt Windows Binaries\n",
    "Go To:  \n",
    "https://sourceforge.net/projects/chadwick/  \n",
    "Download the Windows binaries for version 0.7.1 or later.\n",
    "\n",
    "**Linux Wine**  \n",
    "Install wine: https://wiki.winehq.org/Ubuntu  \n",
    "Before first use of wine: run winecfg in a terminal\n",
    "\n",
    "**Windows**  \n",
    "You could also run the windows binaries on Windows or a Windows VM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Run the cwdaily Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/local/bin/cwbox',\n",
       " '/usr/local/bin/cwcomment',\n",
       " '/usr/local/bin/cwdaily',\n",
       " '/usr/local/bin/cwevent',\n",
       " '/usr/local/bin/cwgame',\n",
       " '/usr/local/bin/cwsub']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normally os.listdir() is used to list a directory\n",
    "# here, for demonstating the subprocess module, subprocess will be used\n",
    "# invoke bash directly with shell=False in subprocess\n",
    "import subprocess\n",
    "\n",
    "cmd = 'ls /usr/local/bin/cw*'\n",
    "args = ['/bin/bash', '-c', cmd]\n",
    "result = subprocess.run(args, shell=False, text=True, capture_output=True)\n",
    "result.stdout.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cwgame.c', 'cwdaily.c']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the optionally downloaded C source code for the two parsers\n",
    "os.listdir(p_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/lib'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# check the environment variable for LD_LIBRARY_PATH\n",
    "os.environ['LD_LIBRARY_PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run out of RAM for any part of the analysis, try the first cmd below.  52 fields requires much less RAM than 117, and the first 52 are the most useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running windows binaries under Linux, \n",
    "# prepend 'wine ' to the cmd string below\n",
    "def process_cwdaily(year):\n",
    "    \"\"\"Parse event data into player stats per game.\n",
    "    \n",
    "    There are a total of 117 fields to choose from.\n",
    "    \"\"\"\n",
    "    # cmd = f'cwdaily -f 0-51 -n -y {year} {year}*.EV*'\n",
    "    cmd = f'cwdaily -f 0-116 -n -y {year} {year}*.EV*'    \n",
    "    args = [\"/bin/bash\", \"-c\", cmd]\n",
    "    out = f'../parsed/daily{year}.csv'\n",
    "    with open(out, \"w\") as outfile:\n",
    "        result = subprocess.run(args, stdout=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to raw file directory\n",
    "os.chdir(p_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run out of RAM at any point in the analysis, try years in the range of 1975 to present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each year of event data\n",
    "for year in range(1955, 2019):\n",
    "    file = p_parsed.joinpath(f'daily{year}.csv')\n",
    "    \n",
    "    # if the output file is not already there\n",
    "    if not file.is_file():\n",
    "        process_cwdaily(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the parsed files into a single pandas dataframe\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(p_parsed)\n",
    "dailyfiles = glob.glob('daily*.csv')\n",
    "dailyfiles.sort()\n",
    "\n",
    "dfs = []\n",
    "for file in dailyfiles:\n",
    "    dfs.append(pd.read_csv(file))\n",
    "player_game = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3549700 entries, 0 to 3549699\n",
      "Columns: 117 entries, game_id to f_rf_tp\n",
      "dtypes: int64(114), object(3)\n",
      "memory usage: 3.1+ GB\n"
     ]
    }
   ],
   "source": [
    "player_game = player_game.reset_index(drop=True)\n",
    "player_game.columns = player_game.columns.str.lower()\n",
    "player_game.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Persist Dataframe\n",
    "\n",
    "Parsing dates and other data wrangling is performed in the next notebook.  This notebook just downloads, parses, downcasts as appropriate, and saves the data to a compressed csv file.\n",
    "\n",
    "Due to the sparsity of the player_game dataframe, using gzip will reduce the file size by a factor of 10+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3744.10 MB'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.mem_usage(player_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_game = bb.optimize_df_dtypes(player_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1062.97 MB'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.mem_usage(player_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3549700 entries, 0 to 3549699\n",
      "Columns: 117 entries, game_id to f_rf_tp\n",
      "dtypes: object(3), uint32(2), uint8(112)\n",
      "memory usage: 487.5+ MB\n"
     ]
    }
   ],
   "source": [
    "player_game.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 31s, sys: 905 ms, total: 5min 32s\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "# change working dir\n",
    "os.chdir(p_collected)\n",
    "\n",
    "# persist as compressed csv file\n",
    "%time bb.to_csv_with_types(player_game, 'player_game.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Parse Event Data for Stats per Game\n",
    "Additional information about each game is available, such as the attendance, temperature at game start time, game start time, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run out of RAM at any point in the analysis, try the first cmd below.  46 fields requires less RAM than 108 fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running windows binaries under Linux, prepend 'wine ' to the cmd string below\n",
    "def process_cwgame(year):\n",
    "    \"\"\"Parse yearly event data into stats per game.\n",
    "    \n",
    "    There are 84 standard fields and 95 extended fields to choose from.  \n",
    "    \"\"\"\n",
    "    # cmd = f'cwgame -f 0-45 -n -y {year} {year}*.EV*'\n",
    "    cmd = f'cwgame -f 0-45,82,83 -x 0-59 -n -y {year} {year}*.EV*'    \n",
    "    args = [\"/bin/bash\", \"-c\", cmd]\n",
    "    out = f'../parsed/game{year}.csv'\n",
    "    with open(out, \"w\") as outfile:\n",
    "        result = subprocess.run(args, stdout=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to raw file directory\n",
    "os.chdir(p_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run out of RAM at any point in the analysis, try years in the range of 1975 to present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each year of event data\n",
    "for year in range(1955, 2019):\n",
    "    file = p_parsed.joinpath(f'game{year}.csv')\n",
    "    \n",
    "    # if the output file is not already there\n",
    "    if not file.is_file():\n",
    "        process_cwgame(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the parsed files into a single pandas dataframe\n",
    "import glob\n",
    "os.chdir(p_parsed)\n",
    "gamefiles = glob.glob('game*.csv')\n",
    "gamefiles.sort()\n",
    "\n",
    "dfs = []\n",
    "for file in gamefiles:\n",
    "    dfs.append(pd.read_csv(file))\n",
    "game = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.columns = game.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = bb.optimize_df_dtypes(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 129846 entries, 0 to 2430\n",
      "Columns: 108 entries, game_id to home_tp_ct\n",
      "dtypes: float64(6), int64(3), object(29), uint16(2), uint32(1), uint8(67)\n",
      "memory usage: 47.9+ MB\n"
     ]
    }
   ],
   "source": [
    "game.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 15 ms, total: 16.8 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "os.chdir(p_collected)\n",
    "%time bb.to_csv_with_types(game, 'game.csv.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
