{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Retrosheet Baseball Data -- Parse Play by Play Data\n",
    "\n",
    "**Baseball Notebooks**  \n",
    "1. Downloaded and unzipped data.  Discussed techniques for persisting DataFrames.\n",
    "2. Lahman data was wrangled and persisted.\n",
    "3. This notebook will parse the Retrosheet Play by Play data.\n",
    "\n",
    "The parses used will be the open source parsers by Dr. T. L. Turocy.  \n",
    "Parser Description: http://chadwick.sourceforge.net/doc/index.html  \n",
    "Parser Source: https://sourceforge.net/projects/chadwick/\n",
    "\n",
    "This notebook is designed to be used with Jupyter Lab and the Table of Contents extension: https://github.com/jupyterlab/jupyterlab-toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Repeatable Research\n",
    "All data processing should be documented so that others can repeat the results.  This includes every step from downloading the data through analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Useful Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persisting DataFrame Column Data Types with CSV\n",
    "See the discussion in previous notebook for persisting DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv_with_types(df, file_prefix, compression=False):\n",
    "    \"\"\"Save df to csv and save df.dtypes to csv\"\"\"\n",
    "    \n",
    "    dtypes = df.dtypes.to_frame('dtypes').reset_index()\n",
    "    filename_types = file_prefix + '_types.csv'\n",
    "    dtypes.to_csv(filename_types, index=False)    \n",
    "    \n",
    "    if compression:\n",
    "        filename = file_prefix + '.csv.gz'\n",
    "        df.to_csv(filename, compression='gzip', index=False)        \n",
    "    else:\n",
    "        filename = file_prefix + '.csv'        \n",
    "        df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_csv_with_types(file_prefix, compression=False):\n",
    "    \"\"\"Read df.dtypes from csv and read df from csv\"\"\"\n",
    "    \n",
    "    filename_types = file_prefix + '_types.csv'\n",
    "    types = pd.read_csv(filename_types).set_index('index').to_dict()\n",
    "    dtypes = types['dtypes']\n",
    "    \n",
    "    dates = [key for key,value in dtypes.items() if value.startswith('datetime')]\n",
    "    for field in dates:\n",
    "        dtypes.pop(field)\n",
    "        \n",
    "    if compression:\n",
    "        filename = file_prefix + '.csv.gz'\n",
    "        df = pd.read_csv(filename, compression='gzip', parse_dates = dates, dtype=dtypes)\n",
    "    else:\n",
    "        df = pd.read_csv(file_prefix+'.csv', parse_dates = dates, dtype=dtypes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is Unique over Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is faster than using groupby\n",
    "def is_unique(df, cols):\n",
    "    return not (df.duplicated(subset=cols)).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Pandas Data Types\n",
    "There is no way to do this perfectly in general, however the following is a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_pandas_dtypes(df, cutoff=0.05):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # int64 -> smallest uint allowed by data\n",
    "    df_int = df.select_dtypes(include=[np.int])\n",
    "    df_int = df_int.apply(pd.to_numeric,downcast='unsigned')\n",
    "    df[df_int.columns] = df_int\n",
    "\n",
    "    # object -> category, if less than 5% of values are unique\n",
    "    df_obj = df.select_dtypes(include=['object'])\n",
    "    s = df_obj.nunique() / df.shape[0]\n",
    "    columns = s.index[s <= cutoff].values\n",
    "    if len(columns) > 0:\n",
    "        df_cat = df[columns].astype('category')\n",
    "        df[columns] = df_cat    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_usage(df):\n",
    "    mem = df.memory_usage(deep=True).sum()\n",
    "    mem = mem / 2 ** 20 # covert to megabytes\n",
    "    return f'{mem:03.2f} MB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Directories for Data Processing\n",
    "\n",
    "* ~/data/retrosheet/raw -- event files downloaded and unzipped\n",
    "* ~/data/retrosheet/parsed -- results of running 2 parsers on the event files\n",
    "* ~/data/retrosheet/collected -- collect the parsed files into dataframes\n",
    "* ~/data/retrosheet/wrangled -- wrangle the data for analsyis\n",
    "* ~/data/retrosheet/src -- optional directory to hold parser source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path objects\n",
    "home = Path.home()\n",
    "retrosheet = home.joinpath('data/retrosheet')\n",
    "p_raw = retrosheet.joinpath('raw')\n",
    "p_wrangled = retrosheet.joinpath('wrangled')\n",
    "\n",
    "p_parsed = retrosheet.joinpath('parsed')\n",
    "p_collected = retrosheet.joinpath('collected')\n",
    "p_src = retrosheet.joinpath('src')\n",
    "\n",
    "# create directories (if they don't already exist) from these path objects\n",
    "p_raw.mkdir(parents=True, exist_ok=True)\n",
    "p_wrangled.mkdir(parents=True, exist_ok=True)\n",
    "p_parsed.mkdir(parents=True, exist_ok=True)\n",
    "p_collected.mkdir(parents=True, exist_ok=True)\n",
    "p_src.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Parse Event Data for Stats per Player per Game\n",
    "\n",
    "The event data is in a format that is very difficult to work with.  There is an open-source project which has parsers for the Retrosheet event data.  This project has 6 parsers.  Each of these parsers is fed event data and produces csv or XML or text output.\n",
    "\n",
    "The two parsers that are of interest for this study are:\n",
    "1. cwdaily -- player per game stats\n",
    "2. cwgame -- game stats\n",
    "\n",
    "The cwbox parser produces a box score in the form MLB fans are accustomed to seeing (or it can produce XML with appropriate tags).  This appears to have the same information as is produced by cwdaily, however cwdaily formats the data as one line per player per game, which is much easier to work with.\n",
    "\n",
    "The Retrosheet data parser tools are described at:  \n",
    "http://chadwick.sourceforge.net/doc/index.html  \n",
    "  \n",
    "They are distributed under the GPL:  \n",
    "https://www.gnu.org/licenses/gpl.html  \n",
    "\n",
    "Note: as of February 2019, the cwdaily parser, published in July 2018, is not described on the above webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Chadwick Parsers on Linux (or use prebuilt Windows binaries)\n",
    "This section describes how to download the source, compile and install it.\n",
    "\n",
    "The compile and install procedure here is the standard procedure for compiling and installing open-source code on Linux.\n",
    "\n",
    "Go To:  \n",
    "https://sourceforge.net/projects/chadwick/  \n",
    "Download the source code for version 0.7.1 or later.\n",
    "\n",
    "If you do not already have a build environment:\n",
    "1. sudo apt install gcc\n",
    "2. sudo apt install build-essential\n",
    "\n",
    "cd to the source directory:\n",
    "1. ./configure\n",
    "2. make\n",
    "3. make install  # or: sudo make install  \n",
    "\n",
    "Result\n",
    "1. The cw command line tools will be installed in /usr/local/bin.  \n",
    "2. The cw library will be installed in /usr/local/lib.  \n",
    "\n",
    "To allow the command line tools to find the shared libraries, add the following to your .bashrc and then: source .bashrc  \n",
    "```export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/lib```\n",
    "\n",
    "Optionally copy cwdaily.c and cwgame.c to the src directory.  These C source code files will be parsed to get data dictionary infromation.  These files, and the parsing of these files, is only useful to understanding the data and is not required for the later baseball analysis notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Prebuilt Windows Binaries\n",
    "Go To:  \n",
    "https://sourceforge.net/projects/chadwick/  \n",
    "Download the Windows binaries for version 0.7.1 or later.\n",
    "\n",
    "**Linux Wine**  \n",
    "Install wine: https://wiki.winehq.org/Ubuntu  \n",
    "Before first use of wine: run winecfg in a terminal\n",
    "\n",
    "**Windows**  \n",
    "You could also run the windows binaries on Windows or a Windows VM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Run the cwdaily Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/local/bin/cwbox',\n",
       " '/usr/local/bin/cwcomment',\n",
       " '/usr/local/bin/cwdaily',\n",
       " '/usr/local/bin/cwevent',\n",
       " '/usr/local/bin/cwgame',\n",
       " '/usr/local/bin/cwsub']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normally os.listdir() is used to list a directory\n",
    "# here, for demonstating the subprocess module, subprocess will be used\n",
    "# invoke bash directly with shell=False in subprocess\n",
    "import subprocess\n",
    "\n",
    "cmd = 'ls /usr/local/bin/cw*'\n",
    "args = ['/bin/bash', '-c', cmd]\n",
    "result = subprocess.run(args, shell=False, text=True, capture_output=True)\n",
    "result.stdout.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cwgame.c', 'cwdaily.c']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the optionally downloaded C source code for the two parsers\n",
    "os.listdir(p_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/lib'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# check the environment variable for LD_LIBRARY_PATH\n",
    "os.environ['LD_LIBRARY_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running windows binaries under Linux, \n",
    "# prepend 'wine ' to the cmd string below\n",
    "def process_cwdaily(year):\n",
    "    \"\"\"Parse event data into 52 fields of player stats per game.\n",
    "    \n",
    "    There are a total of 117 fields to chose from, the first 52 are selected.\n",
    "    \"\"\"\n",
    "    cmd = f'cwdaily -f 0-51 -n -y {year} {year}*.EV*'\n",
    "    args = [\"/bin/bash\", \"-c\", cmd]\n",
    "    out = f'../parsed/daily{year}.csv'\n",
    "    with open(out, \"w\") as outfile:\n",
    "        result = subprocess.run(args, stdout=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to raw file directory\n",
    "os.chdir(p_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each year of event data\n",
    "for year in range(1955, 2019):\n",
    "    file = p_parsed.joinpath(f'daily{year}.csv')\n",
    "    \n",
    "    # if the output file is not already there\n",
    "    if not file.is_file():\n",
    "        process_cwdaily(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the parsed files into a single pandas dataframe\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(p_parsed)\n",
    "dailyfiles = glob.glob('daily*.csv')\n",
    "dailyfiles.sort()\n",
    "\n",
    "dfs = []\n",
    "for file in dailyfiles:\n",
    "    dfs.append(pd.read_csv(file))\n",
    "player_game = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_dt</th>\n",
       "      <th>game_ct</th>\n",
       "      <th>appear_dt</th>\n",
       "      <th>team_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>b_g</th>\n",
       "      <th>b_pa</th>\n",
       "      <th>b_ab</th>\n",
       "      <th>b_r</th>\n",
       "      <th>...</th>\n",
       "      <th>p_bb</th>\n",
       "      <th>p_ibb</th>\n",
       "      <th>p_so</th>\n",
       "      <th>p_gdp</th>\n",
       "      <th>p_hp</th>\n",
       "      <th>p_sh</th>\n",
       "      <th>p_sf</th>\n",
       "      <th>p_xi</th>\n",
       "      <th>p_wp</th>\n",
       "      <th>p_bk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAL195504120</td>\n",
       "      <td>19550412</td>\n",
       "      <td>0</td>\n",
       "      <td>19550412</td>\n",
       "      <td>BOS</td>\n",
       "      <td>goodb101</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAL195504120</td>\n",
       "      <td>19550412</td>\n",
       "      <td>0</td>\n",
       "      <td>19550412</td>\n",
       "      <td>BOS</td>\n",
       "      <td>joose101</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL195504120</td>\n",
       "      <td>19550412</td>\n",
       "      <td>0</td>\n",
       "      <td>19550412</td>\n",
       "      <td>BOS</td>\n",
       "      <td>throf101</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        game_id   game_dt  game_ct  appear_dt team_id player_id  b_g  b_pa  \\\n",
       "0  BAL195504120  19550412        0   19550412     BOS  goodb101    1     5   \n",
       "1  BAL195504120  19550412        0   19550412     BOS  joose101    1     5   \n",
       "2  BAL195504120  19550412        0   19550412     BOS  throf101    1     5   \n",
       "\n",
       "   b_ab  b_r  ...  p_bb  p_ibb  p_so  p_gdp  p_hp  p_sh  p_sf  p_xi  p_wp  \\\n",
       "0     5    1  ...     0      0     0      0     0     0     0     0     0   \n",
       "1     4    0  ...     0      0     0      0     0     0     0     0     0   \n",
       "2     5    1  ...     0      0     0      0     0     0     0     0     0   \n",
       "\n",
       "   p_bk  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "\n",
       "[3 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_game = player_game.reset_index(drop=True)\n",
    "player_game.columns = player_game.columns.str.lower()\n",
    "player_game.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Persist Dataframe\n",
    "\n",
    "Parsing dates and other data wrangling is performed in the next notebook.  This notebook just downloads, parses, and saves the data to a compressed csv file.\n",
    "\n",
    "Due to the sparsity of the player_game dataframe, using gzip will reduce the file size by a factor of 10+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1983.76 MB'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_usage(player_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64     49\n",
       "object     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_game.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_game = optimize_pandas_dtypes(player_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'224.44 MB'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_usage(player_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category     3\n",
       "uint32       2\n",
       "uint8       47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_game.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 38s, sys: 36.4 ms, total: 2min 38s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "# change working dir\n",
    "os.chdir(p_collected)\n",
    "\n",
    "# persist as compressed csv file\n",
    "%time to_csv_with_types(player_game, 'player_game', compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Parse Event Data for Stats per Game\n",
    "Additional information about each game is available, such as the attendance, temperature at game start time, game start time, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running windows binaries under Linux, prepend 'wine ' to the cmd string below\n",
    "def process_cwgame(year):\n",
    "    \"\"\"Parse yearly event data into 45 fields of game data per year.\n",
    "    \n",
    "    For each game, there are 84 standard fields and 95 extended fields to chose from.  \n",
    "    Only the first 46 standard fields are chosen.\n",
    "    \"\"\"\n",
    "    cmd = f'cwgame -f 0-45 -n -y {year} {year}*.EV*'\n",
    "    args = [\"/bin/bash\", \"-c\", cmd]\n",
    "    out = f'../parsed/game{year}.csv'\n",
    "    with open(out, \"w\") as outfile:\n",
    "        result = subprocess.run(args, stdout=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to raw file directory\n",
    "os.chdir(p_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse each year of event data\n",
    "for year in range(1955, 2019):\n",
    "    file = p_parsed.joinpath(f'game{year}.csv')\n",
    "    \n",
    "    # if the output file is not already there\n",
    "    if not file.is_file():\n",
    "        process_cwgame(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the parsed files into a single pandas dataframe\n",
    "import glob\n",
    "os.chdir(p_parsed)\n",
    "gamefiles = glob.glob('game*.csv')\n",
    "gamefiles.sort()\n",
    "\n",
    "dfs = []\n",
    "for file in gamefiles:\n",
    "    dfs.append(pd.read_csv(file))\n",
    "game = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_dt</th>\n",
       "      <th>game_ct</th>\n",
       "      <th>game_dy</th>\n",
       "      <th>start_game_tm</th>\n",
       "      <th>dh_fl</th>\n",
       "      <th>daynight_park_cd</th>\n",
       "      <th>away_team_id</th>\n",
       "      <th>home_team_id</th>\n",
       "      <th>park_id</th>\n",
       "      <th>...</th>\n",
       "      <th>away_hits_ct</th>\n",
       "      <th>home_hits_ct</th>\n",
       "      <th>away_err_ct</th>\n",
       "      <th>home_err_ct</th>\n",
       "      <th>away_lob_ct</th>\n",
       "      <th>home_lob_ct</th>\n",
       "      <th>win_pit_id</th>\n",
       "      <th>lose_pit_id</th>\n",
       "      <th>save_pit_id</th>\n",
       "      <th>gwrbi_bat_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAL195504120</td>\n",
       "      <td>19550412</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>D</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BAL</td>\n",
       "      <td>BAL11</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>sullf101</td>\n",
       "      <td>colej101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAL195504180</td>\n",
       "      <td>19550418</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>NYA</td>\n",
       "      <td>BAL</td>\n",
       "      <td>BAL11</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>fordw101</td>\n",
       "      <td>moorr101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL195504220</td>\n",
       "      <td>19550422</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>WS1</td>\n",
       "      <td>BAL</td>\n",
       "      <td>BAL11</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>mcdem102</td>\n",
       "      <td>wilsj104</td>\n",
       "      <td>schmj101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        game_id   game_dt  game_ct  game_dy  start_game_tm dh_fl  \\\n",
       "0  BAL195504120  19550412        0  Tuesday              0     F   \n",
       "1  BAL195504180  19550418        0   Monday              0     F   \n",
       "2  BAL195504220  19550422        0   Friday              0     F   \n",
       "\n",
       "  daynight_park_cd away_team_id home_team_id park_id  ... away_hits_ct  \\\n",
       "0                D          BOS          BAL   BAL11  ...           13   \n",
       "1                N          NYA          BAL   BAL11  ...            8   \n",
       "2                N          WS1          BAL   BAL11  ...            4   \n",
       "\n",
       "  home_hits_ct away_err_ct home_err_ct away_lob_ct home_lob_ct win_pit_id  \\\n",
       "0            5           0           2           8           9   sullf101   \n",
       "1            3           0           1           5           4   fordw101   \n",
       "2            8           2           1           6          11   mcdem102   \n",
       "\n",
       "  lose_pit_id  save_pit_id gwrbi_bat_id  \n",
       "0    colej101          NaN          NaN  \n",
       "1    moorr101          NaN          NaN  \n",
       "2    wilsj104     schmj101          NaN  \n",
       "\n",
       "[3 rows x 46 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.reset_index(drop=True)\n",
    "game.columns = game.columns.str.lower()\n",
    "game.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'185.21 MB'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_usage(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64     1\n",
       "int64      22\n",
       "object     23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = optimize_pandas_dtypes(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29.36 MB'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_usage(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category    21\n",
       "float64      1\n",
       "int64        3\n",
       "object       2\n",
       "uint16       2\n",
       "uint32       1\n",
       "uint8       16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 12.4 ms, total: 4.48 s\n",
      "Wall time: 4.48 s\n"
     ]
    }
   ],
   "source": [
    "os.chdir(p_collected)\n",
    "%time to_csv_with_types(game, 'game', compression=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
