{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling and Analyzing Open Source Baseball Data\n",
    "\n",
    "**Baseball Notebooks**  \n",
    "1. This is the first in a series of notebooks for wrangling and analyzing open source Baseball data.\n",
    "\n",
    "This notebook will:\n",
    "* create directories for Lahman and Retrosheet raw and wrangled data\n",
    "* download the data\n",
    "* unzip the downloaded files\n",
    "\n",
    "This notebook is designed to be used with Jupyter Lab and the Table of Contents extension: https://github.com/jupyterlab/jupyterlab-toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Source Baseball Data\n",
    "**Lahman**  \n",
    "* Stats per Player per Year including:\n",
    "  * Batting.csv\n",
    "  * Pitching.csv\n",
    "  * Fielding.csv\n",
    "* Stats per Team per Year:\n",
    "  * Teams.csv\n",
    "* Lookup tables such as:\n",
    "  * People.csv\n",
    "  * Parks.csv\n",
    "* and more ...\n",
    "\n",
    "**Retrosheet**  \n",
    "* Play by Play data for every MLB game since 1921\n",
    "  * as parsed by cwdaily -> Batting/Pitching/Fielding stats per Player per Game\n",
    "  * as parsed by cwgame -> Batting/Pitching/Fielding stats per Team per Game, and Game specific info  \n",
    "  \n",
    "**Using Both**  \n",
    "* People.csv has the Lahman player_id as well as the Retrosheet player_id\n",
    "* Teams.csv has the Lahman team_id as well as the Retrosheet team_id\n",
    "* This allows for joins between Lahman and Retrosheet\n",
    "\n",
    "**Data Updates**\n",
    "* Lahman and Retrosheet do not update data for a season that is in progress.\n",
    "* Lahman and Retrosheet will have the previous season's data before the next season begins.\n",
    "  * For example, by March of 2020, all data for 2019 should be available\n",
    "* As of December 2019, Lahman has data through 2018 and Retrosheet has data through 2019.  \n",
    "\n",
    "**Note**  \n",
    "The code checks to see if the data has already been downloaded or not, and later code checks to see if the data has already been parsed or not.  This allows for rerunning the notebook cell without having to wait.  If you want to download new data, and reprocess it, then remove all the data from all the Lahman and Retrosheet directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Download and Unpack Lahman Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lahman Directories\n",
    "* raw data -- zipped and unzipped files\n",
    "* wrangled data -- to be populated in later notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path objects\n",
    "home = Path.home()\n",
    "lahman = home.joinpath('data/lahman')\n",
    "p_lahman_raw = lahman.joinpath('raw')\n",
    "p_lahman_wrangled = lahman.joinpath('wrangled')\n",
    "\n",
    "# create directories from these path objects\n",
    "p_lahman_raw.mkdir(parents=True, exist_ok=True)\n",
    "p_lahman_wrangled.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Unzip\n",
    "There are two sources for the Lahman data.\n",
    "\n",
    "**Sean Lahman**  \n",
    "http://www.seanlahman.com/baseball-archive/statistics  \n",
    "This site has specific snapshots of the data.  Useful if you want to be sure you have the same data as someone else.\n",
    "\n",
    "**Baseball Databank**  \n",
    "https://github.com/chadwickbureau/baseballdatabank  \n",
    "This is the latest data.  This is the data that will be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not already downloaded, download Lahman zip file\n",
    "os.chdir(p_lahman_raw)\n",
    "baseball_zip = p_lahman_raw.joinpath('baseballdatabank-master.zip')\n",
    "\n",
    "if not baseball_zip.is_file():\n",
    "    url = 'https://github.com/chadwickbureau/baseballdatabank/archive/master.zip'\n",
    "    wget.download(url)\n",
    "\n",
    "    # unzip it\n",
    "    with zipfile.ZipFile('baseballdatabank-master.zip', \"r\") as zip_ref:\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "os.chdir(p_lahman_raw)\n",
    "people_csv = p_lahman_raw.joinpath('People.csv')\n",
    "\n",
    "if not people_csv.is_file():\n",
    "    unzip_dir = p_lahman_raw.joinpath('baseballdatabank-master/core')\n",
    "\n",
    "    # move the unzipped csv files to the current working directory\n",
    "    os.chdir(p_lahman_raw)\n",
    "    for root, dirs, files in os.walk(unzip_dir):\n",
    "        for file in files:\n",
    "            shutil.move(root+'/'+file, '.')\n",
    "\n",
    "    # rm the extract directory\n",
    "    shutil.rmtree('baseballdatabank-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AllstarFull.csv',\n",
       " 'Appearances.csv',\n",
       " 'AwardsManagers.csv',\n",
       " 'AwardsPlayers.csv',\n",
       " 'AwardsShareManagers.csv',\n",
       " 'AwardsSharePlayers.csv',\n",
       " 'Batting.csv',\n",
       " 'BattingPost.csv',\n",
       " 'CollegePlaying.csv',\n",
       " 'Fielding.csv',\n",
       " 'FieldingOF.csv',\n",
       " 'FieldingOFsplit.csv',\n",
       " 'FieldingPost.csv',\n",
       " 'HallOfFame.csv',\n",
       " 'HomeGames.csv',\n",
       " 'Managers.csv',\n",
       " 'ManagersHalf.csv',\n",
       " 'Parks.csv',\n",
       " 'People.csv',\n",
       " 'Pitching.csv',\n",
       " 'PitchingPost.csv',\n",
       " 'Salaries.csv',\n",
       " 'Schools.csv',\n",
       " 'SeriesPost.csv',\n",
       " 'Teams.csv',\n",
       " 'TeamsFranchises.csv',\n",
       " 'TeamsHalf.csv',\n",
       " 'baseballdatabank-master.zip',\n",
       " 'readme2014.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the current directory (p_lahman_raw) has the csv files\n",
    "os.chdir(p_lahman_raw)\n",
    "sorted(os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Download and Unpack Retrosheet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Retrosheet Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Retrosheet directories for:\n",
    "* raw data -- zipped and unzipped files\n",
    "* wrangled data -- to be populated in later notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path objects\n",
    "home = Path.home()\n",
    "retrosheet = home.joinpath('data/retrosheet')\n",
    "p_retro_raw = retrosheet.joinpath('raw')\n",
    "p_retro_wrangled = retrosheet.joinpath('wrangled')\n",
    "\n",
    "# create directories (if they don't already exist) from these path objects\n",
    "p_retro_raw.mkdir(parents=True, exist_ok=True)\n",
    "p_retro_wrangled.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrosheet Event (aka Play by Play) Data\n",
    "Data is available from 1921 to present.  \n",
    "[Retrosheet Game Data](https://www.retrosheet.org/game.htm)\n",
    "\n",
    "Note that the \"live ball\" era of baseball began in 1920.  \n",
    "[Wikipedia Live Ball Era](https://en.wikipedia.org/wiki/Live-ball_era)\n",
    "\n",
    "Roughly\n",
    "* less than 1% of all games are missing since 1955\n",
    "* almost all of the missing games occurred before about 1975\n",
    "\n",
    "Data from 1955 through present will be downloaded an unzipped.\n",
    "\n",
    "The start year of 1955 was chosen for a few reasons:\n",
    "* Retrosheet is less likely to have missing games\n",
    "* some statistics, such as sacrifice flies, were not recorded prior to 1955\n",
    "\n",
    "Using all data since 1955 will create a DataFrame of over 2 GB in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current year:  2019\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    " \n",
    "# get current year\n",
    "d = datetime.datetime.today()\n",
    "print('Current year: ', d.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(p_retro_raw)\n",
    "\n",
    "for year in range(1955,d.year+1):    \n",
    "    # download each event file, if it doesn't exist locally\n",
    "    filename = f'{year}eve.zip'\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        try:\n",
    "            print(f'Downloading data for {year}')\n",
    "            url = f'http://www.retrosheet.org/events/{year}eve.zip'\n",
    "            wget.download(url)\n",
    "        except Exception:\n",
    "            print(f'{year} data not yet available')\n",
    "            break\n",
    "    \n",
    "    # unzip each zip file, if its contents don't exist locally\n",
    "    # {year}BOS.EVA is in all zip files\n",
    "    filename = f'{year}BOS.EVA'\n",
    "    path = Path(filename)\n",
    "    if not path.exists():\n",
    "        filename = f'{year}eve.zip'\n",
    "        with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzipped Data File Types\n",
    "The unzipped data consists of 3 types of files:\n",
    "1. *.EVA and *.EVN -- these are American League and National League event files per team per year\n",
    "2. *.ROS -- these are the rosters per team per year\n",
    "3. TEAM* -- these are the MBL teams in existence per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019SDN.EVN\n",
      "2019TEX.EVA\n",
      "2019ARI.EVN\n",
      "2019CLE.EVA\n",
      "2019PHI.EVN\n",
      "2019SLN.EVN\n",
      "2019BAL.EVA\n",
      "2019KCA.EVA\n",
      "2019COL.EVN\n",
      "2019HOU.EVA\n",
      "2019BOS.EVA\n",
      "2019MIA.EVN\n",
      "2019MIL.EVN\n",
      "2019TOR.EVA\n",
      "2019OAK.EVA\n",
      "2019SFN.EVN\n",
      "2019CHN.EVN\n",
      "2019ATL.EVN\n",
      "2019WAS.EVN\n",
      "2019DET.EVA\n",
      "2019CIN.EVN\n",
      "2019ANA.EVA\n",
      "2019NYA.EVA\n",
      "2019NYN.EVN\n",
      "2019CHA.EVA\n",
      "2019LAN.EVN\n",
      "2019MIN.EVA\n",
      "2019SEA.EVA\n",
      "2019PIT.EVN\n",
      "2019TBA.EVA\n"
     ]
    }
   ],
   "source": [
    "# List 2019 Play by Play Files\n",
    "files = os.listdir(p_retro_raw)\n",
    "for file in files:\n",
    "    if '2019' in file and (file.endswith('.EVA') or file.endswith('.EVN')):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAS2019.ROS\n",
      "NLS2019.ROS\n",
      "MIL2019.ROS\n",
      "COL2019.ROS\n",
      "MIA2019.ROS\n",
      "SFN2019.ROS\n",
      "PHI2019.ROS\n",
      "MIN2019.ROS\n",
      "KCA2019.ROS\n",
      "CIN2019.ROS\n",
      "LAN2019.ROS\n",
      "OAK2019.ROS\n",
      "NYN2019.ROS\n",
      "SEA2019.ROS\n",
      "ARI2019.ROS\n",
      "PIT2019.ROS\n",
      "ALS2019.ROS\n",
      "HOU2019.ROS\n",
      "TBA2019.ROS\n",
      "CLE2019.ROS\n",
      "BAL2019.ROS\n",
      "SLN2019.ROS\n",
      "BOS2019.ROS\n",
      "CHN2019.ROS\n",
      "NYA2019.ROS\n",
      "ATL2019.ROS\n",
      "DET2019.ROS\n",
      "SDN2019.ROS\n",
      "ANA2019.ROS\n",
      "TEX2019.ROS\n",
      "TOR2019.ROS\n",
      "CHA2019.ROS\n"
     ]
    }
   ],
   "source": [
    "# List 2019 Roster Files\n",
    "files = os.listdir(p_retro_raw)\n",
    "for file in files:\n",
    "    if '2019' in file and file.endswith('.ROS'):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEAM2019\n"
     ]
    }
   ],
   "source": [
    "# List 2019 Team Files\n",
    "files = os.listdir(p_retro_raw)\n",
    "for file in files:\n",
    "    if '2019' in file and file.startswith('TEAM'):\n",
    "        print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
